{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment4-4thDNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "# **4th DNN**\n",
        "\n",
        "**Thinking about**\n",
        "\n",
        "1. Number of Epochs and when to increase them,\n",
        "2. Batch Size, and effects of batch size\n",
        "3. How do we know our network is not going well, comparatively, very early\n",
        "4. When to add validation checks\n",
        "5. Learning Rate,\n",
        "6. LR schedule and concept behind it\n",
        "7. When do we stop convolutions and go ahead with a larger kernel or some other alternative (which we have not yet covered)\n",
        "\n",
        "**This is version 1.2 for Version 1.2 of 3rd DNN  **\n",
        "\n",
        "  Batch size 64\n",
        "  Epoch 30\n",
        "  Learning rate schedule with starting lr .001 and scheduler defined as example from session material\n",
        "\n",
        "*Result*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8FDs1Hx0-o0",
        "colab_type": "text"
      },
      "source": [
        "installing and Importing Keras for current solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "outputId": "8cfa1ad1-53e3-4490-92fa-a4380e76f1bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-qhHUhK1Ggp",
        "colab_type": "text"
      },
      "source": [
        "Importing Numpy and Keras modules as well as mnist data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxPvMT_21Mhy",
        "colab_type": "text"
      },
      "source": [
        "Loading mnist data set in train and test variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SMpZZpo1Sv0",
        "colab_type": "text"
      },
      "source": [
        "Ploting sample from train data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "568aad4e-c877-42cf-b525-b3b67dea81a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7629938b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1AM8Fy81X1n",
        "colab_type": "text"
      },
      "source": [
        "Reshaping all train and test data to a uniform size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjr4ODS81eUc",
        "colab_type": "text"
      },
      "source": [
        "Regularizing train and test data for float data type and division wiht 255"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDZ-v1na1okY",
        "colab_type": "text"
      },
      "source": [
        "Visualizing train out put"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "0685ecd0-b725-4a37-ffc9-1a03cda02abd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCLqRA3o1wFq",
        "colab_type": "text"
      },
      "source": [
        "Convert 1-dimensional class arrays to 10-dimensional class matrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXmnovfn1yew",
        "colab_type": "text"
      },
      "source": [
        "Viewing tranformed train out put matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "2cb8b023-387b-4580-8060-175682ad347e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "Y_train[:10]\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2PFtTZq127m",
        "colab_type": "text"
      },
      "source": [
        "Carrying form 3rd  DNN Version 1.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osKqT73Q9JJB",
        "colab_type": "code",
        "outputId": "2ed0b02b-d4d6-4f0d-c628-fcde3744636d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "from keras.layers import Activation, BatchNormalization\n",
        "model = Sequential()\n",
        "\n",
        "#Vanilla\n",
        "''' \n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Convolution2D(10, 1, activation='relu'))\n",
        "model.add(Convolution2D(10, 26))\n",
        "'''\n",
        "\n",
        "#1st version \n",
        "''''''\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 26,26 #RF 3X3\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 24,24 #RF 7X7\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 22,22 #RF 9X9\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 20,20 #RF 11X11\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 18,18 #RF 13X13\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 16,16 #RF 15X15\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 14,14 #RF 17X17\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Convolution2D(4, 3, 3, activation='relu')) #input 12,12 #RF 19X19\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(10, 1)) #input 10,10 \n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(10, 10)) #input 10,10\n",
        "\n",
        "\n",
        "#2nd version \n",
        "'''\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) #input 26,26 #RF 3X3\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) #input 24,24 #RF 7X7\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) #input 22,22 #RF 14X14\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 11,11 #RF 16X16\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu')) #input 9,9\n",
        "model.add(Convolution2D(10, 9)) #input 9X9\n",
        "'''\n",
        "\n",
        "#3rd version \n",
        "'''\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) #input 26,26 #RF 3X3\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) #input 24,24 #RF 6X6\n",
        "\n",
        "model.add(Convolution2D(12, 3, 3, activation='relu')) #input 12,12 #RF 8X8\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu')) #input 9,9\n",
        "model.add(Convolution2D(10, 10)) #input 9X9\n",
        "'''\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\")`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(4, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1mq9MtB2GgQ",
        "colab_type": "text"
      },
      "source": [
        "Printing model summary to understand current paramaters for the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzdAYg1k9K7Z",
        "colab_type": "code",
        "outputId": "1f28c353-47fd-4e28-c091-4be3227e0576",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_36 (Conv2D)           (None, 26, 26, 8)         80        \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 26, 26, 8)         32        \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 24, 24, 8)         584       \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 24, 24, 8)         32        \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 22, 22, 8)         584       \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 22, 22, 8)         32        \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 20, 20, 8)         584       \n",
            "_________________________________________________________________\n",
            "batch_normalization_30 (Batc (None, 20, 20, 8)         32        \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 20, 20, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 18, 18, 8)         584       \n",
            "_________________________________________________________________\n",
            "batch_normalization_31 (Batc (None, 18, 18, 8)         32        \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 16, 16, 8)         584       \n",
            "_________________________________________________________________\n",
            "batch_normalization_32 (Batc (None, 16, 16, 8)         32        \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (None, 14, 14, 8)         584       \n",
            "_________________________________________________________________\n",
            "batch_normalization_33 (Batc (None, 14, 14, 8)         32        \n",
            "_________________________________________________________________\n",
            "conv2d_43 (Conv2D)           (None, 12, 12, 8)         584       \n",
            "_________________________________________________________________\n",
            "batch_normalization_34 (Batc (None, 12, 12, 8)         32        \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 12, 12, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_44 (Conv2D)           (None, 10, 10, 4)         292       \n",
            "_________________________________________________________________\n",
            "batch_normalization_35 (Batc (None, 10, 10, 4)         16        \n",
            "_________________________________________________________________\n",
            "conv2d_45 (Conv2D)           (None, 10, 10, 10)        50        \n",
            "_________________________________________________________________\n",
            "batch_normalization_36 (Batc (None, 10, 10, 10)        40        \n",
            "_________________________________________________________________\n",
            "conv2d_46 (Conv2D)           (None, 1, 1, 10)          10010     \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 14,832\n",
            "Trainable params: 14,676\n",
            "Non-trainable params: 156\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlnhdT4u2Owz",
        "colab_type": "text"
      },
      "source": [
        "Setting model's compile environment with loss function, optimizer and matrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6SuGrL9M3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.001 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer=Adam(lr=0.001),\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06jT2a0t2Vpj",
        "colab_type": "text"
      },
      "source": [
        "Training model for 30 epoch for 64 batch size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xWoKhPY9Of5",
        "colab_type": "code",
        "outputId": "ec06cb4a-9431-4751-ea3f-15ed21ba36e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2108
        }
      },
      "source": [
        "history = model.fit(X_train, Y_train, batch_size=64, nb_epoch=30, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
            "60000/60000 [==============================] - 16s 267us/step - loss: 0.2927 - acc: 0.9083 - val_loss: 0.1116 - val_acc: 0.9647\n",
            "Epoch 2/30\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0007581501.\n",
            "60000/60000 [==============================] - 14s 230us/step - loss: 0.1031 - acc: 0.9680 - val_loss: 0.0664 - val_acc: 0.9798\n",
            "Epoch 3/30\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0006105006.\n",
            "60000/60000 [==============================] - 15s 250us/step - loss: 0.0808 - acc: 0.9751 - val_loss: 0.0605 - val_acc: 0.9812\n",
            "Epoch 4/30\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0005109862.\n",
            "60000/60000 [==============================] - 14s 230us/step - loss: 0.0685 - acc: 0.9788 - val_loss: 0.0534 - val_acc: 0.9819\n",
            "Epoch 5/30\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0004393673.\n",
            "60000/60000 [==============================] - 14s 228us/step - loss: 0.0630 - acc: 0.9806 - val_loss: 0.0471 - val_acc: 0.9858\n",
            "Epoch 6/30\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0003853565.\n",
            "60000/60000 [==============================] - 14s 235us/step - loss: 0.0587 - acc: 0.9818 - val_loss: 0.0577 - val_acc: 0.9824\n",
            "Epoch 7/30\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0003431709.\n",
            "60000/60000 [==============================] - 15s 248us/step - loss: 0.0539 - acc: 0.9831 - val_loss: 0.0464 - val_acc: 0.9855\n",
            "Epoch 8/30\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0003093102.\n",
            "60000/60000 [==============================] - 14s 232us/step - loss: 0.0514 - acc: 0.9838 - val_loss: 0.0414 - val_acc: 0.9859\n",
            "Epoch 9/30\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0002815315.\n",
            "60000/60000 [==============================] - 15s 243us/step - loss: 0.0488 - acc: 0.9847 - val_loss: 0.0381 - val_acc: 0.9872\n",
            "Epoch 10/30\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0002583312.\n",
            "60000/60000 [==============================] - 14s 227us/step - loss: 0.0474 - acc: 0.9850 - val_loss: 0.0410 - val_acc: 0.9871\n",
            "Epoch 11/30\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0002386635.\n",
            "60000/60000 [==============================] - 14s 227us/step - loss: 0.0439 - acc: 0.9864 - val_loss: 0.0431 - val_acc: 0.9856\n",
            "Epoch 12/30\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0002217787.\n",
            "60000/60000 [==============================] - 14s 227us/step - loss: 0.0427 - acc: 0.9869 - val_loss: 0.0370 - val_acc: 0.9882\n",
            "Epoch 13/30\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0002071251.\n",
            "60000/60000 [==============================] - 14s 228us/step - loss: 0.0409 - acc: 0.9869 - val_loss: 0.0371 - val_acc: 0.9881\n",
            "Epoch 14/30\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0001942879.\n",
            "60000/60000 [==============================] - 14s 237us/step - loss: 0.0405 - acc: 0.9872 - val_loss: 0.0390 - val_acc: 0.9876\n",
            "Epoch 15/30\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0001829491.\n",
            "60000/60000 [==============================] - 15s 249us/step - loss: 0.0389 - acc: 0.9877 - val_loss: 0.0374 - val_acc: 0.9879\n",
            "Epoch 16/30\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0001728608.\n",
            "60000/60000 [==============================] - 14s 227us/step - loss: 0.0380 - acc: 0.9878 - val_loss: 0.0396 - val_acc: 0.9874\n",
            "Epoch 17/30\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000163827.\n",
            "60000/60000 [==============================] - 14s 227us/step - loss: 0.0381 - acc: 0.9879 - val_loss: 0.0382 - val_acc: 0.9883\n",
            "Epoch 18/30\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0001556905.\n",
            "60000/60000 [==============================] - 14s 227us/step - loss: 0.0367 - acc: 0.9881 - val_loss: 0.0368 - val_acc: 0.9874\n",
            "Epoch 19/30\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0001483239.\n",
            "60000/60000 [==============================] - 14s 227us/step - loss: 0.0355 - acc: 0.9887 - val_loss: 0.0356 - val_acc: 0.9883\n",
            "Epoch 20/30\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000141623.\n",
            "60000/60000 [==============================] - 15s 246us/step - loss: 0.0351 - acc: 0.9888 - val_loss: 0.0355 - val_acc: 0.9880\n",
            "Epoch 21/30\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0001355014.\n",
            "60000/60000 [==============================] - 14s 228us/step - loss: 0.0348 - acc: 0.9889 - val_loss: 0.0390 - val_acc: 0.9876\n",
            "Epoch 22/30\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000129887.\n",
            "60000/60000 [==============================] - 14s 227us/step - loss: 0.0343 - acc: 0.9889 - val_loss: 0.0383 - val_acc: 0.9883\n",
            "Epoch 23/30\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0001247194.\n",
            "60000/60000 [==============================] - 14s 227us/step - loss: 0.0328 - acc: 0.9896 - val_loss: 0.0349 - val_acc: 0.9881\n",
            "Epoch 24/30\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0001199472.\n",
            "60000/60000 [==============================] - 14s 228us/step - loss: 0.0325 - acc: 0.9897 - val_loss: 0.0363 - val_acc: 0.9885\n",
            "Epoch 25/30\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0001155268.\n",
            "60000/60000 [==============================] - 14s 226us/step - loss: 0.0315 - acc: 0.9899 - val_loss: 0.0354 - val_acc: 0.9886\n",
            "Epoch 26/30\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0001114206.\n",
            "60000/60000 [==============================] - 15s 248us/step - loss: 0.0321 - acc: 0.9900 - val_loss: 0.0366 - val_acc: 0.9883\n",
            "Epoch 27/30\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0001075963.\n",
            "60000/60000 [==============================] - 14s 226us/step - loss: 0.0317 - acc: 0.9896 - val_loss: 0.0365 - val_acc: 0.9888\n",
            "Epoch 28/30\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0001040258.\n",
            "60000/60000 [==============================] - 14s 226us/step - loss: 0.0318 - acc: 0.9901 - val_loss: 0.0354 - val_acc: 0.9885\n",
            "Epoch 29/30\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.0001006847.\n",
            "60000/60000 [==============================] - 15s 254us/step - loss: 0.0301 - acc: 0.9903 - val_loss: 0.0370 - val_acc: 0.9884\n",
            "Epoch 30/30\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 9.75515e-05.\n",
            "60000/60000 [==============================] - 14s 227us/step - loss: 0.0314 - acc: 0.9899 - val_loss: 0.0358 - val_acc: 0.9881\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_0_UAU1M1wP",
        "colab_type": "text"
      },
      "source": [
        "Plotting training and validation accuracty as well as loss for every epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tvptcn8dxvp",
        "colab_type": "code",
        "outputId": "47081fd4-57d2-45b3-9b4a-895f6c5eb6b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#history = model.fit(x, y, validation_split=0.25, epochs=50, batch_size=16, verbose=1)\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UyH8P1SaNYYZ"
      },
      "source": [
        "Evaluating model and storing score in a variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_eDU0sXWNXmE",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_weXQQMkNWk1"
      },
      "source": [
        "Printing loss and accuracy of model test done in last step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkX8JMv79q9r",
        "colab_type": "code",
        "outputId": "54ae7b65-fec0-4324-ca01-1ccb356d52c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.035838619132025636, 0.9881]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ed35zlSB37Mm",
        "colab_type": "text"
      },
      "source": [
        "Predicting out put for test inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCWoJkwE9suh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8INoWoRT4BBu",
        "colab_type": "text"
      },
      "source": [
        "Printing prediction and test out puts "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym7iCFBm9uBs",
        "colab_type": "code",
        "outputId": "4c37ccbb-d6b0-4506-dfc0-1f70fc18db57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.4714722e-08 1.9759131e-08 6.5332932e-07 1.9755696e-05 1.2454306e-11\n",
            "  5.3617515e-09 2.1021771e-16 9.9997783e-01 9.6184380e-08 1.6557022e-06]\n",
            " [3.5062811e-04 1.3740474e-04 9.9943405e-01 4.1514981e-05 5.5457052e-09\n",
            "  3.7970713e-07 3.4700897e-05 9.2768310e-12 1.4295778e-06 1.2506852e-09]\n",
            " [5.5395817e-09 9.9999428e-01 2.9717787e-08 5.9665723e-08 1.3477761e-06\n",
            "  3.3349050e-07 4.6683826e-07 3.2206713e-06 6.8809612e-08 1.2302043e-07]\n",
            " [9.9978811e-01 9.7302388e-10 5.6100589e-08 4.8327103e-10 3.8235717e-10\n",
            "  6.2279560e-07 2.1002923e-04 5.8542955e-11 4.0047961e-08 1.2736280e-06]\n",
            " [5.2599761e-11 1.0844868e-11 2.0051560e-10 1.7017536e-14 9.9998534e-01\n",
            "  8.8404241e-12 3.9925787e-09 4.2481552e-10 4.2813295e-09 1.4607306e-05]\n",
            " [5.2361770e-06 9.9985492e-01 1.3641660e-05 4.2785771e-08 1.5857235e-05\n",
            "  1.6411461e-07 6.6560910e-06 9.8212367e-05 1.6112641e-06 3.5895687e-06]\n",
            " [8.3362001e-13 8.4117055e-08 5.6270349e-10 1.3791371e-11 9.9999726e-01\n",
            "  1.0064516e-11 3.7638795e-11 6.1648819e-09 8.1404545e-07 1.8559923e-06]\n",
            " [2.5005710e-08 3.6148653e-09 1.7777023e-07 8.5643915e-05 1.2623807e-03\n",
            "  4.7955916e-07 8.1214291e-10 4.5015736e-06 1.7781033e-06 9.9864501e-01]\n",
            " [3.2199902e-04 8.6760134e-16 8.5265878e-10 1.9651826e-07 3.7085721e-10\n",
            "  7.7328426e-01 2.2625954e-01 2.3090907e-10 3.6719983e-05 9.7254531e-05]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT--y98_dr2T",
        "colab_type": "code",
        "outputId": "7c62fe04-3661-4ec5-8fbb-cb9e338d3765",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
        "layer_dict"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation_1': <keras.layers.core.Activation at 0x7f761061f160>,\n",
              " 'batch_normalization_1': <keras.layers.normalization.BatchNormalization at 0x7f76270c5588>,\n",
              " 'batch_normalization_10': <keras.layers.normalization.BatchNormalization at 0x7f7610772f98>,\n",
              " 'batch_normalization_2': <keras.layers.normalization.BatchNormalization at 0x7f76270c59e8>,\n",
              " 'batch_normalization_3': <keras.layers.normalization.BatchNormalization at 0x7f761a753b38>,\n",
              " 'batch_normalization_4': <keras.layers.normalization.BatchNormalization at 0x7f761a6e24e0>,\n",
              " 'batch_normalization_5': <keras.layers.normalization.BatchNormalization at 0x7f761a618c18>,\n",
              " 'batch_normalization_6': <keras.layers.normalization.BatchNormalization at 0x7f761a4405f8>,\n",
              " 'batch_normalization_7': <keras.layers.normalization.BatchNormalization at 0x7f761a3ad588>,\n",
              " 'batch_normalization_8': <keras.layers.normalization.BatchNormalization at 0x7f761a2b08d0>,\n",
              " 'batch_normalization_9': <keras.layers.normalization.BatchNormalization at 0x7f761a1e59b0>,\n",
              " 'conv2d_1': <keras.layers.convolutional.Conv2D at 0x7f76270c53c8>,\n",
              " 'conv2d_10': <keras.layers.convolutional.Conv2D at 0x7f761078af60>,\n",
              " 'conv2d_11': <keras.layers.convolutional.Conv2D at 0x7f761071d0f0>,\n",
              " 'conv2d_2': <keras.layers.convolutional.Conv2D at 0x7f76270c5978>,\n",
              " 'conv2d_3': <keras.layers.convolutional.Conv2D at 0x7f761a7e14a8>,\n",
              " 'conv2d_4': <keras.layers.convolutional.Conv2D at 0x7f761a72c6d8>,\n",
              " 'conv2d_5': <keras.layers.convolutional.Conv2D at 0x7f761a5e95c0>,\n",
              " 'conv2d_6': <keras.layers.convolutional.Conv2D at 0x7f761a457e10>,\n",
              " 'conv2d_7': <keras.layers.convolutional.Conv2D at 0x7f761a34c208>,\n",
              " 'conv2d_8': <keras.layers.convolutional.Conv2D at 0x7f761a24f4a8>,\n",
              " 'conv2d_9': <keras.layers.convolutional.Conv2D at 0x7f761a1a0b00>,\n",
              " 'dropout_1': <keras.layers.core.Dropout at 0x7f761a62fc88>,\n",
              " 'dropout_2': <keras.layers.core.Dropout at 0x7f761a1974a8>,\n",
              " 'flatten_1': <keras.layers.core.Flatten at 0x7f761066fe80>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GY4Upv4dsUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras import backend as K\n",
        "%matplotlib inline\n",
        "# util function to convert a tensor into a valid image\n",
        "def deprocess_image(x):\n",
        "    # normalize tensor: center on 0., ensure std is 0.1\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + 1e-5)\n",
        "    x *= 0.1\n",
        "\n",
        "    # clip to [0, 1]\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "\n",
        "    # convert to RGB array\n",
        "    x *= 255\n",
        "    #x = x.transpose((1, 2, 0))\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "def vis_img_in_filter(img = np.array(X_train[2]).reshape((1, 28, 28, 1)).astype(np.float64), \n",
        "                      layer_name = 'conv2d_2'):  \n",
        "    layer_output = layer_dict[layer_name].output\n",
        "    img_ascs = list()\n",
        "    for filter_index in range(layer_output.shape[3]):\n",
        "        # build a loss function that maximizes the activation\n",
        "        # of the nth filter of the layer considered\n",
        "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
        "\n",
        "        # compute the gradient of the input picture wrt this loss\n",
        "        grads = K.gradients(loss, model.input)[0]\n",
        "\n",
        "        # normalization trick: we normalize the gradient\n",
        "        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
        "\n",
        "        # this function returns the loss and grads given the input picture\n",
        "        iterate = K.function([model.input], [loss, grads])\n",
        "\n",
        "        # step size for gradient ascent\n",
        "        step = 5.\n",
        "\n",
        "        img_asc = np.array(img)\n",
        "        # run gradient ascent for 20 steps\n",
        "        for i in range(20):\n",
        "            loss_value, grads_value = iterate([img_asc])\n",
        "            img_asc += grads_value * step\n",
        "\n",
        "        img_asc = img_asc[0]\n",
        "        img_ascs.append(deprocess_image(img_asc).reshape((28, 28)))\n",
        "        \n",
        "    if layer_output.shape[3] >= 35:\n",
        "        plot_x, plot_y = 6, 6\n",
        "    elif layer_output.shape[3] >= 23:\n",
        "        plot_x, plot_y = 4, 6\n",
        "    elif layer_output.shape[3] >= 11:\n",
        "        plot_x, plot_y = 2, 6\n",
        "    else:\n",
        "        plot_x, plot_y = 1, 2\n",
        "    fig, ax = plt.subplots(plot_x, plot_y, figsize = (12, 12))\n",
        "    ax[0, 0].imshow(img.reshape((28, 28)), cmap = 'gray')\n",
        "    ax[0, 0].set_title('Input image')\n",
        "    fig.suptitle('Input image and %s filters' % (layer_name,))\n",
        "    fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n",
        "    for (x, y) in [(i, j) for i in range(plot_x) for j in range(plot_y)]:\n",
        "        if x == 0 and y == 0:\n",
        "            continue\n",
        "        ax[x, y].imshow(img_ascs[x * plot_y + y - 1], cmap = 'gray')\n",
        "        ax[x, y].set_title('filter %d' % (x * plot_y + y - 1))\n",
        "\n",
        "vis_img_in_filter()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}