{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment4-4thDNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "# **4th DNN**\n",
        "\n",
        "**Thinking about**\n",
        "\n",
        "1. Number of Epochs and when to increase them,\n",
        "2. Batch Size, and effects of batch size\n",
        "3. How do we know our network is not going well, comparatively, very early\n",
        "4. When to add validation checks\n",
        "5. Learning Rate,\n",
        "6. LR schedule and concept behind it\n",
        "7. When do we stop convolutions and go ahead with a larger kernel or some other alternative (which we have not yet covered)\n",
        "\n",
        "**This is version 3.1 for Version 3 of 3rd DNN  **\n",
        "\n",
        "  Batch size 128\n",
        "  Epoch 50\n",
        "  Learning rate schedule with starting lr .008 and scheduler defined as example from session material\n",
        "\n",
        "*Result*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8FDs1Hx0-o0",
        "colab_type": "text"
      },
      "source": [
        "installing and Importing Keras for current solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "outputId": "8cfa1ad1-53e3-4490-92fa-a4380e76f1bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-qhHUhK1Ggp",
        "colab_type": "text"
      },
      "source": [
        "Importing Numpy and Keras modules as well as mnist data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxPvMT_21Mhy",
        "colab_type": "text"
      },
      "source": [
        "Loading mnist data set in train and test variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SMpZZpo1Sv0",
        "colab_type": "text"
      },
      "source": [
        "Ploting sample from train data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "568aad4e-c877-42cf-b525-b3b67dea81a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7629938b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1AM8Fy81X1n",
        "colab_type": "text"
      },
      "source": [
        "Reshaping all train and test data to a uniform size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjr4ODS81eUc",
        "colab_type": "text"
      },
      "source": [
        "Regularizing train and test data for float data type and division wiht 255"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDZ-v1na1okY",
        "colab_type": "text"
      },
      "source": [
        "Visualizing train out put"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "0685ecd0-b725-4a37-ffc9-1a03cda02abd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCLqRA3o1wFq",
        "colab_type": "text"
      },
      "source": [
        "Convert 1-dimensional class arrays to 10-dimensional class matrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXmnovfn1yew",
        "colab_type": "text"
      },
      "source": [
        "Viewing tranformed train out put matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "2cb8b023-387b-4580-8060-175682ad347e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "Y_train[:10]\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2PFtTZq127m",
        "colab_type": "text"
      },
      "source": [
        "Carrying form 3rd  DNN Version 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osKqT73Q9JJB",
        "colab_type": "code",
        "outputId": "294ca6be-adb6-494b-e15a-bb7551330bb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "from keras.layers import Activation, BatchNormalization\n",
        "model = Sequential()\n",
        "\n",
        "#Vanilla\n",
        "''' \n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Convolution2D(10, 1, activation='relu'))\n",
        "model.add(Convolution2D(10, 26))\n",
        "'''\n",
        "\n",
        "#1st version \n",
        "'''\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 26,26 #RF 3X3\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 24,24 #RF 7X7\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 22,22 #RF 9X9\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 20,20 #RF 11X11\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 18,18 #RF 13X13\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 16,16 #RF 15X15\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 14,14 #RF 17X17\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Convolution2D(4, 3, 3, activation='relu')) #input 12,12 #RF 19X19\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(10, 1)) #input 10,10 \n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(10, 10)) #input 10,10\n",
        "'''\n",
        "\n",
        "#2nd version \n",
        "'''\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) #input 26,26 #RF 3X3\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) #input 24,24 #RF 7X7\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) #input 22,22 #RF 14X14\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 11,11 #RF 16X16\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu')) #input 9,9\n",
        "model.add(Convolution2D(10, 9)) #input 9X9\n",
        "'''\n",
        "\n",
        "#3rd version \n",
        "''''''\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) #input 26,26 #RF 3X3\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) #input 24,24 #RF 6X6\n",
        "\n",
        "model.add(Convolution2D(12, 3, 3, activation='relu')) #input 12,12 #RF 8X8\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu')) #input 9,9\n",
        "model.add(Convolution2D(10, 10)) #input 9X9\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:75: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:80: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:85: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1mq9MtB2GgQ",
        "colab_type": "text"
      },
      "source": [
        "Printing model summary to understand current paramaters for the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzdAYg1k9K7Z",
        "colab_type": "code",
        "outputId": "4c422703-1741-4fbb-a92e-fa25f9b1394d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_75 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_61 (Batc (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_76 (Conv2D)           (None, 24, 24, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_62 (Batc (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 12, 12, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_77 (Conv2D)           (None, 10, 10, 12)        1740      \n",
            "_________________________________________________________________\n",
            "batch_normalization_63 (Batc (None, 10, 10, 12)        48        \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 10, 10, 12)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_78 (Conv2D)           (None, 10, 10, 10)        130       \n",
            "_________________________________________________________________\n",
            "conv2d_79 (Conv2D)           (None, 1, 1, 10)          10010     \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 14,536\n",
            "Trainable params: 14,448\n",
            "Non-trainable params: 88\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlnhdT4u2Owz",
        "colab_type": "text"
      },
      "source": [
        "Setting model's compile environment with loss function, optimizer and matrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6SuGrL9M3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.008 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer=Adam(lr=0.008),\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06jT2a0t2Vpj",
        "colab_type": "text"
      },
      "source": [
        "Training model for 50 epoch for 128 batch size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xWoKhPY9Of5",
        "colab_type": "code",
        "outputId": "fe37b2a4-7869-44ba-e0c2-84daf32acf24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3468
        }
      },
      "source": [
        "history = model.fit(X_train, Y_train, batch_size=128, nb_epoch=50, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.008.\n",
            "60000/60000 [==============================] - 10s 169us/step - loss: 0.1501 - acc: 0.9545 - val_loss: 0.0507 - val_acc: 0.9837\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0060652009.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0608 - acc: 0.9815 - val_loss: 0.0516 - val_acc: 0.9836\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0048840049.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0474 - acc: 0.9860 - val_loss: 0.0479 - val_acc: 0.9832\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0040878896.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0391 - acc: 0.9876 - val_loss: 0.0424 - val_acc: 0.9865\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0035149385.\n",
            "60000/60000 [==============================] - 5s 77us/step - loss: 0.0342 - acc: 0.9890 - val_loss: 0.0396 - val_acc: 0.9866\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0030828516.\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0308 - acc: 0.9900 - val_loss: 0.0308 - val_acc: 0.9900\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0027453672.\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.0269 - acc: 0.9909 - val_loss: 0.0297 - val_acc: 0.9894\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0024744819.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0260 - acc: 0.9915 - val_loss: 0.0261 - val_acc: 0.9911\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0022522523.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0237 - acc: 0.9920 - val_loss: 0.0299 - val_acc: 0.9898\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0020666494.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0209 - acc: 0.9934 - val_loss: 0.0256 - val_acc: 0.9915\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0019093079.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0197 - acc: 0.9936 - val_loss: 0.0245 - val_acc: 0.9914\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0017742293.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0183 - acc: 0.9939 - val_loss: 0.0246 - val_acc: 0.9914\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0016570008.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0179 - acc: 0.9940 - val_loss: 0.0239 - val_acc: 0.9927\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0015543035.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0169 - acc: 0.9942 - val_loss: 0.0244 - val_acc: 0.9922\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0014635931.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0160 - acc: 0.9947 - val_loss: 0.0263 - val_acc: 0.9916\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0013828868.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0159 - acc: 0.9947 - val_loss: 0.0262 - val_acc: 0.9925\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.001310616.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0139 - acc: 0.9954 - val_loss: 0.0236 - val_acc: 0.9925\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0012455239.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0143 - acc: 0.9953 - val_loss: 0.0255 - val_acc: 0.9931\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0011865915.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0131 - acc: 0.9954 - val_loss: 0.0247 - val_acc: 0.9919\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.001132984.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0124 - acc: 0.9960 - val_loss: 0.0294 - val_acc: 0.9910\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0010840108.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0122 - acc: 0.9959 - val_loss: 0.0279 - val_acc: 0.9916\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.001039096.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0118 - acc: 0.9959 - val_loss: 0.0258 - val_acc: 0.9917\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0009977551.\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0129 - acc: 0.9955 - val_loss: 0.0264 - val_acc: 0.9921\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0009595778.\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0114 - acc: 0.9960 - val_loss: 0.0241 - val_acc: 0.9929\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0009242144.\n",
            "60000/60000 [==============================] - 5s 78us/step - loss: 0.0104 - acc: 0.9963 - val_loss: 0.0258 - val_acc: 0.9925\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0008913649.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0109 - acc: 0.9963 - val_loss: 0.0240 - val_acc: 0.9925\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0008607704.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0097 - acc: 0.9967 - val_loss: 0.0244 - val_acc: 0.9922\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0008322064.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0094 - acc: 0.9968 - val_loss: 0.0235 - val_acc: 0.9930\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.0008054772.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0097 - acc: 0.9968 - val_loss: 0.0260 - val_acc: 0.9927\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0007804117.\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.0092 - acc: 0.9968 - val_loss: 0.0237 - val_acc: 0.9931\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.000756859.\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0079 - acc: 0.9971 - val_loss: 0.0266 - val_acc: 0.9923\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0007346864.\n",
            "60000/60000 [==============================] - 5s 79us/step - loss: 0.0082 - acc: 0.9971 - val_loss: 0.0286 - val_acc: 0.9921\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.0007137759.\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.0087 - acc: 0.9971 - val_loss: 0.0267 - val_acc: 0.9925\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0006940227.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0081 - acc: 0.9972 - val_loss: 0.0303 - val_acc: 0.9914\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.0006753334.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0084 - acc: 0.9971 - val_loss: 0.0267 - val_acc: 0.9921\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0006576243.\n",
            "60000/60000 [==============================] - 4s 73us/step - loss: 0.0084 - acc: 0.9969 - val_loss: 0.0256 - val_acc: 0.9923\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0006408202.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0077 - acc: 0.9972 - val_loss: 0.0248 - val_acc: 0.9933\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0006248535.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0077 - acc: 0.9975 - val_loss: 0.0258 - val_acc: 0.9930\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0006096632.\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.0074 - acc: 0.9971 - val_loss: 0.0269 - val_acc: 0.9929\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0005951938.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0071 - acc: 0.9975 - val_loss: 0.0259 - val_acc: 0.9923\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0005813953.\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0087 - acc: 0.9970 - val_loss: 0.0268 - val_acc: 0.9922\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0005682222.\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.0069 - acc: 0.9977 - val_loss: 0.0226 - val_acc: 0.9938\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0005556327.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0076 - acc: 0.9971 - val_loss: 0.0261 - val_acc: 0.9928\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.000543589.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0078 - acc: 0.9972 - val_loss: 0.0256 - val_acc: 0.9926\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0005320564.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0071 - acc: 0.9977 - val_loss: 0.0265 - val_acc: 0.9927\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0005210029.\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.0064 - acc: 0.9979 - val_loss: 0.0267 - val_acc: 0.9925\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0005103994.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0074 - acc: 0.9974 - val_loss: 0.0251 - val_acc: 0.9927\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0005002188.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0066 - acc: 0.9977 - val_loss: 0.0264 - val_acc: 0.9928\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0004904365.\n",
            "60000/60000 [==============================] - 4s 74us/step - loss: 0.0071 - acc: 0.9976 - val_loss: 0.0278 - val_acc: 0.9928\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.0004810294.\n",
            "60000/60000 [==============================] - 4s 75us/step - loss: 0.0068 - acc: 0.9975 - val_loss: 0.0287 - val_acc: 0.9925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_0_UAU1M1wP",
        "colab_type": "text"
      },
      "source": [
        "Plotting training and validation accuracty as well as loss for every epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tvptcn8dxvp",
        "colab_type": "code",
        "outputId": "f8107b99-4e72-442e-9887-8c722f0dcf44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#history = model.fit(x, y, validation_split=0.25, epochs=50, batch_size=16, verbose=1)\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UyH8P1SaNYYZ"
      },
      "source": [
        "Evaluating model and storing score in a variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_eDU0sXWNXmE",
        "colab": {}
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_weXQQMkNWk1"
      },
      "source": [
        "Printing loss and accuracy of model test done in last step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkX8JMv79q9r",
        "colab_type": "code",
        "outputId": "e3a66801-ac5d-40a9-fd9c-0a567757494b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.028704250345370427, 0.9925]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ed35zlSB37Mm",
        "colab_type": "text"
      },
      "source": [
        "Predicting out put for test inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCWoJkwE9suh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8INoWoRT4BBu",
        "colab_type": "text"
      },
      "source": [
        "Printing prediction and test out puts "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym7iCFBm9uBs",
        "colab_type": "code",
        "outputId": "097aef11-541e-4a44-ee7c-f4d6e011f4db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[8.92548263e-17 3.00165104e-16 4.17341032e-12 1.07516745e-13\n",
            "  1.28801889e-22 1.50071243e-17 5.80253081e-28 1.00000000e+00\n",
            "  6.19123645e-16 5.09850463e-13]\n",
            " [2.98076722e-14 3.98444971e-10 1.00000000e+00 4.78047429e-17\n",
            "  3.12833086e-14 6.84246202e-18 2.81354162e-09 4.95035707e-13\n",
            "  5.02663300e-14 2.14265504e-17]\n",
            " [1.08592927e-14 1.00000000e+00 2.75951987e-11 7.05022876e-15\n",
            "  5.30381428e-08 7.14295810e-12 2.07089276e-11 3.85287025e-10\n",
            "  2.25461403e-11 7.19051012e-13]\n",
            " [1.00000000e+00 8.96771964e-20 2.12623877e-11 5.29195269e-15\n",
            "  5.81410694e-17 8.09655999e-13 4.30408020e-09 4.89531277e-18\n",
            "  2.05450934e-12 7.14240334e-11]\n",
            " [1.19869045e-11 1.01401729e-13 1.81767900e-14 1.11112318e-17\n",
            "  9.99999046e-01 5.74467464e-18 7.97282108e-13 7.49714283e-14\n",
            "  7.42855624e-16 9.94174684e-07]\n",
            " [3.21636543e-13 1.00000000e+00 9.40399633e-11 1.31259485e-17\n",
            "  4.60644944e-09 1.39193212e-14 5.08813911e-13 2.41387870e-08\n",
            "  3.26209220e-12 3.38096630e-13]\n",
            " [8.97956448e-20 4.26443481e-15 1.21228358e-13 9.76438116e-20\n",
            "  1.00000000e+00 1.11031609e-15 1.24467231e-22 4.22018106e-12\n",
            "  3.75130621e-10 4.51061988e-09]\n",
            " [8.54382607e-25 5.77300599e-15 8.42635152e-13 9.28252607e-16\n",
            "  3.31878880e-08 6.56507158e-15 2.00259993e-23 5.84187771e-16\n",
            "  2.53939014e-13 1.00000000e+00]\n",
            " [6.30903140e-14 6.58433369e-18 3.65544684e-19 1.40615053e-16\n",
            "  3.26285322e-18 9.99685049e-01 3.13987723e-04 3.95395848e-19\n",
            "  5.67581708e-07 3.42485151e-07]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT--y98_dr2T",
        "colab_type": "code",
        "outputId": "7c62fe04-3661-4ec5-8fbb-cb9e338d3765",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
        "layer_dict"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation_1': <keras.layers.core.Activation at 0x7f761061f160>,\n",
              " 'batch_normalization_1': <keras.layers.normalization.BatchNormalization at 0x7f76270c5588>,\n",
              " 'batch_normalization_10': <keras.layers.normalization.BatchNormalization at 0x7f7610772f98>,\n",
              " 'batch_normalization_2': <keras.layers.normalization.BatchNormalization at 0x7f76270c59e8>,\n",
              " 'batch_normalization_3': <keras.layers.normalization.BatchNormalization at 0x7f761a753b38>,\n",
              " 'batch_normalization_4': <keras.layers.normalization.BatchNormalization at 0x7f761a6e24e0>,\n",
              " 'batch_normalization_5': <keras.layers.normalization.BatchNormalization at 0x7f761a618c18>,\n",
              " 'batch_normalization_6': <keras.layers.normalization.BatchNormalization at 0x7f761a4405f8>,\n",
              " 'batch_normalization_7': <keras.layers.normalization.BatchNormalization at 0x7f761a3ad588>,\n",
              " 'batch_normalization_8': <keras.layers.normalization.BatchNormalization at 0x7f761a2b08d0>,\n",
              " 'batch_normalization_9': <keras.layers.normalization.BatchNormalization at 0x7f761a1e59b0>,\n",
              " 'conv2d_1': <keras.layers.convolutional.Conv2D at 0x7f76270c53c8>,\n",
              " 'conv2d_10': <keras.layers.convolutional.Conv2D at 0x7f761078af60>,\n",
              " 'conv2d_11': <keras.layers.convolutional.Conv2D at 0x7f761071d0f0>,\n",
              " 'conv2d_2': <keras.layers.convolutional.Conv2D at 0x7f76270c5978>,\n",
              " 'conv2d_3': <keras.layers.convolutional.Conv2D at 0x7f761a7e14a8>,\n",
              " 'conv2d_4': <keras.layers.convolutional.Conv2D at 0x7f761a72c6d8>,\n",
              " 'conv2d_5': <keras.layers.convolutional.Conv2D at 0x7f761a5e95c0>,\n",
              " 'conv2d_6': <keras.layers.convolutional.Conv2D at 0x7f761a457e10>,\n",
              " 'conv2d_7': <keras.layers.convolutional.Conv2D at 0x7f761a34c208>,\n",
              " 'conv2d_8': <keras.layers.convolutional.Conv2D at 0x7f761a24f4a8>,\n",
              " 'conv2d_9': <keras.layers.convolutional.Conv2D at 0x7f761a1a0b00>,\n",
              " 'dropout_1': <keras.layers.core.Dropout at 0x7f761a62fc88>,\n",
              " 'dropout_2': <keras.layers.core.Dropout at 0x7f761a1974a8>,\n",
              " 'flatten_1': <keras.layers.core.Flatten at 0x7f761066fe80>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GY4Upv4dsUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras import backend as K\n",
        "%matplotlib inline\n",
        "# util function to convert a tensor into a valid image\n",
        "def deprocess_image(x):\n",
        "    # normalize tensor: center on 0., ensure std is 0.1\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + 1e-5)\n",
        "    x *= 0.1\n",
        "\n",
        "    # clip to [0, 1]\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "\n",
        "    # convert to RGB array\n",
        "    x *= 255\n",
        "    #x = x.transpose((1, 2, 0))\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "def vis_img_in_filter(img = np.array(X_train[2]).reshape((1, 28, 28, 1)).astype(np.float64), \n",
        "                      layer_name = 'conv2d_2'):  \n",
        "    layer_output = layer_dict[layer_name].output\n",
        "    img_ascs = list()\n",
        "    for filter_index in range(layer_output.shape[3]):\n",
        "        # build a loss function that maximizes the activation\n",
        "        # of the nth filter of the layer considered\n",
        "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
        "\n",
        "        # compute the gradient of the input picture wrt this loss\n",
        "        grads = K.gradients(loss, model.input)[0]\n",
        "\n",
        "        # normalization trick: we normalize the gradient\n",
        "        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
        "\n",
        "        # this function returns the loss and grads given the input picture\n",
        "        iterate = K.function([model.input], [loss, grads])\n",
        "\n",
        "        # step size for gradient ascent\n",
        "        step = 5.\n",
        "\n",
        "        img_asc = np.array(img)\n",
        "        # run gradient ascent for 20 steps\n",
        "        for i in range(20):\n",
        "            loss_value, grads_value = iterate([img_asc])\n",
        "            img_asc += grads_value * step\n",
        "\n",
        "        img_asc = img_asc[0]\n",
        "        img_ascs.append(deprocess_image(img_asc).reshape((28, 28)))\n",
        "        \n",
        "    if layer_output.shape[3] >= 35:\n",
        "        plot_x, plot_y = 6, 6\n",
        "    elif layer_output.shape[3] >= 23:\n",
        "        plot_x, plot_y = 4, 6\n",
        "    elif layer_output.shape[3] >= 11:\n",
        "        plot_x, plot_y = 2, 6\n",
        "    else:\n",
        "        plot_x, plot_y = 1, 2\n",
        "    fig, ax = plt.subplots(plot_x, plot_y, figsize = (12, 12))\n",
        "    ax[0, 0].imshow(img.reshape((28, 28)), cmap = 'gray')\n",
        "    ax[0, 0].set_title('Input image')\n",
        "    fig.suptitle('Input image and %s filters' % (layer_name,))\n",
        "    fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n",
        "    for (x, y) in [(i, j) for i in range(plot_x) for j in range(plot_y)]:\n",
        "        if x == 0 and y == 0:\n",
        "            continue\n",
        "        ax[x, y].imshow(img_ascs[x * plot_y + y - 1], cmap = 'gray')\n",
        "        ax[x, y].set_title('filter %d' % (x * plot_y + y - 1))\n",
        "\n",
        "vis_img_in_filter()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}