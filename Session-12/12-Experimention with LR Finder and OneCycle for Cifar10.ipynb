{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "12.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lqayzy3snKz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc159764-b744-4a0f-d616-841eb6a086c8"
      },
      "source": [
        "# importing necessary libs\n",
        "from keras import backend as K\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "% matplotlib inline\n",
        "np.random.seed(2017) \n",
        "from keras import regularizers, optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D\n",
        "from keras.layers import Activation, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA9IWwwTxSbE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tunable hyperparameters\n",
        "BATCH_SIZE = 512 #@param [\"512\", \"256\", \"128\"] {type:\"raw\"}\n",
        "MOMENTUM = 0.9 #@param [\"0.9\", \"0.95\", \"0.975\"] {type:\"raw\"}\n",
        "WEIGHT_DECAY = 0.000125 #@param [\"0.000125\", \"0.00025\", \"0.0005\"] {type:\"raw\"}\n",
        "LEARNING_RATE = 0.4 #@param [\"0.4\", \"0.2\", \"0.1\"] {type:\"raw\"}\n",
        "EPOCHS = 24 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "WARMUP = 5 #@param {type:\"slider\", min:0, max:24, step:1}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UFDMSWDwGsl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ec462f88-b2c6-4c5e-e7d3-488f535b4711"
      },
      "source": [
        "# Getting cifar10 data\n",
        "from keras.datasets import cifar10\n",
        "(train_features, train_labels), (test_features, test_labels) = cifar10.load_data()\n",
        "num_train, img_rows, img_cols,img_channels =  train_features.shape\n",
        "num_test, _, _, _ =  test_features.shape\n",
        "num_classes = len(np.unique(train_labels))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2_UuoZMyOwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Normalizing data\n",
        "train_features = train_features.astype('float32')/255\n",
        "test_features = test_features.astype('float32')/255\n",
        "# convert class labels to binary class labels\n",
        "train_labels = np_utils.to_categorical(train_labels, num_classes)\n",
        "test_labels = np_utils.to_categorical(test_labels, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YmPrZh0ySop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Defining function to measure accuracy\n",
        "def accuracy(test_x, test_y, model):\n",
        "    result = model.predict(test_x)\n",
        "    predicted_class = np.argmax(result, axis=1)\n",
        "    true_class = np.argmax(test_y, axis=1)\n",
        "    num_correct = np.sum(predicted_class == true_class) \n",
        "    accuracy = float(num_correct)/result.shape[0]\n",
        "    return (accuracy * 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNCRfegYwO_L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "a6e74269-b3bb-43d6-c913-6a24e3a20f9c"
      },
      "source": [
        "''' need to impliment this in keras\n",
        "def build_nn(c=64, weight=0.125):\n",
        " \n",
        "return model\n",
        "'''\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#model.add(fw.layers.ConvBN(c, **fw.layers.PYTORCH_CONV_PARAMS))\n",
        "model.add(Convolution2D(64, 3, 3, input_shape=(32, 32, 3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "#model.add(fw.layers.ConvResBlk(c*2, res_convs=2,  **fw.layers.PYTORCH_CONV_PARAMS))\n",
        "model.add(Convolution2D(128, 3, 3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(128, 3, 3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "#model.add(fw.layers.ConvBlk(c*4, **fw.layers.PYTORCH_CONV_PARAMS))\n",
        "model.add(Convolution2D(256, 3, 3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "#model.add(fw.layers.ConvResBlk(c*8, res_convs=2,  **fw.layers.PYTORCH_CONV_PARAMS))\n",
        "model.add(Convolution2D(512, 3, 3))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Convolution2D(512, 3, 3))\n",
        "model.add(BatchNormalization())\n",
        "#model.add(Activation('relu'))\n",
        "\n",
        "#model.add(tf.keras.layers.GlobalMaxPool2D())\n",
        "model.add(MaxPooling2D()) # , AveragePooling2D\n",
        "model.add(GlobalAveragePooling2D())\n",
        "\n",
        "#model.add(fw.layers.Classifier(n_classes, kernel_initializer=fw.layers.init_pytorch, weight=0.125))\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0802 17:24:14.770689 140336569206656 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), input_shape=(32, 32, 3...)`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "W0802 17:24:14.808055 140336569206656 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0802 17:24:14.814225 140336569206656 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0802 17:24:14.851964 140336569206656 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0802 17:24:14.852751 140336569206656 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0802 17:24:17.726893 140336569206656 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3))`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3))`\n",
            "W0802 17:24:18.170787 140336569206656 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3))`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RG4XzA0sylIy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "6dc295d7-c54b-4359-d6cf-c0475626795f"
      },
      "source": [
        "#Compiling model \n",
        "sgd = optimizers.SGD(momentum=MOMENTUM, nesterov=False)\n",
        "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0802 17:24:18.372078 140336569206656 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRtyUb7dyec4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "outputId": "012fa25b-4fa7-438a-9d45-e0d5d6790313"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 30, 30, 64)        1792      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 30, 30, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 28, 28, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 28, 28, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 28, 28, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 26, 26, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 26, 26, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 26, 26, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 24, 24, 256)       295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 24, 24, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 24, 24, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 10, 10, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 10, 10, 512)       2048      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 10, 10, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 4,069,898\n",
            "Trainable params: 4,066,698\n",
            "Non-trainable params: 3,200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EC1BirdrzP4w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "f923fea5-eab5-4c90-8a3d-ee24c5685635"
      },
      "source": [
        "#Loading google drive to retrive data and store training weights\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "#preparing path for dir in drive to save weights\n",
        "import os\n",
        "corpus = os.path.join(\"/content/gdrive/My Drive\", \"Weights\")\n",
        "\n",
        "# define the checkpoint\n",
        "filepath=os.path.join(corpus, \"13-v0.1weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\")\n",
        "#\"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWbAsd0m0unJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "30dc0a5e-75f1-4dac-8924-cd3a93e6b0b5"
      },
      "source": [
        "#Getting repo for import OneCycleLR from this link: https://github.com/titu1994/keras-one-cycle\n",
        "!git clone https://github.com/titu1994/keras-one-cycle.git\n",
        "import sys\n",
        "sys.path.append(\"/content/keras-one-cycle/\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'keras-one-cycle'...\n",
            "remote: Enumerating objects: 208, done.\u001b[K\n",
            "remote: Total 208 (delta 0), reused 0 (delta 0), pack-reused 208\u001b[K\n",
            "Receiving objects: 100% (208/208), 3.18 MiB | 16.45 MiB/s, done.\n",
            "Resolving deltas: 100% (82/82), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEkIcsD0VGe0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b4c1e460-4c35-4437-f96e-482f0a6afe2b"
      },
      "source": [
        "#Finding LR\n",
        "from clr import LRFinder\n",
        "\n",
        "lr_callback = LRFinder(num_samples=num_train, batch_size=BATCH_SIZE,\n",
        "                       minimum_lr=0.001, maximum_lr=0.1,\n",
        "                       # validation_data=(X_val, Y_val),\n",
        "                       lr_scale='exp', save_dir=filepath)\n",
        "\n",
        "# Ensure that number of epochs = 1 when calling fit()\n",
        "model.fit(train_features, train_labels, epochs=1, batch_size=BATCH_SIZE, callbacks=[lr_callback])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0802 17:24:50.555277 140336569206656 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "  512/50000 [..............................] - ETA: 17:03 - loss: 3.2678 - acc: 0.0957 - LRFinder: lr = 0.00104862 \n",
            " 1024/50000 [..............................] - ETA: 8:43 - loss: 3.2094 - acc: 0.0869  - LRFinder: lr = 0.00109961 \n",
            " 1536/50000 [..............................] - ETA: 5:56 - loss: 3.1740 - acc: 0.0892 - LRFinder: lr = 0.00115307 \n",
            " 2048/50000 [>.............................] - ETA: 4:32 - loss: 3.0475 - acc: 0.0991 - LRFinder: lr = 0.00120913 \n",
            " 2560/50000 [>.............................] - ETA: 3:41 - loss: 2.9529 - acc: 0.1113 - LRFinder: lr = 0.00126792 \n",
            " 3072/50000 [>.............................] - ETA: 3:07 - loss: 2.8458 - acc: 0.1273 - LRFinder: lr = 0.00132957 \n",
            " 3584/50000 [=>............................] - ETA: 2:43 - loss: 2.7508 - acc: 0.1392 - LRFinder: lr = 0.00139422 \n",
            " 4096/50000 [=>............................] - ETA: 2:25 - loss: 2.6721 - acc: 0.1504 - LRFinder: lr = 0.00146200 \n",
            " 4608/50000 [=>............................] - ETA: 2:11 - loss: 2.5985 - acc: 0.1641 - LRFinder: lr = 0.00153309 \n",
            " 5120/50000 [==>...........................] - ETA: 1:59 - loss: 2.5444 - acc: 0.1723 - LRFinder: lr = 0.00160763 \n",
            " 5632/50000 [==>...........................] - ETA: 1:50 - loss: 2.4923 - acc: 0.1804 - LRFinder: lr = 0.00168579 \n",
            " 6144/50000 [==>...........................] - ETA: 1:42 - loss: 2.4490 - acc: 0.1864 - LRFinder: lr = 0.00176776 \n",
            " 6656/50000 [==>...........................] - ETA: 1:35 - loss: 2.4122 - acc: 0.1923 - LRFinder: lr = 0.00185371 \n",
            " 7168/50000 [===>..........................] - ETA: 1:29 - loss: 2.3747 - acc: 0.1985 - LRFinder: lr = 0.00194384 \n",
            " 7680/50000 [===>..........................] - ETA: 1:24 - loss: 2.3398 - acc: 0.2068 - LRFinder: lr = 0.00203835 \n",
            " 8192/50000 [===>..........................] - ETA: 1:20 - loss: 2.3059 - acc: 0.2135 - LRFinder: lr = 0.00213745 \n",
            " 8704/50000 [====>.........................] - ETA: 1:16 - loss: 2.2771 - acc: 0.2193 - LRFinder: lr = 0.00224138 \n",
            " 9216/50000 [====>.........................] - ETA: 1:12 - loss: 2.2543 - acc: 0.2255 - LRFinder: lr = 0.00235036 \n",
            " 9728/50000 [====>.........................] - ETA: 1:09 - loss: 2.2295 - acc: 0.2321 - LRFinder: lr = 0.00246463 \n",
            "10240/50000 [=====>........................] - ETA: 1:06 - loss: 2.2035 - acc: 0.2384 - LRFinder: lr = 0.00258447 \n",
            "10752/50000 [=====>........................] - ETA: 1:03 - loss: 2.1792 - acc: 0.2461 - LRFinder: lr = 0.00271013 \n",
            "11264/50000 [=====>........................] - ETA: 1:00 - loss: 2.1569 - acc: 0.2523 - LRFinder: lr = 0.00284190 \n",
            "11776/50000 [======>.......................] - ETA: 58s - loss: 2.1385 - acc: 0.2573  - LRFinder: lr = 0.00298007 \n",
            "12288/50000 [======>.......................] - ETA: 56s - loss: 2.1157 - acc: 0.2642 - LRFinder: lr = 0.00312497 \n",
            "12800/50000 [======>.......................] - ETA: 54s - loss: 2.0973 - acc: 0.2692 - LRFinder: lr = 0.00327691 \n",
            "13312/50000 [======>.......................] - ETA: 52s - loss: 2.0786 - acc: 0.2743 - LRFinder: lr = 0.00343623 \n",
            "13824/50000 [=======>......................] - ETA: 50s - loss: 2.0630 - acc: 0.2781 - LRFinder: lr = 0.00360331 \n",
            "14336/50000 [=======>......................] - ETA: 49s - loss: 2.0452 - acc: 0.2838 - LRFinder: lr = 0.00377850 \n",
            "14848/50000 [=======>......................] - ETA: 47s - loss: 2.0315 - acc: 0.2873 - LRFinder: lr = 0.00396222 \n",
            "15360/50000 [========>.....................] - ETA: 46s - loss: 2.0165 - acc: 0.2913 - LRFinder: lr = 0.00415486 \n",
            "15872/50000 [========>.....................] - ETA: 44s - loss: 2.0034 - acc: 0.2953 - LRFinder: lr = 0.00435688 \n",
            "16384/50000 [========>.....................] - ETA: 43s - loss: 1.9915 - acc: 0.2983 - LRFinder: lr = 0.00456871 \n",
            "16896/50000 [=========>....................] - ETA: 42s - loss: 1.9788 - acc: 0.3023 - LRFinder: lr = 0.00479085 \n",
            "17408/50000 [=========>....................] - ETA: 40s - loss: 1.9648 - acc: 0.3066 - LRFinder: lr = 0.00502378 \n",
            "17920/50000 [=========>....................] - ETA: 39s - loss: 1.9509 - acc: 0.3116 - LRFinder: lr = 0.00526804 \n",
            "18432/50000 [==========>...................] - ETA: 38s - loss: 1.9391 - acc: 0.3152 - LRFinder: lr = 0.00552418 \n",
            "18944/50000 [==========>...................] - ETA: 37s - loss: 1.9272 - acc: 0.3192 - LRFinder: lr = 0.00579277 \n",
            "19456/50000 [==========>...................] - ETA: 36s - loss: 1.9147 - acc: 0.3230 - LRFinder: lr = 0.00607442 \n",
            "19968/50000 [==========>...................] - ETA: 35s - loss: 1.9032 - acc: 0.3267 - LRFinder: lr = 0.00636977 \n",
            "20480/50000 [===========>..................] - ETA: 34s - loss: 1.8922 - acc: 0.3304 - LRFinder: lr = 0.00667947 \n",
            "20992/50000 [===========>..................] - ETA: 33s - loss: 1.8826 - acc: 0.3335 - LRFinder: lr = 0.00700424 \n",
            "21504/50000 [===========>..................] - ETA: 32s - loss: 1.8745 - acc: 0.3358 - LRFinder: lr = 0.00734479 \n",
            "22016/50000 [============>.................] - ETA: 31s - loss: 1.8668 - acc: 0.3387 - LRFinder: lr = 0.00770190 \n",
            "22528/50000 [============>.................] - ETA: 30s - loss: 1.8567 - acc: 0.3417 - LRFinder: lr = 0.00807638 \n",
            "23040/50000 [============>.................] - ETA: 30s - loss: 1.8479 - acc: 0.3449 - LRFinder: lr = 0.00846906 \n",
            "23552/50000 [=============>................] - ETA: 29s - loss: 1.8390 - acc: 0.3471 - LRFinder: lr = 0.00888083 \n",
            "24064/50000 [=============>................] - ETA: 28s - loss: 1.8321 - acc: 0.3495 - LRFinder: lr = 0.00931263 \n",
            "24576/50000 [=============>................] - ETA: 27s - loss: 1.8237 - acc: 0.3521 - LRFinder: lr = 0.00976542 \n",
            "25088/50000 [==============>...............] - ETA: 26s - loss: 1.8152 - acc: 0.3545 - LRFinder: lr = 0.01024022 \n",
            "25600/50000 [==============>...............] - ETA: 26s - loss: 1.8063 - acc: 0.3572 - LRFinder: lr = 0.01073811 \n",
            "26112/50000 [==============>...............] - ETA: 25s - loss: 1.7986 - acc: 0.3596 - LRFinder: lr = 0.01126021 \n",
            "26624/50000 [==============>...............] - ETA: 24s - loss: 1.7917 - acc: 0.3623 - LRFinder: lr = 0.01180769 \n",
            "27136/50000 [===============>..............] - ETA: 23s - loss: 1.7853 - acc: 0.3649 - LRFinder: lr = 0.01238179 \n",
            "27648/50000 [===============>..............] - ETA: 23s - loss: 1.7775 - acc: 0.3673 - LRFinder: lr = 0.01298381 \n",
            "28160/50000 [===============>..............] - ETA: 22s - loss: 1.7724 - acc: 0.3694 - LRFinder: lr = 0.01361509 \n",
            "28672/50000 [================>.............] - ETA: 21s - loss: 1.7669 - acc: 0.3719 - LRFinder: lr = 0.01427707 \n",
            "29184/50000 [================>.............] - ETA: 21s - loss: 1.7593 - acc: 0.3745 - LRFinder: lr = 0.01497124 \n",
            "29696/50000 [================>.............] - ETA: 20s - loss: 1.7544 - acc: 0.3762 - LRFinder: lr = 0.01569915 \n",
            "30208/50000 [=================>............] - ETA: 19s - loss: 1.7481 - acc: 0.3785 - LRFinder: lr = 0.01646246 \n",
            "30720/50000 [=================>............] - ETA: 19s - loss: 1.7434 - acc: 0.3799 - LRFinder: lr = 0.01726288 \n",
            "31232/50000 [=================>............] - ETA: 18s - loss: 1.7386 - acc: 0.3811 - LRFinder: lr = 0.01810222 \n",
            "31744/50000 [==================>...........] - ETA: 18s - loss: 1.7339 - acc: 0.3831 - LRFinder: lr = 0.01898237 \n",
            "32256/50000 [==================>...........] - ETA: 17s - loss: 1.7298 - acc: 0.3844 - LRFinder: lr = 0.01990531 \n",
            "32768/50000 [==================>...........] - ETA: 16s - loss: 1.7261 - acc: 0.3858 - LRFinder: lr = 0.02087313 \n",
            "33280/50000 [==================>...........] - ETA: 16s - loss: 1.7213 - acc: 0.3873 - LRFinder: lr = 0.02188800 \n",
            "33792/50000 [===================>..........] - ETA: 15s - loss: 1.7161 - acc: 0.3890 - LRFinder: lr = 0.02295222 \n",
            "34304/50000 [===================>..........] - ETA: 15s - loss: 1.7104 - acc: 0.3913 - LRFinder: lr = 0.02406818 \n",
            "34816/50000 [===================>..........] - ETA: 14s - loss: 1.7063 - acc: 0.3927 - LRFinder: lr = 0.02523840 \n",
            "35328/50000 [====================>.........] - ETA: 14s - loss: 1.7007 - acc: 0.3952 - LRFinder: lr = 0.02646552 \n",
            "35840/50000 [====================>.........] - ETA: 13s - loss: 1.6954 - acc: 0.3971 - LRFinder: lr = 0.02775230 \n",
            "36352/50000 [====================>.........] - ETA: 13s - loss: 1.6916 - acc: 0.3986 - LRFinder: lr = 0.02910164 \n",
            "36864/50000 [=====================>........] - ETA: 12s - loss: 1.6876 - acc: 0.3996 - LRFinder: lr = 0.03051660 \n",
            "37376/50000 [=====================>........] - ETA: 11s - loss: 1.6838 - acc: 0.4009 - LRFinder: lr = 0.03200034 \n",
            "37888/50000 [=====================>........] - ETA: 11s - loss: 1.6803 - acc: 0.4021 - LRFinder: lr = 0.03355623 \n",
            "38400/50000 [======================>.......] - ETA: 10s - loss: 1.6772 - acc: 0.4030 - LRFinder: lr = 0.03518777 \n",
            "38912/50000 [======================>.......] - ETA: 10s - loss: 1.6756 - acc: 0.4032 - LRFinder: lr = 0.03689864 \n",
            "39424/50000 [======================>.......] - ETA: 9s - loss: 1.6729 - acc: 0.4042  - LRFinder: lr = 0.03869269 \n",
            "39936/50000 [======================>.......] - ETA: 9s - loss: 1.6720 - acc: 0.4048 - LRFinder: lr = 0.04057396 \n",
            "40448/50000 [=======================>......] - ETA: 8s - loss: 1.6683 - acc: 0.4064 - LRFinder: lr = 0.04254671 \n",
            "40960/50000 [=======================>......] - ETA: 8s - loss: 1.6657 - acc: 0.4073 - LRFinder: lr = 0.04461538 \n",
            "41472/50000 [=======================>......] - ETA: 7s - loss: 1.6629 - acc: 0.4079 - LRFinder: lr = 0.04678462 \n",
            "41984/50000 [========================>.....] - ETA: 7s - loss: 1.6599 - acc: 0.4088 - LRFinder: lr = 0.04905934 \n",
            "42496/50000 [========================>.....] - ETA: 6s - loss: 1.6572 - acc: 0.4096 - LRFinder: lr = 0.05144465 \n",
            "43008/50000 [========================>.....] - ETA: 6s - loss: 1.6529 - acc: 0.4107 - LRFinder: lr = 0.05394594 \n",
            "43520/50000 [=========================>....] - ETA: 5s - loss: 1.6499 - acc: 0.4116 - LRFinder: lr = 0.05656885 \n",
            "44032/50000 [=========================>....] - ETA: 5s - loss: 1.6476 - acc: 0.4124 - LRFinder: lr = 0.05931928 \n",
            "44544/50000 [=========================>....] - ETA: 4s - loss: 1.6444 - acc: 0.4139 - LRFinder: lr = 0.06220344 \n",
            "45056/50000 [==========================>...] - ETA: 4s - loss: 1.6410 - acc: 0.4149 - LRFinder: lr = 0.06522784 \n",
            "45568/50000 [==========================>...] - ETA: 3s - loss: 1.6397 - acc: 0.4155 - LRFinder: lr = 0.06839928 \n",
            "46080/50000 [==========================>...] - ETA: 3s - loss: 1.6378 - acc: 0.4164 - LRFinder: lr = 0.07172492 \n",
            "46592/50000 [==========================>...] - ETA: 3s - loss: 1.6351 - acc: 0.4171 - LRFinder: lr = 0.07521226 \n",
            "47104/50000 [===========================>..] - ETA: 2s - loss: 1.6334 - acc: 0.4179 - LRFinder: lr = 0.07886916 \n",
            "47616/50000 [===========================>..] - ETA: 2s - loss: 1.6303 - acc: 0.4187 - LRFinder: lr = 0.08270385 \n",
            "48128/50000 [===========================>..] - ETA: 1s - loss: 1.6280 - acc: 0.4195 - LRFinder: lr = 0.08672500 \n",
            "48640/50000 [============================>.] - ETA: 1s - loss: 1.6255 - acc: 0.4203 - LRFinder: lr = 0.09094166 \n",
            "49152/50000 [============================>.] - ETA: 0s - loss: 1.6238 - acc: 0.4208 - LRFinder: lr = 0.09536334 \n",
            "49664/50000 [============================>.] - ETA: 0s - loss: 1.6209 - acc: 0.4220 - LRFinder: lr = 0.10000000 \n",
            " - LRFinder: lr = 0.10486210 \n",
            "50000/50000 [==============================] - 48s 968us/step - loss: 1.6205 - acc: 0.4222\n",
            "\tLR Finder : Saved the losses and learning rate values in path : {/content/gdrive/My Drive/Weights/13-v0.1weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa20238bc18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edC6e0Tk2Nf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training with OneCycleLR\n",
        "from clr import OneCycleLR\n",
        "\n",
        "lr_manager = OneCycleLR(num_samples=num_train, num_epoch, batch_size=BATCH_SIZE, max_lr,\n",
        "                        end_percentage=0.1, scale_percentage=None,\n",
        "                        maximum_momentum=0.95, minimum_momentum=0.85)\n",
        "                        \n",
        "model.fittrain_features, train_labels, epochs=EPOCHS, batch_size==BATCH_SIZE, callbacks=[model_checkpoint, lr_manager])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4P4boW8xtEk",
        "colab_type": "text"
      },
      "source": [
        "Data augmentation and input pipeline. In DavidNet, training images go through the standard Cifar10 transformations, that is, pad 4 pixels to 40×40, crop back to 32×32, and randomly flip left and right. In addition, it applies the popular Cutout augmentation as a regularization measure, which alleviates overfitting. Cutout is a bit tricky to implement in Tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sxEiJYLxoM5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Applying data augmentation\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXhPEBVtyAvJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tG3bKAByBfe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Testing Model"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}