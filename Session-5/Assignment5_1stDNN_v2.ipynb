{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment5-1stDNN_v2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "# **1st DNN for assignment 5**\n",
        "\n",
        "**Task**\n",
        "\n",
        "* Change the code 8 or your own 4th Code from Assignment 4 to include:\n",
        "  1. image normalization\n",
        "  2. L2 regularization\n",
        "  3. ReLU after BN\n",
        "\n",
        "* Run your new code for 40 epochs and save the model with highest validation accuracy\n",
        "* Find out 25 misclassified images from the validation dataset and create an image gallery\n",
        "* Submit\n",
        " \n",
        "\n",
        "**This is version 2 for code picked from Assignment5-1stDNN_v1  **\n",
        "\n",
        "Version 1: Adding Inage Normalization\n",
        "**Version 2 L2 Reg**\n",
        "Version 3 Relu after BN\n",
        "Version 4 Tuning and saving model for highers accuracy\n",
        "Version 5 Finding 25 missclassified images\n",
        "\n",
        "\n",
        "*Result*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8FDs1Hx0-o0",
        "colab_type": "text"
      },
      "source": [
        "installing and Importing Keras for current solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-qhHUhK1Ggp",
        "colab_type": "text"
      },
      "source": [
        "Importing Numpy and Keras modules as well as mnist data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxPvMT_21Mhy",
        "colab_type": "text"
      },
      "source": [
        "Loading mnist data set in train and test variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SMpZZpo1Sv0",
        "colab_type": "text"
      },
      "source": [
        "Ploting sample from train data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "0ebd17bf-b116-47ee-f89d-1bdb1312a175",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7543f7fe80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1AM8Fy81X1n",
        "colab_type": "text"
      },
      "source": [
        "Reshaping all train and test data to a uniform size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjr4ODS81eUc",
        "colab_type": "text"
      },
      "source": [
        "Regularizing train and test data for float data type and division wiht 255"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDZ-v1na1okY",
        "colab_type": "text"
      },
      "source": [
        "Visualizing train out put"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "77ef114d-58af-4d05-adfc-53bf0d6a86eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCLqRA3o1wFq",
        "colab_type": "text"
      },
      "source": [
        "Convert 1-dimensional class arrays to 10-dimensional class matrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXmnovfn1yew",
        "colab_type": "text"
      },
      "source": [
        "Viewing tranformed train out put matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "4429e205-8164-495a-ee0b-803bdd3fb0ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "Y_train[:10]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlpFjyqJyhCW",
        "colab_type": "text"
      },
      "source": [
        "Adding Image normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXG-3PuRyfkr",
        "colab_type": "code",
        "outputId": "3669cd36-f6e6-4d45-f670-a7f8f4671729",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# standardizing a image dataset\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "'''\n",
        "# load dataset\n",
        "(trainX, trainy), (testX, testy) = mnist.load_data()\n",
        "# reshape dataset to have a single channel\n",
        "width, height, channels = trainX.shape[1], trainX.shape[2], 1\n",
        "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\n",
        "testX = testX.reshape((testX.shape[0], width, height, channels))\n",
        "'''\n",
        "\n",
        "# report pixel means and standard deviations\n",
        "print('Statistics train=%.3f (%.3f), test=%.3f (%.3f)' % (X_train.mean(), X_train.std(), X_test.mean(), Y_test.std()))\n",
        "# create generator that centers pixel values\n",
        "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "# calculate the mean on the training dataset\n",
        "datagen.fit(X_train)\n",
        "print('Data Generator mean=%.3f, std=%.3f' % (datagen.mean, datagen.std))\n",
        "# demonstrate effect on a single batch of samples\n",
        "train_iterator = datagen.flow(X_train, Y_train, batch_size=64)\n",
        "\n",
        "# get batch iterator for validation\n",
        "validation_generator = datagen.flow(X_test, Y_test)\n",
        "\n",
        "\n",
        "# get a batch\n",
        "batchX, batchy = train_iterator.next()\n",
        "# pixel stats in the batch\n",
        "print(batchX.shape, batchX.mean(), batchX.std())\n",
        "# demonstrate effect on entire training dataset\n",
        "train_iterator1 = datagen.flow(X_train, Y_train, batch_size=len(X_train), shuffle=False)\n",
        "# get a batch\n",
        "batchX, batchy = train_iterator1.next()\n",
        "# pixel stats in the batch\n",
        "print(batchX.shape, batchX.mean(), batchX.std())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Statistics train=0.131 (0.308), test=0.133 (0.300)\n",
            "Data Generator mean=0.131, std=0.308\n",
            "(64, 28, 28, 1) 0.005542551 1.0063723\n",
            "(60000, 28, 28, 1) -4.9324944e-07 0.9999959\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2PFtTZq127m",
        "colab_type": "text"
      },
      "source": [
        "Carrying model arch from Assignment5-1stDNN_v1\n",
        "Addubg L2 regullarization: tried with 0.01 weight and based on reviews on article in following link setting weight for L2 reg to 0.00001 which seems to be fairing well for the training. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osKqT73Q9JJB",
        "colab_type": "code",
        "outputId": "b1767293-9b3f-4f60-f17d-112c7bf88c3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "from keras.layers import Activation, BatchNormalization\n",
        "\n",
        "# Importing library for L2 regularization\n",
        "from keras.regularizers import l2\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#Vanilla\n",
        "''' \n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Convolution2D(10, 1, activation='relu'))\n",
        "model.add(Convolution2D(10, 26))\n",
        "'''\n",
        "\n",
        "#1st version \n",
        "'''\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 26,26 #RF 3X3\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 24,24 #RF 7X7\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 22,22 #RF 9X9\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 20,20 #RF 11X11\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 18,18 #RF 13X13\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 16,16 #RF 15X15\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 14,14 #RF 17X17\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Convolution2D(4, 3, 3, activation='relu')) #input 12,12 #RF 19X19\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(10, 1)) #input 10,10 \n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(10, 10)) #input 10,10\n",
        "'''\n",
        "\n",
        "#2nd version \n",
        "'''\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) #input 26,26 #RF 3X3\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) #input 24,24 #RF 7X7\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) #input 22,22 #RF 14X14\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 11,11 #RF 16X16\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu')) #input 9,9\n",
        "model.add(Convolution2D(10, 9)) #input 9X9\n",
        "'''\n",
        "\n",
        "#3rd version \n",
        "''''''\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', input_shape=(28,28,1), kernel_regularizer=l2(0.00001)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', kernel_regularizer=l2(0.00001))) #input 26,26 #RF 3X3\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) #input 24,24 #RF 6X6\n",
        "\n",
        "model.add(Convolution2D(12, 3, 3, activation='relu', kernel_regularizer=l2(0.00001))) #input 12,12 #RF 8X8\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu')) #input 10,10\n",
        "model.add(Convolution2D(10, 10)) #input 10,10\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:79: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", input_shape=(28, 28, 1..., kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:84: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:89: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), activation=\"relu\", kernel_regularizer=<keras.reg...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1mq9MtB2GgQ",
        "colab_type": "text"
      },
      "source": [
        "Printing model summary to understand current paramaters for the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzdAYg1k9K7Z",
        "colab_type": "code",
        "outputId": "d2b7cd47-9e64-43db-9a6c-f587588d54b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_27 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 24, 24, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 12, 12, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 10, 10, 12)        1740      \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 10, 10, 12)        48        \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 10, 10, 12)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 10, 10, 10)        130       \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 1, 1, 10)          10010     \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 14,536\n",
            "Trainable params: 14,448\n",
            "Non-trainable params: 88\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlnhdT4u2Owz",
        "colab_type": "text"
      },
      "source": [
        "Setting model's compile environment with loss function, optimizer and matrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6SuGrL9M3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam, SGD\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.01 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer=Adam(lr=0.01),\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06jT2a0t2Vpj",
        "colab_type": "text"
      },
      "source": [
        "Training model for 50 epoch for 128 batch size\n",
        "Replacing training images with batchX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xWoKhPY9Of5",
        "colab_type": "code",
        "outputId": "06c73d2f-35ae-4a58-8424-ca086962c53b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3417
        }
      },
      "source": [
        "#history = model.fit(X_train, Y_train, batch_size=128, nb_epoch=50, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])\n",
        "\n",
        "\n",
        "#Fit gen for normalized image gen \n",
        "\n",
        "history = model.fit_generator(train_iterator, steps_per_epoch=len(train_iterator), epochs=50, callbacks=[LearningRateScheduler(scheduler, verbose=1)], verbose=1, validation_data=validation_generator,\n",
        "        validation_steps=len(validation_generator))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.01.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.1395 - acc: 0.9578 - val_loss: 0.0593 - val_acc: 0.9799\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0075815011.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0599 - acc: 0.9821 - val_loss: 0.0413 - val_acc: 0.9874\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0061050061.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0503 - acc: 0.9850 - val_loss: 0.0365 - val_acc: 0.9899\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.005109862.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0417 - acc: 0.9871 - val_loss: 0.0442 - val_acc: 0.9870\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0043936731.\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0395 - acc: 0.9886 - val_loss: 0.0375 - val_acc: 0.9884\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0038535645.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0354 - acc: 0.9899 - val_loss: 0.0377 - val_acc: 0.9884\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.003431709.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0310 - acc: 0.9912 - val_loss: 0.0360 - val_acc: 0.9898\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0030931024.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0297 - acc: 0.9914 - val_loss: 0.0342 - val_acc: 0.9904\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0028153153.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0281 - acc: 0.9920 - val_loss: 0.0357 - val_acc: 0.9899\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0025833118.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0249 - acc: 0.9927 - val_loss: 0.0324 - val_acc: 0.9917\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0023866348.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0250 - acc: 0.9931 - val_loss: 0.0334 - val_acc: 0.9918\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0022177866.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0236 - acc: 0.9935 - val_loss: 0.0335 - val_acc: 0.9912\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.002071251.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0223 - acc: 0.9939 - val_loss: 0.0324 - val_acc: 0.9920\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0019428793.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0207 - acc: 0.9945 - val_loss: 0.0343 - val_acc: 0.9910\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0018294914.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0199 - acc: 0.9947 - val_loss: 0.0348 - val_acc: 0.9905\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0017286085.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0194 - acc: 0.9947 - val_loss: 0.0357 - val_acc: 0.9913\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.00163827.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0181 - acc: 0.9952 - val_loss: 0.0318 - val_acc: 0.9927\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0015569049.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0174 - acc: 0.9953 - val_loss: 0.0349 - val_acc: 0.9909\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0014832394.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0165 - acc: 0.9957 - val_loss: 0.0322 - val_acc: 0.9923\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.00141623.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0159 - acc: 0.9958 - val_loss: 0.0350 - val_acc: 0.9920\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0013550136.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0162 - acc: 0.9958 - val_loss: 0.0364 - val_acc: 0.9916\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.00129887.\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0154 - acc: 0.9960 - val_loss: 0.0375 - val_acc: 0.9914\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0012471938.\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 0.0152 - acc: 0.9962 - val_loss: 0.0367 - val_acc: 0.9919\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0011994722.\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 0.0150 - acc: 0.9962 - val_loss: 0.0359 - val_acc: 0.9924\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.001155268.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0146 - acc: 0.9958 - val_loss: 0.0349 - val_acc: 0.9923\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0011142061.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0136 - acc: 0.9963 - val_loss: 0.0366 - val_acc: 0.9914\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.001075963.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0141 - acc: 0.9962 - val_loss: 0.0348 - val_acc: 0.9919\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.001040258.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0136 - acc: 0.9965 - val_loss: 0.0356 - val_acc: 0.9925\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.0010068466.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0134 - acc: 0.9966 - val_loss: 0.0393 - val_acc: 0.9920\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0009755146.\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0123 - acc: 0.9968 - val_loss: 0.0341 - val_acc: 0.9935\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0009460738.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0135 - acc: 0.9967 - val_loss: 0.0371 - val_acc: 0.9925\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.000918358.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0118 - acc: 0.9969 - val_loss: 0.0380 - val_acc: 0.9918\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.0008922198.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0119 - acc: 0.9969 - val_loss: 0.0359 - val_acc: 0.9917\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0008675284.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0115 - acc: 0.9970 - val_loss: 0.0413 - val_acc: 0.9918\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.0008441668.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0114 - acc: 0.9971 - val_loss: 0.0333 - val_acc: 0.9929\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0008220304.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0116 - acc: 0.9970 - val_loss: 0.0388 - val_acc: 0.9927\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0008010253.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0110 - acc: 0.9971 - val_loss: 0.0353 - val_acc: 0.9928\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0007810669.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0112 - acc: 0.9974 - val_loss: 0.0405 - val_acc: 0.9917\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.000762079.\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0113 - acc: 0.9970 - val_loss: 0.0357 - val_acc: 0.9932\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0007439923.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0108 - acc: 0.9974 - val_loss: 0.0403 - val_acc: 0.9926\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0007267442.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0104 - acc: 0.9974 - val_loss: 0.0417 - val_acc: 0.9924\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0007102777.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0103 - acc: 0.9976 - val_loss: 0.0349 - val_acc: 0.9928\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0006945409.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0110 - acc: 0.9971 - val_loss: 0.0426 - val_acc: 0.9915\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0006794863.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0106 - acc: 0.9975 - val_loss: 0.0390 - val_acc: 0.9927\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0006650705.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0091 - acc: 0.9978 - val_loss: 0.0415 - val_acc: 0.9915\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0006512537.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0092 - acc: 0.9979 - val_loss: 0.0438 - val_acc: 0.9921\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0006379992.\n",
            "938/938 [==============================] - 10s 10ms/step - loss: 0.0094 - acc: 0.9979 - val_loss: 0.0386 - val_acc: 0.9919\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0006252736.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0099 - acc: 0.9976 - val_loss: 0.0388 - val_acc: 0.9924\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0006130456.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0097 - acc: 0.9977 - val_loss: 0.0363 - val_acc: 0.9926\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.0006012868.\n",
            "938/938 [==============================] - 9s 10ms/step - loss: 0.0091 - acc: 0.9976 - val_loss: 0.0393 - val_acc: 0.9922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_0_UAU1M1wP",
        "colab_type": "text"
      },
      "source": [
        "Plotting training and validation accuracty as well as loss for every epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tvptcn8dxvp",
        "colab_type": "code",
        "outputId": "8d41183f-7ab7-4c34-e391-e4ad3ff2a5d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#history = model.fit(x, y, validation_split=0.25, epochs=50, batch_size=16, verbose=1)\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmAaxQGKMMaZBLJAYY4xpkP8Pv5GXi5fBUBUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd8lfXZ+PHPlZO9CAkJK4EgoAii\nKBHqqAP3qBO3dVSldtk+fexT+vzaOlpb7dOnrVUeF+JWRK3VunCvikyRvQUSVkIG2ePkXL8/vnfg\ncHIygJwkJNf79crrnHOPc193CPd1f8f9/YqqYowxxrQmqqsDMMYY0/1ZsjDGGNMmSxbGGGPaZMnC\nGGNMmyxZGGOMaZMlC2OMMW2yZGHMARCRXBFREYlux7Y3iMjnB/o9xnQFSxam1xCRjSJSLyL9QpZ/\n5V2oc7smMmO6P0sWprf5Briq6YOIjAUSuy4cYw4OlixMb/MMcF3Q5+uBp4M3EJE+IvK0iBSJyCYR\n+bWIRHnrfCLyZxHZKSIbgPPC7Pu4iGwTkS0i8nsR8e1rkCIySEReF5ESEVknIrcErZsgIgtEpFxE\ndojIX7zl8SLyrIgUi0iZiMwXkf77emxjwrFkYXqbL4FUETncu4hfCTwbss0DQB/gEOBkXHK50Vt3\nC3A+cDSQB0wO2fdJwA+M8LY5E7h5P+KcCRQAg7xj/EFEJnnr7gfuV9VUYDgwy1t+vRd3DpAB3ArU\n7MexjWnGkoXpjZpKF2cAK4EtTSuCEsivVLVCVTcC/wt819vkcuBvqpqvqiXAH4P27Q+cC/xMVatU\ntRD4q/d97SYiOcAJwC9VtVZVFwPT2VMiagBGiEg/Va1U1S+DlmcAI1S1UVUXqmr5vhzbmJZYsjC9\n0TPA1cANhFRBAf2AGGBT0LJNwGDv/SAgP2Rdk6Hevtu8aqAy4BEgax/jGwSUqGpFCzHcBBwKrPKq\nms4POq/ZwEwR2SoifxKRmH08tjFhWbIwvY6qbsI1dJ8L/CNk9U7cHfrQoGVD2FP62Iar5gle1yQf\nqAP6qWqa95OqqmP2McStQLqIpISLQVXXqupVuCR0H/CyiCSpaoOq3qWqo4HjcdVl12FMB7BkYXqr\nm4BJqloVvFBVG3FtAPeISIqIDAV+zp52jVnAbSKSLSJ9galB+24D3gX+V0RSRSRKRIaLyMn7Epiq\n5gNfAH/0Gq2P9OJ9FkBErhWRTFUNAGXebgEROVVExnpVaeW4pBfYl2Mb0xJLFqZXUtX1qrqghdU/\nAaqADcDnwPPADG/dY7iqnq+BRTQvmVwHxAIrgFLgZWDgfoR4FZCLK2W8Ctyhqu97684GlotIJa6x\n+0pVrQEGeMcrx7XFfIKrmjLmgIlNfmSMMaYtVrIwxhjTJksWxhhj2mTJwhhjTJssWRhjjGlTjxkO\nuV+/fpqbm9vVYRhjzEFl4cKFO1U1s63tekyyyM3NZcGClnpCGmOMCUdENrW9lVVDGWOMaQdLFsYY\nY9pkycIYY0ybekybRTgNDQ0UFBRQW1vb1aF0mvj4eLKzs4mJscFGjTEdJ6LJQkTOxo1d4wOmq+q9\nIetPAv4GHIkb3+blkPWpuDF2/qmqP97X4xcUFJCSkkJubi4isr+ncdBQVYqLiykoKGDYsGFdHY4x\npgeJWDWUN/LlNOAcYDRwlYiMDtlsM25Ogedb+JrfAZ/ubwy1tbVkZGT0ikQBICJkZGT0qpKUMaZz\nRLLNYgKwTlU3qGo9bprIC4M3UNWNqrqEMMMoi8h4oD9uyOf91lsSRZPedr7GmM4RyWQxmL1nFCtg\nz0xfrRKRKNxUlrdHIK69NAYCbC+vpbreH+lDGWPMQau79ob6IfCWqha0tpGITBGRBSKyoKioaL8O\npAqF5bVU1zXu1/6tKS4uZty4cYwbN44BAwYwePDg3Z/r6+vb9R033ngjq1ev7vDYjDFmX0SygXsL\ne08/mc2eqSnbchzwbRH5IZAMxIpIpapODd5IVR8FHgXIy8vbr4k5oqJctU1jBOb1yMjIYPHixQDc\neeedJCcnc/vtexeWVBVVJSoqfN5+4oknOjwuY4zZV5EsWcwHRorIMBGJBa4EXm/Pjqp6jaoOUdVc\nXFXU06GJoqNEiSAiBDpxEqh169YxevRorrnmGsaMGcO2bduYMmUKeXl5jBkzhrvvvnv3tieeeCKL\nFy/G7/eTlpbG1KlTOeqoozjuuOMoLCzstJiNMb1bxEoWquoXkR/jpqD0ATNUdbmI3A0sUNXXReRY\n3JSRfYHviMhd+zG5fbvc9a/lrNhaHnZddb2f6KgoYqP3LXeOHpTKHd/Zv3BXrVrF008/TV5eHgD3\n3nsv6enp+P1+Tj31VCZPnszo0Xt3Htu1axcnn3wy9957Lz//+c+ZMWMGU6dGJIcaY8xeIvqchaq+\nBbwVsuy3Qe/n46qnWvuOJ4EnIxBeEKGzJ5cdPnz47kQB8MILL/D444/j9/vZunUrK1asaJYsEhIS\nOOeccwAYP348n332WafGbIzpvXr0E9zBWisBrNlRQawvitx+SZ0WT1LSnmOtXbuW+++/n3nz5pGW\nlsa1114b9lmJ2NjY3e99Ph9+v/XgMsZ0ju7aG6pT+Tq5zSJUeXk5KSkppKamsm3bNmbPnt1lsRhj\nTDi9pmTRmqgowR9o9lxgpznmmGMYPXo0o0aNYujQoZxwwgldFosxxoQj2oV31B0pLy9PQyc/Wrly\nJYcffnib+24qrqK2IcBhA1IiFV6nau95G2OMiCxU1by2trNqKLq+GsoYY7o7Sxa4aqhAwJKFMca0\nxJIF7sG8Ru9JamOMMc1ZsgB83m/BChfGGBOeJQtcyQKwdgtjjGmBJQuCBhO0ooUxxoRlyQLXGwo6\nvmTREUOUA8yYMYPt27d3aGzGGLMv7KE8wCtYdHiPqPYMUd4eM2bM4JhjjmHAgAEdGp8xxrSXJQv2\nVEN1Zi3UU089xbRp06ivr+f444/nwQcfJBAIcOONN7J48WJUlSlTptC/f38WL17MFVdcQUJCAvPm\nzdtrjChjjOkMvSdZvD0Vti8NuypelUPqG4mLiYIWJiEKa8BYOOfefQ5l2bJlvPrqq3zxxRdER0cz\nZcoUZs6cyfDhw9m5cydLl7o4y8rKSEtL44EHHuDBBx9k3Lhx+3wsY4zpCL0nWbTGq4bqrHHK33//\nfebPn797iPKamhpycnI466yzWL16NbfddhvnnXceZ555ZucEZIwxbeg9yaKVEoAGlA1bdzGgTzxZ\nKfERD0VV+d73vsfvfve7ZuuWLFnC22+/zbRp03jllVd49NFHIx6PMca0xXpDEdzA3TnHO/3005k1\naxY7d+4EXK+pzZs3U1RUhKpy2WWXcffdd7No0SIAUlJSqKio6JzgjDEmjN5TsmiFiHTqYIJjx47l\njjvu4PTTTycQCBATE8PDDz+Mz+fjpptuQlUREe677z4AbrzxRm6++WZr4DbGdBkborxp223lpMRF\nk52eGInwOpUNUW6MaS8bonwfNQ0maIwxpjlLFh5flA0kaIwxLenxyaK91WxRIj1ibKieUq1ojOle\nIposRORsEVktIutEZGqY9SeJyCIR8YvI5KDl40RkjogsF5ElInLF/hw/Pj6e4uLidl1Ao3rAbHmq\nSnFxMfHxke/+a4zpXSLWG0pEfMA04AygAJgvIq+r6oqgzTYDNwChAyZVA9ep6loRGQQsFJHZqlq2\nLzFkZ2dTUFBAUVFRm9uWVNVT7w/QWHJwX2jj4+PJzs7u6jCMMT1MJLvOTgDWqeoGABGZCVwI7E4W\nqrrRW7fXEw6quibo/VYRKQQygX1KFjExMQwbNqxd2/7mn8t4Y8kOvvqtPTVtjDGhIlkNNRjID/pc\n4C3bJyIyAYgF1odZN0VEFojIgvaUHlqTFBdNZZ3/gL7DGGN6qm7dwC0iA4FngBtVtdnz1ar6qKrm\nqWpeZmbmAR0rOc5HQ6NS5288oO8xxpieKJLJYguQE/Q521vWLiKSCrwJ/D9V/bKDY2smKc7VyFXV\nWbIwxphQkUwW84GRIjJMRGKBK4HX27Ojt/2rwNOq+nIEY9xtT7KwqihjjAkVsWShqn7gx8BsYCUw\nS1WXi8jdInIBgIgcKyIFwGXAIyKy3Nv9cuAk4AYRWez9RHQyh2QvWVi7hTHGNBfRgQRV9S3grZBl\nvw16Px9XPRW637PAs5GMLVSylSyMMaZF3bqBuzM1VUNVWLIwxphmLFl4rGRhjDEts2ThSYrzAZYs\njDEmHEsWnj0N3NZ11hhjQlmy8FjXWWOMaZklC0+ML4q46ChLFsYYE4YliyDJcdHWG8oYY8KwZBEk\nKS7aShbGGBOGJYsgliyMMSY8SxZBkuN8NtyHMcaEYckiiCtZWNdZY4wJZckiSLJVQxljTFiWLIIk\n22x5xhgTliWLIDa1qjHGhGfJIkhSXDTV9Y0EAtrVoRhjTLdiySJIctNggvVWujDGmGCWLILYPNzG\nGBOeJYsgNrWqMcaEZ8kiiE2AZIwx4VmyCJJkJQtjjAnLkkUQq4YyxpjwIposRORsEVktIutEZGqY\n9SeJyCIR8YvI5JB114vIWu/n+kjG2cQmQDLGmPAilixExAdMA84BRgNXicjokM02AzcAz4fsmw7c\nAUwEJgB3iEjfSMXaxObhNsaY8CJZspgArFPVDapaD8wELgzeQFU3quoSIBCy71nAe6paoqqlwHvA\n2RGMFYCUuBjA5uE2xphQkUwWg4H8oM8F3rIO21dEpojIAhFZUFRUtN+BNomPiSJKrGRhjDGhDuoG\nblV9VFXzVDUvMzPzgL9PRGx8KGOMCSOSyWILkBP0OdtbFul9D4iNPGuMMc1FMlnMB0aKyDARiQWu\nBF5v576zgTNFpK/XsH2mtyzibGpVY4xpLmLJQlX9wI9xF/mVwCxVXS4id4vIBQAicqyIFACXAY+I\nyHJv3xLgd7iEMx+421sWcVYNZYwxzUVH8stV9S3grZBlvw16Px9XxRRu3xnAjEjGF06KlSyMMaaZ\ng7qBOxKS4nw26qwxxoSwZBHCqqGMMaY5SxYhrDeUMcY0Z8kiRFNvKFWbWtUYY5pYsgiRHBeNP6DU\n+UNHIDHGmN7LkkUImwDJGGOas2QRwubhNsaY5ixZhEj2himvqGvo4kiMMab7sGQRwkoWxhjTnCWL\nEDZbnjHGNGfJIoTNw22MMc1ZsghhvaGMMaY5SxYhkqxkYYwxzViyCJEU63pDWbIwxpg9LFmEiPZF\nER8TZdVQxhgTxJJFGG4wQes6a4wxTSxZhGFTqxpjzN4sWYSRbMnCGGP2YskiDJsAyRhj9mbJIgyb\nAMkYY/ZmySIMa7Mwxpi9RTRZiMjZIrJaRNaJyNQw6+NE5EVv/VwRyfWWx4jIUyKyVERWisivIhln\nqOQ4n/WGMsaYIBFLFiLiA6YB5wCjgatEZHTIZjcBpao6AvgrcJ+3/DIgTlXHAuOB7zclks6QFGsl\nC2OMCRbJksUEYJ2qblDVemAmcGHINhcCT3nvXwZOExEBFEgSkWggAagHyiMY616S46OpaWikMWDz\ncBtjDEQ2WQwG8oM+F3jLwm6jqn5gF5CBSxxVwDZgM/BnVS2JYKx72T2YYL2VLowxBtqZLERkuIjE\nee9PEZHbRCQtgnFNABqBQcAw4D9F5JAwcU0RkQUisqCoqKjDDr57MMFaSxbGGAPtL1m8AjSKyAjg\nUSAHeL6NfbZ42zXJ9paF3carcuoDFANXA++oaoOqFgL/BvJCD6Cqj6pqnqrmZWZmtvNU2mYTIBlj\nzN7amywCXjXRxcADqvoLYGAb+8wHRorIMBGJBa4EXg/Z5nXgeu/9ZOBDVVVc1dMkABFJAr4FrGpn\nrAesaR5ue9bCGGOc9iaLBhG5Cndhf8NbFtPaDl5y+TEwG1gJzFLV5SJyt4hc4G32OJAhIuuAnwNN\n3WunAckishyXdJ5Q1SXtPakDlRRr83AbY0yw6HZudyNwK3CPqn4jIsOAZ9raSVXfAt4KWfbboPe1\nuG6yoftVhlveWZLjbQIkY4wJ1q5koaorgNsARKQvkKKq97W+18HLplY1xpi9tbc31Mcikioi6cAi\n4DER+UtkQ+s6SdZ11hhj9tLeNos+qloOXAI8raoTgdMjF1bXaipZVFjXWWOMAdqfLKJFZCBwOXsa\nuHusuOgofFFi1VDGGONpb7K4G9erab2qzvcekFsbubC6loiQFOuzZGGMMZ72NnC/BLwU9HkDcGmk\nguoObB5uY4zZo70N3Nki8qqIFHo/r4hIdqSD60rJ8TbyrDHGNGlvNdQTuKetB3k///KW9VhJcdHW\nG8oYYzztTRaZqvqEqvq9nyeBjhuMqRtKjou23lDGGONpb7IoFpFrRcTn/VyLG/Cvx7IJkIwxZo/2\nJovv4brNbsfNMTEZuCFCMXULNg+3Mcbs0a5koaqbVPUCVc1U1SxVvYge3xvKZ2NDGWOM50Bmyvt5\nh0XRDSXHR1NV34gbMd0YY3q3A0kW0mFRdENJcdE0BpQ6f6CrQzHGmC53IMmiR99y2/hQxhizR6tP\ncItIBeGTggAJEYmom9gzAZKfzJS4Lo7GGGO6VqvJQlVTOiuQ7qZpmHJr5DbGmAOrhurRbAIkY4zZ\nw5JFC5qmVrUhP4wxxpJFi5LjfAA28qwxxmDJokW72yysN5QxxliyaEmStVkYY8xuEU0WInK2iKwW\nkXUiMjXM+jgRedFbP1dEcoPWHSkic0RkuYgsFZH4SMYaqqnrrPWGMsaYCCYLEfEB04BzgNHAVSIy\nOmSzm4BSVR0B/BW4z9s3GngWuFVVxwCnAA2RijUcX5SQEGNTqxpjDES2ZDEBWKeqG1S1HpgJXBiy\nzYXAU977l4HTRESAM4Elqvo1gKoWq2qntzQnx0dbycIYY4hsshgM5Ad9LvCWhd1GVf3ALiADOBRQ\nEZktIotE5L/CHUBEpojIAhFZUFRUtH9R7toCD50Ay/7RbNWoASl8uqYIf6OND2WM6d26awN3NHAi\ncI33erGInBa6kao+qqp5qpqXmbmfE/clZ0HJBtj8ZbNV1x2Xy9Zdtby7Ysf+fbcxxvQQkUwWW4Cc\noM/Z3rKw23jtFH1wM/AVAJ+q6k5VrQbeAo6JSJS+GBg8HvLnNls1aVQWOekJPPnvjRE5tDHGHCwi\nmSzmAyNFZJiIxAJXAq+HbPM6cL33fjLwoboJJGYDY0Uk0UsiJwMrIhZpzkTYvhTqq/Za7IsSrj8u\nl3kbS1i2ZVfEDm+MMd1dxJKF1wbxY9yFfyUwS1WXi8jdInKBt9njQIaIrMNNpjTV27cU+Asu4SwG\nFqnqm5GKlZyJoI2wZWGzVZfl5ZAQ4+OpLzZG7PDGGNPdtTrq7IFS1bdwVUjBy34b9L4WuKyFfZ/F\ndZ+NvOw895o/F4adtNeqPgkxXDp+MLMWFDD1nFFkJNtw5caY3qe7NnB3rsR0yBwF+fPCrr7h+Fzq\n/QFmzs8Pu94YY3o6SxZNcia4ZBFo3k12RFYK3x7Zj2fmbKLButEaY3ohSxZNciZCbRkUrw27+sYT\nctleXss7y7Z3cmDGGNP1LFk0yZnoXsM8bwFwyqFZDM1I5Elr6DbG9EKWLJpkjICE9BbbLaK8brQL\nN5WypKCsk4MzxpiuZcmiiYgrXYR5OK/J5LxskmJ9VrowxvQ6liyC5UxwbRZVxWFXp8bHMHl8Nm98\nvY2iirpODs4YY7qOJYtgTe0WBeGrogCuOz6X+sYAL8zb3ElBGWNM17NkEWzQ0RAV3WpV1PDMZE4+\nNJOn52yitsHm5zbG9A6WLILFJsLAo1ps5G7y/ZMPYWdlHS8tLOikwIwxpmtZsgiVM9GNEdXY8sR8\nxx2SwdFD0njkk/U214UxplewZBEqZwL4a2H7khY3ERF+eMoICkpr+NeSrZ0YnDHGdA1LFqF2P5zX\ncrsFwGmjsji0fzIPfbyeQEA7ITBjjOk6lixCpQ6CPkNabeQG95DeD08ZwZodlXywqrCTgjPGmK5h\nySKcnAkuWWjrJYbzjxxITnoC0z5ah7axrTHGHMwsWYSTMxEqtsGu1ns7RfuimHLScBbnlzFnQ/gH\n+YwxpiewZBFOzgT32kZVFMBl47PplxzHQx+vj3BQxhjTdSxZhNP/CIhJaleyiI/xcfO3h/HZ2p1s\n/vhJmPYtqLQ2DGMMULQGvvmsq6PoEJYswvFFQ/b4diULgGsmDqF/vJ8+n90FRSvh3d9EOEBjTLdW\nWQRv/Af837fgqe/Auve7OqIDZsmiJTkTYfsyqKtsc9OU+Bj+PGQufRpLqBp6GiyZCRs/74QgjTEd\nrtEPS16Cmv2YiqChBj77X/j70bDwKTj2Jug/Bl6+CUo3dnioncmSRUtyJoI2uqe521JTygk7nuUj\nPYbfJ/7Sdb198/ZWnwI3xnSShtp23fTttvAJ+MfNMONsKGvngKGBAHz9IjyQBx/cDcO+DT+aC+f+\nD1zxDKDw4rVQX71fp9AdRDRZiMjZIrJaRNaJyNQw6+NE5EVv/VwRyQ1ZP0REKkXk9kjGGVb2se61\nhZnz9vL534iqK2fV6J8xc/FOpqfc6qqjvnwosjEa0xX89fD5X6G8G49e0FADK99wd/T/M9xVB9VV\ntL1fXSV8ch9kjXbnN/102Lq49X22L4XHz4BXp0BSBlz/Blz1AvQb6danHwKXTHc1FW/+vM0u+d1V\nxJKFiPiAacA5wGjgKhEZHbLZTUCpqo4A/grcF7L+L8DbkYqxVQlpMOQ4mPMgFK5sebvybTD3ERh7\nGTdcfD7fP2k4f9p4CB8ExlP/wR8o37Gp82I2pjO8+2t4/054p9n9X8dRhR3L9+3C2lALK//lJYgR\n8OI1sP5DOPRs2JUPn/yp7e/48iGoKoLv/B1umg2+WHjiXFgzu/m29VXud/HIyVC2CS56GG752JUq\nQh16JpwyFb5+AeZPb/85dSORLFlMANap6gZVrQdmAheGbHMh8JT3/mXgNBERABG5CPgGWB7BGFt3\nyWMQkwDPXd5yD6dP/wSBBjj1v0mI9TH1nFF8fPspzD3sFzQ2NvLlQ1N45JP1Npy56RmWvwrzHoG0\nIbDiNdjW8hhqB+Tje+Gh4+HD37Vv+8oiePgEV9Wz/kM44lL47qtw+xqY/Dgc/V348v+gcFXL31FV\nDP++H0adDznHQtbhcPP70G8EvHDl3hf5Ne+6no9fPABHXws/mgfjroKoVi6pJ/0XjDwL3vlVm8MJ\ndUeRTBaDgfygzwXesrDbqKof2AVkiEgy8EvgrtYOICJTRGSBiCwoKirqsMB3S8uBq2a6O40XrnJF\n22DF62HR0zD+BkgftnvxoLQE/vuac6iY8FPO5Ev+PftFTvvfT1hasKvjYzS9U205fPo/rmTbWXau\ng9d+4qpob/kI4vu4i3pHW/UmfHIvpAxyjcULn2x9+7pKeP5y2LUFrngWbl8LF/wdhk8CX4zb5vQ7\nITYZ3rq95dLK53+BhiqYFNSbMWUA3PAWjDgD3vxPeHsqzLoenr/MTWlw4zvuWInpbZ9XVBRc8gj0\nyYZZ10HFjnb8MtphxWuw4ImO+a5WdNcG7juBv6pqq61Sqvqoquapal5mZmZkIhl8DFz6mGvofvVW\n15DV5KM/uGLqSb8Iu2vWWb+AjBE8kjGTWK3n6ulf8tXm0sjEaXqPykJ48jz48PfuTtrfCVP81le7\nC5wvBi57EpL6wXE/gdVvwpZFbe8//3GY/f/ajrVoDfzj+24ish/PhxGnwxs/b7nraWMDvHQ9bFsM\nlz0Bh3/HdX0PldQPTvstbPwMlr3SfH1ZPsx7FI66GrJG7b0uLhmufB6OvRnmPgRr3nEJ5fufwdDj\n2j73YAl9XUKr3eUSzpu3u/OdeY3rYvvoKfB/x7vqsEZ/699VXw3/+qn7d1ny4t7XpgiIZLLYAuQE\nfc72loXdRkSigT5AMTAR+JOIbAR+Bvy3iPw4grG27vDvwBl3wYp/7ikWb1sCy16Gibe6u49wouPg\n3D+TULGJfx69gL6JsXz38Xks3FTiSikV22HnWus1ZdqvdBPMOMv93Rx/G2xZ4Ko19kdNmauy+eRP\n8MHvWi+lvP0LKFzhqmb7ZLtlE7/vLn4f/7H142z4xN2Vz3kQnr6oxTnuqS2HmVe7/zdXPOsu0pc9\n6RqbZ13vGpKDqcLrt7lEcv7f4LBzWo9j/A0wcJxLWqGN3R/fC4hrVwjHFw3n/tnVNPxwDpx0O0TH\ntn68lgw4Ai76P9eVdtnLsPkLKPnGdRxI7OdKLO9MhemTWu6NuWM5PHaqK3Wd8DO47vXWq8A6gERq\nADzv4r8GOA2XFOYDV6vq8qBtfgSMVdVbReRK4BJVvTzke+4EKlX1z60dLy8vTxcsWNDBZxFE1WXx\nRU/BhdNc0S9/Hvz0a9cY3pqXboRVb+DvM5RdpTtJDlQSJ0EJImUg5H0PjrkeUvpH7hxMc6pQssHd\ncW783F1As0a5p/izRkPmYe7i1R3sWAHPXOzmW7nmJTcszbu/gS/+7hpXx13V+v67ClxDbcECl2R2\nrtmzTqJcKfnYm93FJzmopP7Vc/DaD10JetKv9/7Oz//qGrtvem/PMDnBKgvh4RNdldUJP3WlhNRB\ncPUsyDx0z3aBgGuQXjMbrntt70bipl5Jqq4NoY9Xm/3B3a6a6pRftXyRD1WwEKafBsf9CM66xy0r\nXAUPHQff+uGeZV1J1d2Yvj0VKne4f5PTfuN+h6qu7WT2/3OfL3nEVbcdABFZqKp5bW4XydFSReRc\n4G+AD5ihqveIyN3AAlV9XUTigWeAo4ES4EpV3RDyHXfSHZIFuBLAc5Pd4/va6OpBT/yPtver2O7u\nrKJ8VPtS+NeqKrbUxXHht8YwfEBf94ex7n2IioExF8GEKa5e2LX1m45Wlg8bPnLJ4ZvPoMLrAprc\nH5KyYOdqaKx3y8TnukD2H+OqRgYd7abejUvZ9+MGAu4uMjoeBo/ft3/fzXNdtUV0gmu47e91LGz0\nwzMXQcF8dyEdMDb8/stecXfh9ZXu7jU7Dwbnea/HQHWJK2EsmenimzDFXdwrtsFjp7kG3+/+E6J8\ne39vXSXcf5Q77nX/bH6+z17sup/f8qH7HebPh5lXubvoy5+C4ae6bT++Dz7+A5x9H3zr1ubxb1/m\nnnvoOxRufBu+nulKO+NvcKXkb0KVAAAXZUlEQVSKffldvn4bfPUs3Pq5+z3OvAa++dTd+LWn7aGz\n1Ja7qsb5j0FSJpx2h2vPWf2mq5676OG9k/p+6hbJojN1SrIAd+c54yxXjP3xAldk3EdFFXVcM/1L\nNhVX89h1eZx0aKZrPJw/HRY/B3Xl7oI08VbXq6M9d7aBADTWud5bBwPVzk2GFTtcUl72yp5hXJIy\nIfdEyP22++k30sXU6IeS9a6ov2O5q37ZvtR1vwRA3LaDjnHJI/cEyBrTcjVATRksfh4WPA7F69yy\nQUfDxB/AmIvbrs5Y+x68+F1IHegu2H2H7r2+shAeOcn9nUz52FUNNWmohdm/ggUzIHsCXPCAKy21\n9LvfudY9Z7D0ZdcgHJcCGoBbP4PkrPD7fPGA60J649sw9Pg9yz/9H3ex+87fYfz1e5aXbYbnr4Ci\n1XDen11D9gtXwFFXwUUPtRzb+g/hucsgc5T7dznsHLj8mfBtFK2pKoYHx7t/s9PvcM9InPprODl8\n22OX27LIDR2ybbG7oTzjLve300HVTpYsIqm+2rU5JGXs91cUV9ZxzfS5bNhZxfSmhAHuTm3JizDv\nMfdgX/IAmHCLq6YKd9ezqwAWvwCLn3V3zGf9wdUld6dSSWODe1Zl29fuD37b165KZdS5rkovUtU8\nNaWu3/3Sl101kwbcBeKIS2DUee6isy+/p8oiF//Wr9zPlkVQud2tS0h3VSfDToLck1wy2b7U3RUu\neQn8NW5UgLyb3N393IddNVByf7cs73vuLjHQ6HrZbV/ifk/bl7rYs0bDta+0fMHePBeePNfdcV75\ngruQFK93jb/bl7r2jdN+u6d3UFsKV7q2iLXvwTUvu4TYkvpq+Ps46Hco3PCGW7bpC9cIP+YSuHR6\n899zbTm8/D1Y956r/so6HL43u+2bnUXPwOs/donvutf262YNcL2H3viZK0kC3PaVayPprgKN7kYn\n6/CWS4/7yZLFQaC0qp6rp89l484qnr9lIkcPCbojVHV3UnMedK8xiTDualevmjoYVr3hSiHrPwLU\n3Rn7YmH9B67f93l/6dy6dlVXlVGy3rUBFDe9rnN35k3VOrEpMPBI106z7GUYfpprzGztP32g0TVA\nrn0Xzvx9+Iee9to+4O7i37vDdYXsOwzGTnaltKzDO+6cwSXrjZ+7aowNn0C5NwdKfBrUlrl/t7GX\nuXrngUfuHeOGD+HLh4MumKNdAmnwhoSIinHx5kzcU2fdmrmPuqqZSb+G9OGuuiXKBxc/3Hbjb0sC\ngfbdwX75MLzzS9fQ2v8I104REw/f/7TlKrtGP7z3G6+d4p/u2Y32yJ/v2pX2pyqwSaDRezp7kWu4\nnnDL/n/XQc6SxUGisKKWyQ/NoaK2gZduPY4RWWH+A+xYAV9OgyWz3F16XIqrquqT4xLIuKuhb677\nj/3xH92DgtnHuotwSz21OkrJBtfNb+lL7k6+iUS5+NIPcb0/Bo5zP+mH7Ln4LHzKdRoYchxcPTP8\nxbCyEF65yV2ME9KhpsTdhZ9+F8SnNt9+VwG89iPY8LFr+Jv0G1fl0xklLVUo/cbFmj/PXTTHXd12\nB4iiNe5Bt51rXMlnwFiXWPodtm89blThH7e4fwtwfwOTn3DPC0VaQ60bPC8tx/07bvjYtaEMPCry\nx95fO9e6J6pPnrr/PZt6AEsWB5FNxVVc+tAcYn3Cyz84nkFpLRTFK3a4do2KrXDEZBh2cvi7vhWv\nwas/cBfTK55zw60HqylzF7P8ue6BQ3+tq1YLfk3u7xofh09yF/hQ+fNdL5xVb7hG4DEXuTr89EMg\nY7i7S2xPyWbZK/CPKe7C+t1X965q2/hvV1VRuwvO/wuMvgg+ugfmTHOlq+/cDyNPd9uqunaBd6a6\nu8azfg/jb+xe1XGdob4KXrrBlVIm/br91U4dYf5015EDev3d+sHEksVBZvnWXVz5yJf07xPPS98/\njr5JB3ins32Z63VSsQPOuc/d7W2eA5vmwI5lgEJUNCRmuN4v0fGu2iA6wb0Wr9/ToJs21CWOQ051\nJYY50yD/S/edeTe5njOpA/c/1jWzXQNu+iGuOiK5v0tE79/lSkxXPON60jTJn+9KDztXu4eoTvyZ\n6765+i0Ycrzrwx70RL3pJP4691DZgCNd1VdvS9QHKUsWB6E564u5/ol5jBmUynM3TyQxdh97eYSq\nKnYNnBu9mbpiklwXyCHHuydPB+e13Fag6hLGho9cm8k3n0G99yBT2hD41o9c20hHNQp+86kbUiWp\nH2QeDmvediWJCx4IX93UUOuq2z7/m+vG7ItzPVs6sJeI2Q+N/n3vnWS6lCWLg9Q7y7bzw+cW8u2R\nmUy/Po8Y3wFe+Br9bniC1IHujm9/qyUaG9zTpLXl3pg7EbggFCyAZy9xVSln3tO+Xl3bvnZPsU68\n1XUJNcbsE0sWB7GZ8zYz9R9LGTMole8cNYgzR/fnkMxu3K2vI5Vucu0moePzGGMiwpLFQe6lBfk8\nNWcjy7aUAzAyK5kzx/TnzNEDODK7D2L1wcaYDmDJoofYUlbDe8u38+6KHcz9poTGgDI4LYFLjhnM\npcdkk9svqatDNMYcxCxZ9EBl1fV8sLKQ17/eymdriwgo5A3ty+Tx2Zx35EBS4juxm6QxpkewZNHD\nbd9Vy6tfbeHlhfmsL6oiPiaK88YO4tfnHX7g3W6NMb2GJYteQlX5umAXLy3I56UFBWSlxvHId8cz\nZlAbQ0MYYwztTxbWIf0gJyKMy0njnovHMuvW4/A3Kpc+9AWvLQ6dZ8oYY/afJYseZFxOGv/6yYkc\nOTiNn85czO/fWIG/MbJTLRpjegdLFj1MZkocz90ykRuOz2X6599w3Yx5lFTVd3VYxpiDnD2X3wPF\n+KK484IxHDG4D//96lLOvf8zRvZPpqa+kZoG91Nb30itP8BR2X244tghnHZ41oE/LW6M6bEsWfRg\nk8dnc2j/ZP7w1kqq6vwkxPpIS4whPsZHQowPX5Tw0epCbn12If2S47h0/GCuyMvpPU+LG2PazXpD\n9XL+xgCfri1i5rx8PlhVSGNAmTAsnYuPHszJh2a2PFy6MaZHsK6zZp8VltfyyqItvDh/MxuL3Wxt\nI7OSOfnQTE46NJMJw9KJj/F1cZTGmI5kycLsN1VlbWEln64p4pM1RczdUEJ9Y4D4mChOHNGPy/Ny\nmDQqi2hr4zDmoNctkoWInA3cD/iA6ap6b8j6OOBpYDxQDFyhqhtF5AzgXiAWqAd+oaoftnYsSxaR\nU13vZ+6GEj5ZU8RbS7dRWFFH/9Q4Ls/L4fK8HHLSW5k/2xjTrXV5shARH7AGOAMoAOYDV6nqiqBt\nfggcqaq3isiVwMWqeoWIHA3sUNWtInIEMFtVB7d2PEsWncPfGODDVYW8MG8zH68pAuDbIzO5PC+b\nY4b0ZWCfeBsR15iDSHdIFscBd6rqWd7nXwGo6h+DtpntbTNHRKKB7UCmBgUl7spTDAxU1bqWjmfJ\novNtKath1vx8Zi3IZ9uuWgD6JMQwakAKhw9M5fCB7nVoRhJ9EmyQQ2O6o/Ymi0h2nR0M5Ad9LgAm\ntrSNqvpFZBeQAewM2uZSYFG4RCEiU4ApAEOGDOm4yE27DE5L4D/OOJTbThvJ4vxSVmwtZ+X2ClZu\nK2fWgnyq6xt3b5sSH01230Sy+yaQ3TeBnL6JHDO0L0fZ3BzGHBS69XMWIjIGuA84M9x6VX0UeBRc\nyaITQzNBfFHC+KHpjB+avntZIKBsLqlm1fZy8ktqKCitJr+0hk3FVfx73c7diWRwWgJnjRnAuWMH\ncMyQvkRFWeIwpjuKZLLYAuQEfc72loXbpsCrhuqDq3JCRLKBV4HrVHV9BOM0ERAVJeT2Swo7OZOq\nsrOynk/WFPHOsm08++UmZvz7G7JS4jjniAF8e2QmI/snk903EZ8lD2O6hUi2WUTjGrhPwyWF+cDV\nqro8aJsfAWODGrgvUdXLRSQN+AS4S1X/0Z7jWZvFwauitoEPVxXy9tLtfLS6kDq/G/wwNjqKYRlJ\njMhKZnhmEiP7pzAuJ43svglWdWVMB+nyBm4viHOBv+G6zs5Q1XtE5G5ggaq+LiLxwDPA0UAJcKWq\nbhCRXwO/AtYGfd2ZqlrY0rEsWfQM1fV+Vm6rYH1hJeuLmn6q2FRcRcD7U81MiePonDSOGdqXo3PS\nODI7jYRYe1jQmP3RLZJFZ7Jk0bPV+RtZu6OSr/LL+GpTKV/ll/HNzioARGBQnwSGZiQyNCORIelJ\nDM1IJKdvIgFVymsbKK/xe68NlNc20DcxliMG92H0oFRSbTpa04tZsjA9XklVPYvzS/k6fxebiqvY\nVFLN5uJqitsYkj1K2F1KAcjNSGTM4D4cMagPuRmJxMf6iI/2kRDrIz4mavf7pLhoEmN81ghvepTu\n0HXWmIhKT4pl0qj+TBrVf6/lFbUNbCqupqC0hthoISU+htT4GFITokmNjyEx1kdRZR3Lt5azfMsu\nlm0p5+v8Mt5csq1dx030EkdSrI+U+Bj6p8YxKC2BQWkJDOwTz+Cg99a2YnoKK1kY4ymrrmdLWQ21\nDQHqGhqp9TdS2xCg1psDpLqukco6P1V1fqrq/VTVNVJe28D2XbVsLauhvNa/1/elJ8UyITediYek\nM3FYBqMGpDQrlVTV+dlcUs3mkmpq6hvdMyjpiWQmx1kJxnQKK1kYs4/SEmNJS4zd7/0r6/xsK6th\nS1kNBaU1LNpcytwNJbyzfDvgnm4/NjedlPhoNhVXsbmkhp2V4QcliI2O2v3w4qC0BFITokmJiyY5\nLprk+BhS4l0paczg9rW5lFXX89nancRGRzFplE10ZfadlSyMibCC0mrmfVPC3A0lzNtYQr0/wJB0\n1xifk97UKJ9IYqyP/NIaCkrcA4z5JdXkl1azrayWijo/9f7m86lHCYzNTuP44RkcPzyDvKHpJMT6\nUFVWba/gw1WFfLSqkEWbS/fqTXZFXg5XTsghu68NAtnbWQO3MT1Mnb+RqrpGKmv9VNQ1UFxZz4JN\npXyxbieL88vwB5RYXxRHZvdha1kNW73xuo4YnMqkw7I4ZVQWZdX1PPflZj5c7Xqhn3pYFtdMHMIp\nh2XZA5C9lCULY3qRqjo/8zeWMGd9MXO/KaF/ahyTRmVx6mFZZKXGN9u+oLSaF+fnM3N+PkUVdcRF\nR+GLEhoDiioEVGlURXDVc+lJ7icj6DUxLpr46CjiY3xBP1GousRW53ftPXX+AHUNAeJi9lStZfdN\nbPPZmEDAxdAYUBdPQAmoGwEgJT7GklsHsWRhjGlTQ2OA91fsYOGmUkTcMC1RIkQJRIkQUKW0uoHS\nqnqKq+op8X5Kq+s50EtHv+Q4ctITyEiKo6bB75WY3GtlnX+vgShDRUcJ/VPjGZQW7/U8S2BwWjz9\nU+PJSo0nKyWOzJS4drfNNAaUjcVVrNhazvKt5WwoqiQ9KZbBaQkM7puw+3VAanyPm/TLkoUxJmIC\nAd1dcqhpaKS2wfUcq2loxBclxEVHuZ8YH/Hea3W9f8+gkiXV5JfUkF9aTUlVvddw7xrwU7zXxNho\nYnyyO4H5xL0XoLiqjq1ltV51Ww3bd9XS0Lj3tUwE0hNjyUyJIz0plvgYH3FeSajptb4xwMpt5aza\nVkFNg0tOMT5hSHoiu2oa2Fm59zM7vihh/JC+nH/UQM4+YgBZKc1LbQeqss5PjE+Ii+6cUQksWRhj\neo1AQNlZWcf28loKy+sorKhjR3kthRV1FFXUUlrd4KrGGgJ7VY9FCRzaP4XRg1IZPTCV0YNSGZmV\nQmy0Kz3UNjSypayGLaWul9vG4io+XFnI2sJKogQmDsvgvCMHcs4RA8hIjms1RlWlpsF1v66ua6Ss\npoFNxVV8s7OKjTur2FhczcbiKsqqGwCIi44iNSGG1Pho96xQQgwDU+MZkpFIboYbpWBIRuIBj0Bg\nycIYYyJkzY4K3vh6K28s2caGnVX4ooRBaa6U0XRJbXr1BwJU1TVSVe8PW3XXNFxNbr9EhmYkkdM3\nkcZAgPJaPxUhQ9VsKatt1t06PSmW44dn8ODVx+zXudhzFsYYEyGH9k/h52cexn+ccSirtlfw1tJt\nbCmt2bOBNL0I0VHinviP8578957+T42P2d19Oj6m/VVOVXV+NhVXs7nElUY2FVfTNzHy45tZsjDG\nmP0kIt4UwqmddsykuGhXbTao844J0LOa9Y0xxkSEJQtjjDFtsmRhjDGmTZYsjDHGtMmShTHGmDZZ\nsjDGGNMmSxbGGGPaZMnCGGNMm3rMcB8iUgRsOoCv6Afs7KBwDiZ23r2LnXfv0p7zHqqqmW19UY9J\nFgdKRBa0Z3yUnsbOu3ex8+5dOvK8rRrKGGNMmyxZGGOMaZMliz0e7eoAuoidd+9i5927dNh5W5uF\nMcaYNlnJwhhjTJssWRhjjGlTr08WInK2iKwWkXUiMrWr44kkEZkhIoUisixoWbqIvCcia73Xvl0Z\nY0cTkRwR+UhEVojIchH5qbe8p593vIjME5GvvfO+y1s+TETmen/vL4pIbFfHGgki4hORr0TkDe9z\nbznvjSKyVEQWi8gCb1mH/K336mQhIj5gGnAOMBq4SkRGd21UEfUkcHbIsqnAB6o6EvjA+9yT+IH/\nVNXRwLeAH3n/xj39vOuASap6FDAOOFtEvgXcB/xVVUcApcBNXRhjJP0UWBn0ubecN8Cpqjou6PmK\nDvlb79XJApgArFPVDapaD8wELuzimCJGVT8FSkIWXwg85b1/CrioU4OKMFXdpqqLvPcVuAvIYHr+\neauqVnofY7wfBSYBL3vLe9x5A4hINnAeMN37LPSC825Fh/yt9/ZkMRjID/pc4C3rTfqr6jbv/Xag\nf1cGE0kikgscDcylF5y3VxWzGCgE3gPWA2Wq6vc26al/738D/gsIeJ8z6B3nDe6G4F0RWSgiU7xl\nHfK3Ht0R0ZmeQVVVRHpkX2oRSQZeAX6mquXuZtPpqeetqo3AOBFJA14FRnVxSBEnIucDhaq6UERO\n6ep4usCJqrpFRLKA90RkVfDKA/lb7+0liy1ATtDnbG9Zb7JDRAYCeK+FXRxPhxORGFyieE5V/+Et\n7vHn3URVy4CPgOOANBFpuknsiX/vJwAXiMhGXLXyJOB+ev55A6CqW7zXQtwNwgQ66G+9tyeL+cBI\nr6dELHAl8HoXx9TZXgeu995fD7zWhbF0OK+++nFgpar+JWhVTz/vTK9EgYgkAGfg2ms+AiZ7m/W4\n81bVX6lqtqrm4v4/f6iq19DDzxtARJJEJKXpPXAmsIwO+lvv9U9wi8i5uDpOHzBDVe/p4pAiRkRe\nAE7BDVu8A7gD+CcwCxiCG+L9clUNbQQ/aInIicBnwFL21GH/N67doief95G4xkwf7qZwlqreLSKH\n4O6404GvgGtVta7rIo0crxrqdlU9vzect3eOr3ofo4HnVfUeEcmgA/7We32yMMYY07beXg1ljDGm\nHSxZGGOMaZMlC2OMMW2yZGGMMaZNliyMMca0yZKFMftARBq9ET2bfjpsAEIRyQ0eEdiY7sSG+zBm\n39So6riuDsKYzmYlC2M6gDePwJ+8uQTmicgIb3muiHwoIktE5AMRGeIt7y8ir3rzTXwtIsd7X+UT\nkce8OSje9Z6+NqbLWbIwZt8khFRDXRG0bpeqjgUexI0KAPAA8JSqHgk8B/zdW/534BNvvoljgOXe\n8pHANFUdA5QBl0b4fIxpF3uC25h9ICKVqpocZvlG3GRDG7yBC7eraoaI7AQGqmqDt3ybqvYTkSIg\nO3jICW8I9fe8SWoQkV8CMar6+8ifmTGts5KFMR1HW3i/L4LHK2rE2hVNN2HJwpiOc0XQ6xzv/Re4\n0U8BrsENaghuessfwO5Jivp0VpDG7A+7azFm3yR4s881eUdVm7rP9hWRJbjSwVXesp8AT4jIL4Ai\n4EZv+U+BR0XkJlwJ4gfANozppqzNwpgO4LVZ5Knqzq6OxZhIsGooY4wxbbKShTHGmDZZycIYY0yb\nLFkYY4xpkyULY4wxbbJkYYwxpk2WLIwxxrTp/wNTDAwsdHvNzwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UyH8P1SaNYYZ"
      },
      "source": [
        "Evaluating model and storing score in a variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_eDU0sXWNXmE",
        "colab": {}
      },
      "source": [
        "#score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "score = model.evaluate_generator(validation_generator, steps=len(validation_generator), verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_weXQQMkNWk1"
      },
      "source": [
        "Printing loss and accuracy of model test done in last step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkX8JMv79q9r",
        "colab_type": "code",
        "outputId": "83ad668e-375d-49a7-ede0-4a8bf66a3dcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.042779772491753104, 0.9897]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ed35zlSB37Mm",
        "colab_type": "text"
      },
      "source": [
        "Predicting out put for test inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCWoJkwE9suh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8INoWoRT4BBu",
        "colab_type": "text"
      },
      "source": [
        "Printing prediction and test out puts "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym7iCFBm9uBs",
        "colab_type": "code",
        "outputId": "858a4f3a-f7a4-41b2-ad3b-52ea7757096c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.8994661e-09 2.7205772e-18 5.0971709e-04 6.7702658e-13 7.9226325e-08\n",
            "  1.3026211e-11 5.9631149e-09 3.3183226e-12 9.9947637e-01 1.3858690e-05]\n",
            " [4.2642478e-05 2.7794422e-14 4.2387308e-03 1.7574868e-12 2.6051040e-07\n",
            "  6.8195124e-13 1.3419958e-03 3.4531668e-13 9.9437642e-01 2.2990979e-10]\n",
            " [9.9994475e-09 4.7611330e-16 5.1763209e-06 7.5384093e-17 4.6675259e-04\n",
            "  9.0992569e-12 2.6461126e-07 7.1974275e-17 9.9952745e-01 4.0323243e-07]\n",
            " [9.2074746e-01 1.5187742e-15 2.7254533e-02 4.4060186e-10 2.4238792e-05\n",
            "  7.5027106e-07 1.8947417e-03 4.5336822e-13 4.9875207e-02 2.0303526e-04]\n",
            " [3.4732039e-07 3.9927604e-20 4.3407995e-06 3.9728975e-15 2.1488322e-05\n",
            "  8.9994401e-12 2.4825162e-05 2.8804742e-15 9.9994862e-01 4.1619663e-07]\n",
            " [4.5228425e-08 1.7351090e-15 6.4694039e-05 3.1260684e-17 4.4893072e-04\n",
            "  9.2723424e-12 3.3208601e-06 8.4780849e-15 9.9948043e-01 2.5757804e-06]\n",
            " [3.9278811e-09 2.7661071e-18 1.2612057e-05 3.4272798e-16 1.7994957e-05\n",
            "  1.0797573e-11 4.8094687e-08 1.0230679e-15 9.9996734e-01 2.0160207e-06]\n",
            " [1.4838995e-11 7.0243086e-17 2.0740294e-05 6.4785624e-15 1.0053364e-03\n",
            "  2.7571005e-12 4.3148123e-08 2.3660288e-14 9.9896562e-01 8.2646366e-06]\n",
            " [1.6277000e-06 4.4309807e-18 9.4343814e-06 4.9012925e-14 1.5419149e-06\n",
            "  8.3829095e-09 1.8939858e-05 3.5294470e-14 9.9996746e-01 9.1470412e-07]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT--y98_dr2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
        "layer_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GY4Upv4dsUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras import backend as K\n",
        "%matplotlib inline\n",
        "# util function to convert a tensor into a valid image\n",
        "def deprocess_image(x):\n",
        "    # normalize tensor: center on 0., ensure std is 0.1\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + 1e-5)\n",
        "    x *= 0.1\n",
        "\n",
        "    # clip to [0, 1]\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "\n",
        "    # convert to RGB array\n",
        "    x *= 255\n",
        "    #x = x.transpose((1, 2, 0))\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "def vis_img_in_filter(img = np.array(X_train[2]).reshape((1, 28, 28, 1)).astype(np.float64), \n",
        "                      layer_name = 'conv2d_2'):  \n",
        "    layer_output = layer_dict[layer_name].output\n",
        "    img_ascs = list()\n",
        "    for filter_index in range(layer_output.shape[3]):\n",
        "        # build a loss function that maximizes the activation\n",
        "        # of the nth filter of the layer considered\n",
        "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
        "\n",
        "        # compute the gradient of the input picture wrt this loss\n",
        "        grads = K.gradients(loss, model.input)[0]\n",
        "\n",
        "        # normalization trick: we normalize the gradient\n",
        "        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
        "\n",
        "        # this function returns the loss and grads given the input picture\n",
        "        iterate = K.function([model.input], [loss, grads])\n",
        "\n",
        "        # step size for gradient ascent\n",
        "        step = 5.\n",
        "\n",
        "        img_asc = np.array(img)\n",
        "        # run gradient ascent for 20 steps\n",
        "        for i in range(20):\n",
        "            loss_value, grads_value = iterate([img_asc])\n",
        "            img_asc += grads_value * step\n",
        "\n",
        "        img_asc = img_asc[0]\n",
        "        img_ascs.append(deprocess_image(img_asc).reshape((28, 28)))\n",
        "        \n",
        "    if layer_output.shape[3] >= 35:\n",
        "        plot_x, plot_y = 6, 6\n",
        "    elif layer_output.shape[3] >= 23:\n",
        "        plot_x, plot_y = 4, 6\n",
        "    elif layer_output.shape[3] >= 11:\n",
        "        plot_x, plot_y = 2, 6\n",
        "    else:\n",
        "        plot_x, plot_y = 1, 2\n",
        "    fig, ax = plt.subplots(plot_x, plot_y, figsize = (12, 12))\n",
        "    ax[0, 0].imshow(img.reshape((28, 28)), cmap = 'gray')\n",
        "    ax[0, 0].set_title('Input image')\n",
        "    fig.suptitle('Input image and %s filters' % (layer_name,))\n",
        "    fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n",
        "    for (x, y) in [(i, j) for i in range(plot_x) for j in range(plot_y)]:\n",
        "        if x == 0 and y == 0:\n",
        "            continue\n",
        "        ax[x, y].imshow(img_ascs[x * plot_y + y - 1], cmap = 'gray')\n",
        "        ax[x, y].set_title('filter %d' % (x * plot_y + y - 1))\n",
        "\n",
        "vis_img_in_filter()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}