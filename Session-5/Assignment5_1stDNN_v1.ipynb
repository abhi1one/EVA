{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment5-1stDNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "# **1st DNN for assignment 5**\n",
        "\n",
        "**Task**\n",
        "\n",
        "* Change the code 8 or your own 4th Code from Assignment 4 to include:\n",
        "  1. image normalization\n",
        "  2. L2 regularization\n",
        "  3. ReLU after BN\n",
        "\n",
        "* Run your new code for 40 epochs and save the model with highest validation accuracy\n",
        "* Find out 25 misclassified images from the validation dataset and create an image gallery\n",
        "* Submit\n",
        " \n",
        "\n",
        "**This is version 1 for code picked from previous assignemt's last version  **\n",
        "\n",
        "Version 1: Adding Inage Normalization\n",
        "Version 2 L2 Reg\n",
        "Version 3 Relu after BN\n",
        "Version 4 Tuning and saving model for highers accuracy\n",
        "Version 5 Finding 25 missclassified images\n",
        "\n",
        "\n",
        "*Result*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8FDs1Hx0-o0",
        "colab_type": "text"
      },
      "source": [
        "installing and Importing Keras for current solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-qhHUhK1Ggp",
        "colab_type": "text"
      },
      "source": [
        "Importing Numpy and Keras modules as well as mnist data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxPvMT_21Mhy",
        "colab_type": "text"
      },
      "source": [
        "Loading mnist data set in train and test variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SMpZZpo1Sv0",
        "colab_type": "text"
      },
      "source": [
        "Ploting sample from train data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "c35e13c9-3c5a-4d89-b997-1998903dd628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f755c0e9e48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1AM8Fy81X1n",
        "colab_type": "text"
      },
      "source": [
        "Reshaping all train and test data to a uniform size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjr4ODS81eUc",
        "colab_type": "text"
      },
      "source": [
        "Regularizing train and test data for float data type and division wiht 255"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDZ-v1na1okY",
        "colab_type": "text"
      },
      "source": [
        "Visualizing train out put"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "654b6c50-3091-4aa7-e2d2-f7f56e5f95c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCLqRA3o1wFq",
        "colab_type": "text"
      },
      "source": [
        "Convert 1-dimensional class arrays to 10-dimensional class matrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXmnovfn1yew",
        "colab_type": "text"
      },
      "source": [
        "Viewing tranformed train out put matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "17905ca7-ab2e-44da-8903-b1996d7275ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "Y_train[:10]\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlpFjyqJyhCW",
        "colab_type": "text"
      },
      "source": [
        "Adding Image normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXG-3PuRyfkr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "853b905e-131f-4558-f372-db107a3c91dd"
      },
      "source": [
        "# standardizing a image dataset\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "'''\n",
        "# load dataset\n",
        "(trainX, trainy), (testX, testy) = mnist.load_data()\n",
        "# reshape dataset to have a single channel\n",
        "width, height, channels = trainX.shape[1], trainX.shape[2], 1\n",
        "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\n",
        "testX = testX.reshape((testX.shape[0], width, height, channels))\n",
        "'''\n",
        "\n",
        "# report pixel means and standard deviations\n",
        "print('Statistics train=%.3f (%.3f), test=%.3f (%.3f)' % (X_train.mean(), X_train.std(), X_test.mean(), Y_test.std()))\n",
        "# create generator that centers pixel values\n",
        "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "# calculate the mean on the training dataset\n",
        "datagen.fit(X_train)\n",
        "print('Data Generator mean=%.3f, std=%.3f' % (datagen.mean, datagen.std))\n",
        "# demonstrate effect on a single batch of samples\n",
        "train_iterator = datagen.flow(X_train, Y_train, batch_size=64)\n",
        "\n",
        "# get batch iterator for validation\n",
        "validation_generator = datagen.flow(X_test, Y_test)\n",
        "\n",
        "\n",
        "# get a batch\n",
        "batchX, batchy = train_iterator.next()\n",
        "# pixel stats in the batch\n",
        "print(batchX.shape, batchX.mean(), batchX.std())\n",
        "# demonstrate effect on entire training dataset\n",
        "train_iterator1 = datagen.flow(X_train, Y_train, batch_size=len(X_train), shuffle=False)\n",
        "# get a batch\n",
        "batchX, batchy = train_iterator1.next()\n",
        "# pixel stats in the batch\n",
        "print(batchX.shape, batchX.mean(), batchX.std())"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Statistics train=0.131 (0.308), test=0.133 (0.300)\n",
            "Data Generator mean=0.131, std=0.308\n",
            "(64, 28, 28, 1) 0.022442447 1.024061\n",
            "(60000, 28, 28, 1) -4.9324944e-07 0.9999959\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2PFtTZq127m",
        "colab_type": "text"
      },
      "source": [
        "Carrying model arch from Assignment 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osKqT73Q9JJB",
        "colab_type": "code",
        "outputId": "30b2bba7-7625-429a-fd81-c57dc0f8a7bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "from keras.layers import Activation, BatchNormalization\n",
        "model = Sequential()\n",
        "\n",
        "#Vanilla\n",
        "''' \n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Convolution2D(10, 1, activation='relu'))\n",
        "model.add(Convolution2D(10, 26))\n",
        "'''\n",
        "\n",
        "#1st version \n",
        "'''\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 26,26 #RF 3X3\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 24,24 #RF 7X7\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 22,22 #RF 9X9\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 20,20 #RF 11X11\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 18,18 #RF 13X13\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 16,16 #RF 15X15\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 14,14 #RF 17X17\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Convolution2D(4, 3, 3, activation='relu')) #input 12,12 #RF 19X19\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(10, 1)) #input 10,10 \n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(10, 10)) #input 10,10\n",
        "'''\n",
        "\n",
        "#2nd version \n",
        "'''\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) #input 26,26 #RF 3X3\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) #input 24,24 #RF 7X7\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) #input 22,22 #RF 14X14\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 11,11 #RF 16X16\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu')) #input 9,9\n",
        "model.add(Convolution2D(10, 9)) #input 9X9\n",
        "'''\n",
        "\n",
        "#3rd version \n",
        "''''''\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) #input 26,26 #RF 3X3\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) #input 24,24 #RF 6X6\n",
        "\n",
        "model.add(Convolution2D(12, 3, 3, activation='relu')) #input 12,12 #RF 8X8\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu')) #input 10,10\n",
        "model.add(Convolution2D(10, 10)) #input 10,10\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:75: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:80: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\")`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:85: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(12, (3, 3), activation=\"relu\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1mq9MtB2GgQ",
        "colab_type": "text"
      },
      "source": [
        "Printing model summary to understand current paramaters for the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzdAYg1k9K7Z",
        "colab_type": "code",
        "outputId": "ed367da3-c06f-43a9-8535-d628c4a8b6ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_16 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 26, 26, 16)        64        \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 26, 26, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 24, 24, 16)        2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 24, 24, 16)        64        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 10, 10, 12)        1740      \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 10, 10, 12)        48        \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 10, 10, 12)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 10, 10, 10)        130       \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 1, 1, 10)          10010     \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 14,536\n",
            "Trainable params: 14,448\n",
            "Non-trainable params: 88\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlnhdT4u2Owz",
        "colab_type": "text"
      },
      "source": [
        "Setting model's compile environment with loss function, optimizer and matrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6SuGrL9M3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam, SGD\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.01 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer=Adam(lr=0.01),\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06jT2a0t2Vpj",
        "colab_type": "text"
      },
      "source": [
        "Training model for 50 epoch for 128 batch size\n",
        "Replacing training images with batchX"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xWoKhPY9Of5",
        "colab_type": "code",
        "outputId": "ce615d25-1475-4146-d16b-0279f291559e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3417
        }
      },
      "source": [
        "#history = model.fit(X_train, Y_train, batch_size=128, nb_epoch=50, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])\n",
        "\n",
        "\n",
        "#Fit gen for normalized image gen \n",
        "\n",
        "history = model.fit_generator(train_iterator, steps_per_epoch=len(train_iterator), epochs=50, callbacks=[LearningRateScheduler(scheduler, verbose=1)], verbose=1, validation_data=validation_generator,\n",
        "        validation_steps=800)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.01.\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 0.1385 - acc: 0.9577 - val_loss: 0.0501 - val_acc: 0.9843\n",
            "Epoch 2/50\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0075815011.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0605 - acc: 0.9808 - val_loss: 0.0389 - val_acc: 0.9870\n",
            "Epoch 3/50\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0061050061.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0474 - acc: 0.9849 - val_loss: 0.0365 - val_acc: 0.9876\n",
            "Epoch 4/50\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.005109862.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0403 - acc: 0.9874 - val_loss: 0.0395 - val_acc: 0.9868\n",
            "Epoch 5/50\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0043936731.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0370 - acc: 0.9880 - val_loss: 0.0349 - val_acc: 0.9879\n",
            "Epoch 6/50\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0038535645.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0320 - acc: 0.9896 - val_loss: 0.0307 - val_acc: 0.9903\n",
            "Epoch 7/50\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.003431709.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0265 - acc: 0.9910 - val_loss: 0.0380 - val_acc: 0.9881\n",
            "Epoch 8/50\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0030931024.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0261 - acc: 0.9919 - val_loss: 0.0339 - val_acc: 0.9889\n",
            "Epoch 9/50\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0028153153.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0232 - acc: 0.9923 - val_loss: 0.0305 - val_acc: 0.9906\n",
            "Epoch 10/50\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0025833118.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0207 - acc: 0.9932 - val_loss: 0.0280 - val_acc: 0.9915\n",
            "Epoch 11/50\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0023866348.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0193 - acc: 0.9938 - val_loss: 0.0280 - val_acc: 0.9917\n",
            "Epoch 12/50\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0022177866.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0179 - acc: 0.9941 - val_loss: 0.0312 - val_acc: 0.9905\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.002071251.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0168 - acc: 0.9943 - val_loss: 0.0274 - val_acc: 0.9931\n",
            "Epoch 14/50\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0019428793.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0157 - acc: 0.9942 - val_loss: 0.0290 - val_acc: 0.9915\n",
            "Epoch 15/50\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0018294914.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0143 - acc: 0.9953 - val_loss: 0.0257 - val_acc: 0.9925\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0017286085.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0138 - acc: 0.9955 - val_loss: 0.0293 - val_acc: 0.9924\n",
            "Epoch 17/50\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.00163827.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0146 - acc: 0.9953 - val_loss: 0.0310 - val_acc: 0.9915\n",
            "Epoch 18/50\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0015569049.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0117 - acc: 0.9961 - val_loss: 0.0301 - val_acc: 0.9906\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0014832394.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0127 - acc: 0.9955 - val_loss: 0.0304 - val_acc: 0.9916\n",
            "Epoch 20/50\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.00141623.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0116 - acc: 0.9960 - val_loss: 0.0337 - val_acc: 0.9918\n",
            "Epoch 21/50\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0013550136.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0113 - acc: 0.9962 - val_loss: 0.0293 - val_acc: 0.9923\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.00129887.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0104 - acc: 0.9965 - val_loss: 0.0300 - val_acc: 0.9917\n",
            "Epoch 23/50\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0012471938.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0110 - acc: 0.9963 - val_loss: 0.0295 - val_acc: 0.9916\n",
            "Epoch 24/50\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0011994722.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0100 - acc: 0.9964 - val_loss: 0.0282 - val_acc: 0.9926\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.001155268.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0091 - acc: 0.9969 - val_loss: 0.0339 - val_acc: 0.9911\n",
            "Epoch 26/50\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0011142061.\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0092 - acc: 0.9969 - val_loss: 0.0313 - val_acc: 0.9920\n",
            "Epoch 27/50\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.001075963.\n",
            "938/938 [==============================] - 11s 11ms/step - loss: 0.0100 - acc: 0.9966 - val_loss: 0.0304 - val_acc: 0.9925\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.001040258.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0076 - acc: 0.9974 - val_loss: 0.0324 - val_acc: 0.9924\n",
            "Epoch 29/50\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.0010068466.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0097 - acc: 0.9968 - val_loss: 0.0306 - val_acc: 0.9917\n",
            "Epoch 30/50\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0009755146.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0090 - acc: 0.9969 - val_loss: 0.0328 - val_acc: 0.9925\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0009460738.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0082 - acc: 0.9970 - val_loss: 0.0286 - val_acc: 0.9923\n",
            "Epoch 32/50\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.000918358.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0076 - acc: 0.9973 - val_loss: 0.0315 - val_acc: 0.9927\n",
            "Epoch 33/50\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.0008922198.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0085 - acc: 0.9973 - val_loss: 0.0318 - val_acc: 0.9920\n",
            "Epoch 34/50\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0008675284.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0080 - acc: 0.9973 - val_loss: 0.0340 - val_acc: 0.9922\n",
            "Epoch 35/50\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.0008441668.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0076 - acc: 0.9974 - val_loss: 0.0306 - val_acc: 0.9920\n",
            "Epoch 36/50\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0008220304.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0080 - acc: 0.9974 - val_loss: 0.0306 - val_acc: 0.9926\n",
            "Epoch 37/50\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0008010253.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0069 - acc: 0.9977 - val_loss: 0.0298 - val_acc: 0.9925\n",
            "Epoch 38/50\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0007810669.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0067 - acc: 0.9978 - val_loss: 0.0311 - val_acc: 0.9919\n",
            "Epoch 39/50\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.000762079.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0071 - acc: 0.9975 - val_loss: 0.0294 - val_acc: 0.9922\n",
            "Epoch 40/50\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0007439923.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0070 - acc: 0.9977 - val_loss: 0.0332 - val_acc: 0.9929\n",
            "Epoch 41/50\n",
            "\n",
            "Epoch 00041: LearningRateScheduler setting learning rate to 0.0007267442.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0065 - acc: 0.9979 - val_loss: 0.0322 - val_acc: 0.9927\n",
            "Epoch 42/50\n",
            "\n",
            "Epoch 00042: LearningRateScheduler setting learning rate to 0.0007102777.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0068 - acc: 0.9977 - val_loss: 0.0319 - val_acc: 0.9927\n",
            "Epoch 43/50\n",
            "\n",
            "Epoch 00043: LearningRateScheduler setting learning rate to 0.0006945409.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0066 - acc: 0.9977 - val_loss: 0.0343 - val_acc: 0.9919\n",
            "Epoch 44/50\n",
            "\n",
            "Epoch 00044: LearningRateScheduler setting learning rate to 0.0006794863.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0067 - acc: 0.9978 - val_loss: 0.0312 - val_acc: 0.9926\n",
            "Epoch 45/50\n",
            "\n",
            "Epoch 00045: LearningRateScheduler setting learning rate to 0.0006650705.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0059 - acc: 0.9979 - val_loss: 0.0326 - val_acc: 0.9930\n",
            "Epoch 46/50\n",
            "\n",
            "Epoch 00046: LearningRateScheduler setting learning rate to 0.0006512537.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0061 - acc: 0.9980 - val_loss: 0.0324 - val_acc: 0.9926\n",
            "Epoch 47/50\n",
            "\n",
            "Epoch 00047: LearningRateScheduler setting learning rate to 0.0006379992.\n",
            "938/938 [==============================] - 10s 11ms/step - loss: 0.0056 - acc: 0.9979 - val_loss: 0.0318 - val_acc: 0.9929\n",
            "Epoch 48/50\n",
            "\n",
            "Epoch 00048: LearningRateScheduler setting learning rate to 0.0006252736.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0064 - acc: 0.9980 - val_loss: 0.0320 - val_acc: 0.9926\n",
            "Epoch 49/50\n",
            "\n",
            "Epoch 00049: LearningRateScheduler setting learning rate to 0.0006130456.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0060 - acc: 0.9981 - val_loss: 0.0300 - val_acc: 0.9932\n",
            "Epoch 50/50\n",
            "\n",
            "Epoch 00050: LearningRateScheduler setting learning rate to 0.0006012868.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0063 - acc: 0.9977 - val_loss: 0.0335 - val_acc: 0.9924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_0_UAU1M1wP",
        "colab_type": "text"
      },
      "source": [
        "Plotting training and validation accuracty as well as loss for every epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tvptcn8dxvp",
        "colab_type": "code",
        "outputId": "5fe095fb-c9d7-405e-8b26-3dc8315b4a94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#history = model.fit(x, y, validation_split=0.25, epochs=50, batch_size=16, verbose=1)\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBcgkc561tNwDAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UyH8P1SaNYYZ"
      },
      "source": [
        "Evaluating model and storing score in a variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_eDU0sXWNXmE",
        "colab": {}
      },
      "source": [
        "#score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "score = model.evaluate_generator(validation_generator, steps=len(validation_generator), verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_weXQQMkNWk1"
      },
      "source": [
        "Printing loss and accuracy of model test done in last step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkX8JMv79q9r",
        "colab_type": "code",
        "outputId": "5b9bae3e-950d-4111-a096-183f3eed3656",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.031935828762586604, 0.993]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ed35zlSB37Mm",
        "colab_type": "text"
      },
      "source": [
        "Predicting out put for test inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCWoJkwE9suh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8INoWoRT4BBu",
        "colab_type": "text"
      },
      "source": [
        "Printing prediction and test out puts "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym7iCFBm9uBs",
        "colab_type": "code",
        "outputId": "858a4f3a-f7a4-41b2-ad3b-52ea7757096c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.8994661e-09 2.7205772e-18 5.0971709e-04 6.7702658e-13 7.9226325e-08\n",
            "  1.3026211e-11 5.9631149e-09 3.3183226e-12 9.9947637e-01 1.3858690e-05]\n",
            " [4.2642478e-05 2.7794422e-14 4.2387308e-03 1.7574868e-12 2.6051040e-07\n",
            "  6.8195124e-13 1.3419958e-03 3.4531668e-13 9.9437642e-01 2.2990979e-10]\n",
            " [9.9994475e-09 4.7611330e-16 5.1763209e-06 7.5384093e-17 4.6675259e-04\n",
            "  9.0992569e-12 2.6461126e-07 7.1974275e-17 9.9952745e-01 4.0323243e-07]\n",
            " [9.2074746e-01 1.5187742e-15 2.7254533e-02 4.4060186e-10 2.4238792e-05\n",
            "  7.5027106e-07 1.8947417e-03 4.5336822e-13 4.9875207e-02 2.0303526e-04]\n",
            " [3.4732039e-07 3.9927604e-20 4.3407995e-06 3.9728975e-15 2.1488322e-05\n",
            "  8.9994401e-12 2.4825162e-05 2.8804742e-15 9.9994862e-01 4.1619663e-07]\n",
            " [4.5228425e-08 1.7351090e-15 6.4694039e-05 3.1260684e-17 4.4893072e-04\n",
            "  9.2723424e-12 3.3208601e-06 8.4780849e-15 9.9948043e-01 2.5757804e-06]\n",
            " [3.9278811e-09 2.7661071e-18 1.2612057e-05 3.4272798e-16 1.7994957e-05\n",
            "  1.0797573e-11 4.8094687e-08 1.0230679e-15 9.9996734e-01 2.0160207e-06]\n",
            " [1.4838995e-11 7.0243086e-17 2.0740294e-05 6.4785624e-15 1.0053364e-03\n",
            "  2.7571005e-12 4.3148123e-08 2.3660288e-14 9.9896562e-01 8.2646366e-06]\n",
            " [1.6277000e-06 4.4309807e-18 9.4343814e-06 4.9012925e-14 1.5419149e-06\n",
            "  8.3829095e-09 1.8939858e-05 3.5294470e-14 9.9996746e-01 9.1470412e-07]]\n",
            "[7 2 1 0 4 1 4 9 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT--y98_dr2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
        "layer_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GY4Upv4dsUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras import backend as K\n",
        "%matplotlib inline\n",
        "# util function to convert a tensor into a valid image\n",
        "def deprocess_image(x):\n",
        "    # normalize tensor: center on 0., ensure std is 0.1\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + 1e-5)\n",
        "    x *= 0.1\n",
        "\n",
        "    # clip to [0, 1]\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "\n",
        "    # convert to RGB array\n",
        "    x *= 255\n",
        "    #x = x.transpose((1, 2, 0))\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "def vis_img_in_filter(img = np.array(X_train[2]).reshape((1, 28, 28, 1)).astype(np.float64), \n",
        "                      layer_name = 'conv2d_2'):  \n",
        "    layer_output = layer_dict[layer_name].output\n",
        "    img_ascs = list()\n",
        "    for filter_index in range(layer_output.shape[3]):\n",
        "        # build a loss function that maximizes the activation\n",
        "        # of the nth filter of the layer considered\n",
        "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
        "\n",
        "        # compute the gradient of the input picture wrt this loss\n",
        "        grads = K.gradients(loss, model.input)[0]\n",
        "\n",
        "        # normalization trick: we normalize the gradient\n",
        "        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
        "\n",
        "        # this function returns the loss and grads given the input picture\n",
        "        iterate = K.function([model.input], [loss, grads])\n",
        "\n",
        "        # step size for gradient ascent\n",
        "        step = 5.\n",
        "\n",
        "        img_asc = np.array(img)\n",
        "        # run gradient ascent for 20 steps\n",
        "        for i in range(20):\n",
        "            loss_value, grads_value = iterate([img_asc])\n",
        "            img_asc += grads_value * step\n",
        "\n",
        "        img_asc = img_asc[0]\n",
        "        img_ascs.append(deprocess_image(img_asc).reshape((28, 28)))\n",
        "        \n",
        "    if layer_output.shape[3] >= 35:\n",
        "        plot_x, plot_y = 6, 6\n",
        "    elif layer_output.shape[3] >= 23:\n",
        "        plot_x, plot_y = 4, 6\n",
        "    elif layer_output.shape[3] >= 11:\n",
        "        plot_x, plot_y = 2, 6\n",
        "    else:\n",
        "        plot_x, plot_y = 1, 2\n",
        "    fig, ax = plt.subplots(plot_x, plot_y, figsize = (12, 12))\n",
        "    ax[0, 0].imshow(img.reshape((28, 28)), cmap = 'gray')\n",
        "    ax[0, 0].set_title('Input image')\n",
        "    fig.suptitle('Input image and %s filters' % (layer_name,))\n",
        "    fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n",
        "    for (x, y) in [(i, j) for i in range(plot_x) for j in range(plot_y)]:\n",
        "        if x == 0 and y == 0:\n",
        "            continue\n",
        "        ax[x, y].imshow(img_ascs[x * plot_y + y - 1], cmap = 'gray')\n",
        "        ax[x, y].set_title('filter %d' % (x * plot_y + y - 1))\n",
        "\n",
        "vis_img_in_filter()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}