{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment5-1stDNN_v4.3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNyZv-Ec52ot",
        "colab_type": "text"
      },
      "source": [
        "# **1st DNN for assignment 5**\n",
        "\n",
        "**Task**\n",
        "\n",
        "* Change the code 8 or your own 4th Code from Assignment 4 to include:\n",
        "  1. image normalization\n",
        "  2. L2 regularization\n",
        "  3. ReLU after BN\n",
        "\n",
        "* Run your new code for 40 epochs and save the model with highest validation accuracy\n",
        "* Find out 25 misclassified images from the validation dataset and create an image gallery\n",
        "* Submit\n",
        " \n",
        "\n",
        "**This is version 4.3 for code picked from Assignment5-1stDNN_v4.2  **\n",
        "\n",
        "Version 1: Adding Inage Normalization\n",
        "Version 2 L2 Reg\n",
        "Version 3 Relu after BN\n",
        "**Version 4 Tuning and saving model for highers accuracy**\n",
        "Version 5 Finding 25 missclassified images\n",
        "\n",
        "\n",
        "*Changes and Result*\n",
        "\n",
        "Removed Relu and BN from newly added later\n",
        "\n",
        "Observed low / no overfitting on model training; need to work on improving val accuravy\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8FDs1Hx0-o0",
        "colab_type": "text"
      },
      "source": [
        "installing and Importing Keras for current solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-qhHUhK1Ggp",
        "colab_type": "text"
      },
      "source": [
        "Importing Numpy and Keras modules as well as mnist data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rRiTk5tZXYG",
        "colab_type": "code",
        "outputId": "17c45ae0-5712-43c8-f311-0247edca0f61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#preparing check point for saving weights via callback\n",
        "from google.colab import drive\n",
        "from keras.callbacks import CSVLogger\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zByEi95J86RD",
        "colab_type": "text"
      },
      "source": [
        "### Load pre-shuffled MNIST data into train and test sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxPvMT_21Mhy",
        "colab_type": "text"
      },
      "source": [
        "Loading mnist data set in train and test variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SMpZZpo1Sv0",
        "colab_type": "text"
      },
      "source": [
        "Ploting sample from train data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "outputId": "a5ef8bcf-2eb5-4534-87ee-55df02ffbfc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f71d12e9198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1AM8Fy81X1n",
        "colab_type": "text"
      },
      "source": [
        "Reshaping all train and test data to a uniform size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjr4ODS81eUc",
        "colab_type": "text"
      },
      "source": [
        "Regularizing train and test data for float data type and division wiht 255"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDZ-v1na1okY",
        "colab_type": "text"
      },
      "source": [
        "Visualizing train out put"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "outputId": "60067cf7-7cd8-4a60-c9f0-ba4d9c8e10a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCLqRA3o1wFq",
        "colab_type": "text"
      },
      "source": [
        "Convert 1-dimensional class arrays to 10-dimensional class matrices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXmnovfn1yew",
        "colab_type": "text"
      },
      "source": [
        "Viewing tranformed train out put matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "outputId": "405914dd-fd84-489a-b926-eef1dfed4f15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "Y_train[:10]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlpFjyqJyhCW",
        "colab_type": "text"
      },
      "source": [
        "Adding Image normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXG-3PuRyfkr",
        "colab_type": "code",
        "outputId": "178082e1-c8c4-4c73-bf12-bca9738bace1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# standardizing a image dataset\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "'''\n",
        "# load dataset\n",
        "(trainX, trainy), (testX, testy) = mnist.load_data()\n",
        "# reshape dataset to have a single channel\n",
        "width, height, channels = trainX.shape[1], trainX.shape[2], 1\n",
        "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\n",
        "testX = testX.reshape((testX.shape[0], width, height, channels))\n",
        "'''\n",
        "\n",
        "# report pixel means and standard deviations\n",
        "print('Statistics train=%.3f (%.3f), test=%.3f (%.3f)' % (X_train.mean(), X_train.std(), X_test.mean(), Y_test.std()))\n",
        "# create generator that centers pixel values\n",
        "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "# calculate the mean on the training dataset\n",
        "datagen.fit(X_train)\n",
        "print('Data Generator mean=%.3f, std=%.3f' % (datagen.mean, datagen.std))\n",
        "# demonstrate effect on a single batch of samples\n",
        "train_iterator = datagen.flow(X_train, Y_train, batch_size=64)\n",
        "\n",
        "# get batch iterator for validation\n",
        "validation_generator = datagen.flow(X_test, Y_test)\n",
        "\n",
        "\n",
        "# get a batch\n",
        "batchX, batchy = train_iterator.next()\n",
        "# pixel stats in the batch\n",
        "print(batchX.shape, batchX.mean(), batchX.std())\n",
        "# demonstrate effect on entire training dataset\n",
        "train_iterator1 = datagen.flow(X_train, Y_train, batch_size=len(X_train), shuffle=False)\n",
        "# get a batch\n",
        "batchX, batchy = train_iterator1.next()\n",
        "# pixel stats in the batch\n",
        "print(batchX.shape, batchX.mean(), batchX.std())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Statistics train=0.131 (0.308), test=0.133 (0.300)\n",
            "Data Generator mean=0.131, std=0.308\n",
            "(64, 28, 28, 1) -0.0020950316 0.99770886\n",
            "(60000, 28, 28, 1) -4.9324944e-07 0.9999959\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2PFtTZq127m",
        "colab_type": "text"
      },
      "source": [
        "Carrying model arch from Assignment5-1stDNN_v4.2\n",
        "\n",
        "Removing Relu and BN from newly added layer, total params less then 10K"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osKqT73Q9JJB",
        "colab_type": "code",
        "outputId": "cb2ce2fc-7b99-43ce-812d-6b77f3e6c255",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "from keras.layers import Activation, BatchNormalization\n",
        "\n",
        "# Importing library for L2 regularization\n",
        "from keras.regularizers import l2\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#Vanilla\n",
        "''' \n",
        "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Convolution2D(10, 1, activation='relu'))\n",
        "model.add(Convolution2D(10, 26))\n",
        "'''\n",
        "\n",
        "#1st version \n",
        "'''\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 26,26 #RF 3X3\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 24,24 #RF 7X7\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 22,22 #RF 9X9\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 20,20 #RF 11X11\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 18,18 #RF 13X13\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 16,16 #RF 15X15\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 14,14 #RF 17X17\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Convolution2D(4, 3, 3, activation='relu')) #input 12,12 #RF 19X19\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(10, 1)) #input 10,10 \n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(10, 10)) #input 10,10\n",
        "'''\n",
        "\n",
        "#2nd version \n",
        "'''\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu', input_shape=(28,28,1)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) #input 26,26 #RF 3X3\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(16, 3, 3, activation='relu')) #input 24,24 #RF 7X7\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) #input 22,22 #RF 14X14\n",
        "model.add(Convolution2D(8, 3, 3, activation='relu')) #input 11,11 #RF 16X16\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Convolution2D(10, 1, activation='relu')) #input 9,9\n",
        "model.add(Convolution2D(10, 9)) #input 9X9\n",
        "'''\n",
        "\n",
        "#3rd version \n",
        "''''''\n",
        "model.add(Convolution2D(8, 3, 3, input_shape=(28,28,1), kernel_regularizer=l2(0.00001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, kernel_regularizer=l2(0.00001))) #input 26,26 #RF 3X3\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2))) #input 24,24 #RF 6X6\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, kernel_regularizer=l2(0.00001))) #input 12,12 #RF 8X8\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Convolution2D(8, 3, 3, kernel_regularizer=l2(0.00001))) #input 10,10 #RF 10X10\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Convolution2D(10, 1)) #input 8, 8\n",
        "#model.add(BatchNormalization())\n",
        "\n",
        "model.add(Convolution2D(10, 8)) #input 8,8\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:79: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), input_shape=(28, 28, 1..., kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:85: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:93: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), kernel_regularizer=<keras.reg...)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:99: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(8, (3, 3), kernel_regularizer=<keras.reg...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1mq9MtB2GgQ",
        "colab_type": "text"
      },
      "source": [
        "Printing model summary to understand current paramaters for the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzdAYg1k9K7Z",
        "colab_type": "code",
        "outputId": "19c10747-71ef-452c-d50a-7af63feecd6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_54 (Conv2D)           (None, 26, 26, 8)         80        \n",
            "_________________________________________________________________\n",
            "batch_normalization_37 (Batc (None, 26, 26, 8)         32        \n",
            "_________________________________________________________________\n",
            "activation_28 (Activation)   (None, 26, 26, 8)         0         \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 26, 26, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_55 (Conv2D)           (None, 24, 24, 8)         584       \n",
            "_________________________________________________________________\n",
            "batch_normalization_38 (Batc (None, 24, 24, 8)         32        \n",
            "_________________________________________________________________\n",
            "activation_29 (Activation)   (None, 24, 24, 8)         0         \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 24, 24, 8)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 12, 12, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_56 (Conv2D)           (None, 10, 10, 8)         584       \n",
            "_________________________________________________________________\n",
            "batch_normalization_39 (Batc (None, 10, 10, 8)         32        \n",
            "_________________________________________________________________\n",
            "activation_30 (Activation)   (None, 10, 10, 8)         0         \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 10, 10, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_57 (Conv2D)           (None, 8, 8, 8)           584       \n",
            "_________________________________________________________________\n",
            "batch_normalization_40 (Batc (None, 8, 8, 8)           32        \n",
            "_________________________________________________________________\n",
            "activation_31 (Activation)   (None, 8, 8, 8)           0         \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 8, 8, 8)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_58 (Conv2D)           (None, 8, 8, 10)          90        \n",
            "_________________________________________________________________\n",
            "conv2d_59 (Conv2D)           (None, 1, 1, 10)          6410      \n",
            "_________________________________________________________________\n",
            "flatten_11 (Flatten)         (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_32 (Activation)   (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 8,460\n",
            "Trainable params: 8,396\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlnhdT4u2Owz",
        "colab_type": "text"
      },
      "source": [
        "Setting model's compile environment with loss function, optimizer and matrics.\n",
        "Setting up LR scheduler\n",
        "Setting up model save check points for best perfomance.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp6SuGrL9M3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adam, SGD\n",
        "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.01 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "filepath=\"/content/gdrive/My Drive/Weights/Assignment5-1stDNN_v4.3_weights-improvement-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "callback_list = [LearningRateScheduler(scheduler, verbose=1), checkpoint]\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer=Adam(lr=0.01),\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06jT2a0t2Vpj",
        "colab_type": "text"
      },
      "source": [
        "Training model for 40 epoch for 128 batch size\n",
        "\n",
        "Using fit_generator to use normalized image data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xWoKhPY9Of5",
        "colab_type": "code",
        "outputId": "dd019c79-e782-47b5-a14a-9c604b527aba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4117
        }
      },
      "source": [
        "#history = model.fit(X_train, Y_train, batch_size=128, nb_epoch=50, verbose=1, validation_data=(X_test, Y_test), callbacks=[LearningRateScheduler(scheduler, verbose=1)])\n",
        "\n",
        "\n",
        "#Fit gen for normalized image gen \n",
        "\n",
        "history = model.fit_generator(train_iterator, steps_per_epoch=len(train_iterator), epochs=40, callbacks=callback_list, verbose=1, validation_data=validation_generator,\n",
        "        validation_steps=len(validation_generator))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.01.\n",
            "938/938 [==============================] - 17s 18ms/step - loss: 0.2005 - acc: 0.9392 - val_loss: 0.0760 - val_acc: 0.9756\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.97560, saving model to /content/gdrive/My Drive/Weights/Assignment5-1stDNN_v4.3_weights-improvement-01-0.9756.hdf5\n",
            "Epoch 2/40\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0075815011.\n",
            "938/938 [==============================] - 13s 13ms/step - loss: 0.0941 - acc: 0.9715 - val_loss: 0.0590 - val_acc: 0.9817\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.97560 to 0.98170, saving model to /content/gdrive/My Drive/Weights/Assignment5-1stDNN_v4.3_weights-improvement-02-0.9817.hdf5\n",
            "Epoch 3/40\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0061050061.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0817 - acc: 0.9761 - val_loss: 0.0411 - val_acc: 0.9866\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.98170 to 0.98660, saving model to /content/gdrive/My Drive/Weights/Assignment5-1stDNN_v4.3_weights-improvement-03-0.9866.hdf5\n",
            "Epoch 4/40\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.005109862.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0712 - acc: 0.9784 - val_loss: 0.0407 - val_acc: 0.9865\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.98660\n",
            "Epoch 5/40\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0043936731.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0666 - acc: 0.9801 - val_loss: 0.0349 - val_acc: 0.9893\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.98660 to 0.98930, saving model to /content/gdrive/My Drive/Weights/Assignment5-1stDNN_v4.3_weights-improvement-05-0.9893.hdf5\n",
            "Epoch 6/40\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0038535645.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0643 - acc: 0.9807 - val_loss: 0.0378 - val_acc: 0.9890\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.98930\n",
            "Epoch 7/40\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.003431709.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0616 - acc: 0.9813 - val_loss: 0.0352 - val_acc: 0.9892\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.98930\n",
            "Epoch 8/40\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0030931024.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0582 - acc: 0.9828 - val_loss: 0.0311 - val_acc: 0.9900\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.98930 to 0.99000, saving model to /content/gdrive/My Drive/Weights/Assignment5-1stDNN_v4.3_weights-improvement-08-0.9900.hdf5\n",
            "Epoch 9/40\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0028153153.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0560 - acc: 0.9832 - val_loss: 0.0318 - val_acc: 0.9907\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.99000 to 0.99070, saving model to /content/gdrive/My Drive/Weights/Assignment5-1stDNN_v4.3_weights-improvement-09-0.9907.hdf5\n",
            "Epoch 10/40\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0025833118.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0540 - acc: 0.9841 - val_loss: 0.0339 - val_acc: 0.9891\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.99070\n",
            "Epoch 11/40\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0023866348.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0521 - acc: 0.9842 - val_loss: 0.0305 - val_acc: 0.9899\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.99070\n",
            "Epoch 12/40\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.0022177866.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0499 - acc: 0.9854 - val_loss: 0.0344 - val_acc: 0.9896\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.99070\n",
            "Epoch 13/40\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.002071251.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0500 - acc: 0.9849 - val_loss: 0.0342 - val_acc: 0.9897\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.99070\n",
            "Epoch 14/40\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0019428793.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0502 - acc: 0.9853 - val_loss: 0.0309 - val_acc: 0.9910\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.99070 to 0.99100, saving model to /content/gdrive/My Drive/Weights/Assignment5-1stDNN_v4.3_weights-improvement-14-0.9910.hdf5\n",
            "Epoch 15/40\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0018294914.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0462 - acc: 0.9859 - val_loss: 0.0284 - val_acc: 0.9919\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.99100 to 0.99190, saving model to /content/gdrive/My Drive/Weights/Assignment5-1stDNN_v4.3_weights-improvement-15-0.9919.hdf5\n",
            "Epoch 16/40\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0017286085.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0463 - acc: 0.9863 - val_loss: 0.0324 - val_acc: 0.9902\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.99190\n",
            "Epoch 17/40\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.00163827.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0461 - acc: 0.9862 - val_loss: 0.0293 - val_acc: 0.9909\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.99190\n",
            "Epoch 18/40\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0015569049.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0462 - acc: 0.9860 - val_loss: 0.0301 - val_acc: 0.9905\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.99190\n",
            "Epoch 19/40\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0014832394.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0447 - acc: 0.9864 - val_loss: 0.0276 - val_acc: 0.9922\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.99190 to 0.99220, saving model to /content/gdrive/My Drive/Weights/Assignment5-1stDNN_v4.3_weights-improvement-19-0.9922.hdf5\n",
            "Epoch 20/40\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.00141623.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0455 - acc: 0.9861 - val_loss: 0.0303 - val_acc: 0.9911\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.99220\n",
            "Epoch 21/40\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0013550136.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0425 - acc: 0.9872 - val_loss: 0.0280 - val_acc: 0.9916\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.99220\n",
            "Epoch 22/40\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.00129887.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0444 - acc: 0.9868 - val_loss: 0.0272 - val_acc: 0.9917\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.99220\n",
            "Epoch 23/40\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0012471938.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0430 - acc: 0.9870 - val_loss: 0.0271 - val_acc: 0.9920\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.99220\n",
            "Epoch 24/40\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0011994722.\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 0.0412 - acc: 0.9876 - val_loss: 0.0293 - val_acc: 0.9908\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.99220\n",
            "Epoch 25/40\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.001155268.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0422 - acc: 0.9874 - val_loss: 0.0286 - val_acc: 0.9916\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.99220\n",
            "Epoch 26/40\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0011142061.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0410 - acc: 0.9881 - val_loss: 0.0275 - val_acc: 0.9920\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.99220\n",
            "Epoch 27/40\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.001075963.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0407 - acc: 0.9881 - val_loss: 0.0283 - val_acc: 0.9915\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.99220\n",
            "Epoch 28/40\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.001040258.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0402 - acc: 0.9878 - val_loss: 0.0302 - val_acc: 0.9909\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.99220\n",
            "Epoch 29/40\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.0010068466.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0395 - acc: 0.9879 - val_loss: 0.0282 - val_acc: 0.9920\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.99220\n",
            "Epoch 30/40\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0009755146.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0411 - acc: 0.9877 - val_loss: 0.0288 - val_acc: 0.9917\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.99220\n",
            "Epoch 31/40\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0009460738.\n",
            "938/938 [==============================] - 12s 12ms/step - loss: 0.0395 - acc: 0.9883 - val_loss: 0.0276 - val_acc: 0.9927\n",
            "\n",
            "Epoch 00031: val_acc improved from 0.99220 to 0.99270, saving model to /content/gdrive/My Drive/Weights/Assignment5-1stDNN_v4.3_weights-improvement-31-0.9927.hdf5\n",
            "Epoch 32/40\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.000918358.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0407 - acc: 0.9881 - val_loss: 0.0284 - val_acc: 0.9914\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.99270\n",
            "Epoch 33/40\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.0008922198.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0391 - acc: 0.9885 - val_loss: 0.0266 - val_acc: 0.9921\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.99270\n",
            "Epoch 34/40\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0008675284.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0404 - acc: 0.9879 - val_loss: 0.0270 - val_acc: 0.9910\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.99270\n",
            "Epoch 35/40\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.0008441668.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0383 - acc: 0.9885 - val_loss: 0.0267 - val_acc: 0.9917\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.99270\n",
            "Epoch 36/40\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0008220304.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0393 - acc: 0.9884 - val_loss: 0.0270 - val_acc: 0.9912\n",
            "\n",
            "Epoch 00036: val_acc did not improve from 0.99270\n",
            "Epoch 37/40\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0008010253.\n",
            "938/938 [==============================] - 13s 13ms/step - loss: 0.0390 - acc: 0.9882 - val_loss: 0.0269 - val_acc: 0.9921\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.99270\n",
            "Epoch 38/40\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0007810669.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0391 - acc: 0.9884 - val_loss: 0.0264 - val_acc: 0.9919\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.99270\n",
            "Epoch 39/40\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.000762079.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0384 - acc: 0.9884 - val_loss: 0.0257 - val_acc: 0.9923\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.99270\n",
            "Epoch 40/40\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0007439923.\n",
            "938/938 [==============================] - 11s 12ms/step - loss: 0.0370 - acc: 0.9894 - val_loss: 0.0268 - val_acc: 0.9918\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.99270\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_0_UAU1M1wP",
        "colab_type": "text"
      },
      "source": [
        "Plotting training and validation accuracty as well as loss for every epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tvptcn8dxvp",
        "colab_type": "code",
        "outputId": "32fa0b05-7d1e-476c-a295-be24b7960021",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#history = model.fit(x, y, validation_split=0.25, epochs=50, batch_size=16, verbose=1)\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLFkYY4xplSULY4wxrfp//QEzPISbGzUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl8VPW5+PHPM5M9ZCMJBAgQNhUQ\nRYhYl7pVEXfb64K1brXl9vZ6vbfWtvT2tnrppu3tYtVfr7bFpWqtS721Vop7Xaqyyb5IgAAJgWxk\nI/vM8/vjewJDCGSyTGYgz/v1Oq858z3LPHOUefJdzveIqmKMMcb0li/aARhjjDm6WSIxxhjTJ5ZI\njDHG9IklEmOMMX1iicQYY0yfWCIxxhjTJ5ZIjIkQESkQERWRuDD2vUVE3uvreYyJBkskxgAiUiwi\nrSKS06n8Y+9HvCA6kRkT+yyRGHPANuD6jjciMg1IiV44xhwdLJEYc8DvgZtC3t8MPBG6g4hkiMgT\nIlIhIttF5L9ExOdt84vI/4hIpYhsBS7t4tjfiUiZiJSKyA9ExN/TIEVkpIi8JCLVIlIkIl8O2TZL\nRJaJSJ2I7BGRn3vlSSLypIhUiUiNiCwVkeE9/WxjumKJxJgDPgTSRWSy9wM/F3iy0z4PABnAeOAc\nXOK51dv2ZeAy4BSgELi607GPAe3ARG+f2cCXehHnM0AJMNL7jB+JyPnetvuB+1U1HZgAPOuV3+zF\nPRrIBr4CNPXis405hCUSYw7WUSu5ENgAlHZsCEku31bVelUtBn4G3Ojtci3wS1XdqarVwI9Djh0O\nXAL8h6ruU9Vy4Bfe+cImIqOBM4FvqWqzqq4EfsuBmlQbMFFEclS1QVU/DCnPBiaqakBVl6tqXU8+\n25jDsURizMF+D3weuIVOzVpADhAPbA8p2w6M8tZHAjs7besw1ju2zGtaqgEeBob1ML6RQLWq1h8m\nhtuA44CNXvPVZSHfazHwjIjsEpGfiEh8Dz/bmC5ZIjEmhKpux3W6XwL8qdPmStxf9mNDysZwoNZS\nhms6Ct3WYSfQAuSoaqa3pKvq1B6GuAsYKiJpXcWgqptV9XpcgroPeF5EUlW1TVX/W1WnAGfgmuBu\nwph+YInEmEPdBpyvqvtCC1U1gOtz+KGIpInIWOBODvSjPAvcISL5IpIFzA85tgx4FfiZiKSLiE9E\nJojIOT0JTFV3Av8Afux1oJ/kxfskgIh8QURyVTUI1HiHBUXkPBGZ5jXP1eESYrAnn23M4VgiMaYT\nVd2iqssOs/nfgH3AVuA94GlgobftN7jmo1XACg6t0dwEJADrgb3A88CIXoR4PVCAq528CNytqq97\n2+YA60SkAdfxPldVm4A87/PqcH0/f8c1dxnTZ2IPtjLGGNMXViMxxhjTJ5ZIjDHG9IklEmOMMX1i\nicQYY0yfDIppqXNycrSgoCDaYRhjzFFl+fLllaqa291+gyKRFBQUsGzZ4UZzGmOM6YqIbO9+L2va\nMsYY00eWSIwxxvSJJRJjjDF9Mij6SLrS1tZGSUkJzc3N0Q5lQCQlJZGfn098vE34aozpX4M2kZSU\nlJCWlkZBQQEiEu1wIkpVqaqqoqSkhHHjxkU7HGPMMWbQNm01NzeTnZ19zCcRABEhOzt70NS+jDED\nK6KJRETmiMgm77nS87vYfqeIrBeR1SLyhjctd8e2m0Vks7fcHFI+U0TWeOf8lfQhEwyGJNJhMH1X\nY8zAilgi8Z578BBwMTAFuF5EpnTa7WOgUFVPwk1x/RPv2KHA3cBpwCzgbu/5DgC/xj0be5K3zInU\nd9jb2EpVQ0ukTm+MMceESNZIZgFFqrpVVVuBZ4ArQ3dQ1bdUtdF7+yGQ761fBLymqtWquhd4DZgj\nIiOAdFX9UN38908AV0XqC9Q2tlG9rzUi566qqmL69OlMnz6dvLw8Ro0atf99a2t4n3nrrbeyadOm\niMRnjDHhimRn+ygOfn51Ca6GcTi3AYuOcOwobynpovwQIjIPmAcwZsyYrnbplt8nNLdF5nkt2dnZ\nrFy5EoB77rmHIUOGcNdddx20j6qiqvh8Xef7Rx99NCKxGWNMT8REZ7uIfAEoBH7aX+dU1UdUtVBV\nC3Nzu50qpkt+nxAIDuyDv4qKipgyZQo33HADU6dOpaysjHnz5lFYWMjUqVNZsGDB/n3POussVq5c\nSXt7O5mZmcyfP5+TTz6Z008/nfLy8gGN2xgzeEWyRlIKjA55n++VHURELgC+A5yjqi0hx57b6di3\nvfL8TuWHnLOn/vsv61i/q+6Q8rZAkNb2IKmJPb9MU0amc/flU3sVz8aNG3niiScoLCwE4N5772Xo\n0KG0t7dz3nnncfXVVzNlysHdTbW1tZxzzjnce++93HnnnSxcuJD58w8Z32CMMf0ukjWSpcAkERkn\nIgnAXOCl0B1E5BTgYeAKVQ39E3oxMFtEsrxO9tnAYlUtA+pE5FPeaK2bgD9H8DsAMNAPI54wYcL+\nJALwhz/8gRkzZjBjxgw2bNjA+vXrDzkmOTmZiy++GICZM2dSXFw8UOEaYwa5iNVIVLVdRG7HJQU/\nsFBV14nIAmCZqr6Ea8oaAjznDU/doapXqGq1iHwfl4wAFqhqtbf+VeAxIBnXp7KIPjpczaF6Xysl\nexs5Pi+NxDh/Xz8mbKmpqfvXN2/ezP3338+SJUvIzMzkC1/4Qpf3gyQkJOxf9/v9tLe3D0isxhgT\n0TvbVfUV4JVOZd8LWb/gCMcuBBZ2Ub4MOLEfwzysOJ+792Kg+0lC1dXVkZaWRnp6OmVlZSxevJg5\ncyI24tkYY3ps0E6REg5fDCSSGTNmMGXKFE444QTGjh3LmWeeGbVYjDGmK+Juxzi2FRYWaucHW23Y\nsIHJkycf8bimtgCb99QzdmgKGSkJR9z3aBDOdzbGmA4islxVC7vbLyaG/8YqvzetSPsgSLbGGNNb\nlkiOwO81bQWj2LRljDGxzhLJEfgEhIG/KdEYY44mlkiOQESicne7McYcTSyRdMMlkmhHYYwxscsS\nSTf8PghYZ7sxxhyWJZJu+CQyTVv9MY08wMKFC9m9e3e/x2eMMeGyGxK7EecTmtr6v20rnGnkw7Fw\n4UJmzJhBXl5ef4dojDFhsUTSDV8UOtsff/xxHnroIVpbWznjjDN48MEHCQaD3HrrraxcuRJVZd68\neQwfPpyVK1dy3XXXkZyczJIlSw6ac8sYYwaCJRKARfNh95ouN+UGAmQGFE3wI/Tgued50+Die3sc\nytq1a3nxxRf5xz/+QVxcHPPmzeOZZ55hwoQJVFZWsmaNi7OmpobMzEweeOABHnzwQaZPn97jzzLG\nmP5giaQbgsAAdra//vrrLF26dP808k1NTYwePZqLLrqITZs2cccdd3DppZcye/bsAYvJGGOOxBIJ\nHLHmUN/QQmlNE5Pz0omPi/zYBFXli1/8It///vcP2bZ69WoWLVrEQw89xAsvvMAjjzwS8XiMMaY7\nNmqrGx3TpAzUEOALLriAZ599lsrKSsCN7tqxYwcVFRWoKtdccw0LFixgxYoVAKSlpVFfXz8gsRlj\nTFesRtIN/wBPJT9t2jTuvvtuLrjgAoLBIPHx8fzv//4vfr+f2267DVVFRLjvvvsAuPXWW/nSl75k\nne3GmKixaeS70djaTlF5AwXZqaQnx0cqxAFh08gbY3rCppHvJx1Tydt8W8YY0zVLJN0Y6D4SY4w5\n2kQ0kYjIHBHZJCJFIjK/i+1ni8gKEWkXkatDys8TkZUhS7OIXOVte0xEtoVs6/UNFOE06w10H0mk\nDIYmTGNMdESss11E/MBDwIVACbBURF5S1fUhu+0AbgEOmhtEVd8CpnvnGQoUAa+G7PINVX2+L/El\nJSVRVVVFdnY2Ioe/0VBE8Edovq2BoqpUVVWRlJQU7VCMMcegSI7amgUUqepWABF5BrgS2J9IVLXY\n23akyayuBhapamN/Bpefn09JSQkVFRXd7lte20xtnI/a1KN3RFRSUhL5+fnRDsMYcwyKZCIZBewM\neV8CnNaL88wFft6p7Ici8j3gDWC+qrZ0PkhE5gHzAMaMGXPISePj4xk3blxYAXztl++Qn5XCb28+\nuYehG2PMsS+mO9tFZAQwDVgcUvxt4ATgVGAo8K2ujlXVR1S1UFULc3Nz+xRHRnI8dc1tfTqHMcYc\nqyKZSEqB0SHv872ynrgWeFFV9/+Kq2qZOi3Ao7gmtIjKSI6nrskSiTHGdCWSiWQpMElExolIAq6J\n6qUenuN64A+hBV4tBXE95FcBa/sh1iNKT46n1hKJMcZ0KWKJRFXbgdtxzVIbgGdVdZ2ILBCRKwBE\n5FQRKQGuAR4WkXUdx4tIAa5G8/dOp35KRNYAa4Ac4AeR+g4drEZijDGHF9G5tlT1FeCVTmXfC1lf\nimvy6urYYlyHfefy8/s3yu6lJ8WzrzVAWyBIvD+mu5WMMWbA2a9iGDKSXb6tb26PciTGGBN7LJGE\nISPFTdZo/STGGHMoSyRhSE+yRGKMMYdjiSQMGd708dbhbowxh7JEEoaO55BYjcQYYw5liSQM+2sk\ndne7McYcwhJJGKyPxBhjDs8SSRiS4n0k+H2WSIwxpguWSMIgIqQnx1PXZPeRGGNMZ5ZIwpSeHGej\ntowxpguWSMJkU8kbY0zXLJGEKT3JZgA2xpiuWCIJU4ZNJW+MMV2yRBImm0reGGO6ZokkTOnJcdQ1\nt6Oq0Q7FGGNiiiWSMGUkxxMIKvtaA9EOxRhjYoolkjDZ3e3GGNM1SyRh6phvq7bREokxxoSyRBIm\nm7jRGGO6FtFEIiJzRGSTiBSJyPwutp8tIitEpF1Eru60LSAiK73lpZDycSLykXfOP4pIQiS/Qweb\nSt4YY7oWsUQiIn7gIeBiYApwvYhM6bTbDuAW4OkuTtGkqtO95YqQ8vuAX6jqRGAvcFu/B98Fe7iV\nMcZ0LZI1kllAkapuVdVW4BngytAdVLVYVVcDwXBOKCICnA887xU9DlzVfyEfnnW2G2NM1yKZSEYB\nO0Pel3hl4UoSkWUi8qGIdCSLbKBGVTum4T3sOUVknnf8soqKip7Gfoi0pDhErEZijDGdxUU7gCMY\nq6qlIjIeeFNE1gC14R6sqo8AjwAUFhb2+S5Cn09IS3Q3JRpjjDkgkjWSUmB0yPt8rywsqlrqvW4F\n3gZOAaqATBHpSIA9Omdfpdt8W8YYc4hIJpKlwCRvlFUCMBd4qZtjABCRLBFJ9NZzgDOB9ermJ3kL\n6BjhdTPw536P/DBsvi1jjDlUxBKJ149xO7AY2AA8q6rrRGSBiFwBICKnikgJcA3wsIis8w6fDCwT\nkVW4xHGvqq73tn0LuFNEinB9Jr+L1HfozKaSN8aYQ0W0j0RVXwFe6VT2vZD1pbjmqc7H/QOYdphz\nbsWNCBtwGcnxbKloiMZHG2NMzLI723vAnpJojDGHskTSA+nJcda0ZYwxnVgi6YGM5Hia24K0tNtU\n8sYY08ESSQ+k758mxe4lMcaYDpZIeiDDJm40xphDWCLpgXSbSt4YYw5hiaQHbOJGY4w5lCWSHrCp\n5I0x5lCWSHogPdndv2mJxBhjDrBE0gPW2W6MMYeyRNIDiXF+kuJ9NpW8McaEsETSQ+lJ8dQ2Wo3E\nGGM6WCLpIZtvyxhjDmaJpIfs4VbGGHMwSyQ9lGGJxBhjDmKJpIfSk+KsacsYY0JYIumhjGTrbDfG\nmFCWSHooIzme+pZ2gkGNdijGGBMTLJH0UHpyPKpQ32L3khhjDEQ4kYjIHBHZJCJFIjK/i+1ni8gK\nEWkXkatDyqeLyAcisk5EVovIdSHbHhORbSKy0lumR/I7dJZu820ZY8xB4iJ1YhHxAw8BFwIlwFIR\neUlV14fstgO4Bbir0+GNwE2qullERgLLRWSxqtZ427+hqs9HKvYjCZ0BeHQ0AjDGmBgTsUQCzAKK\nVHUrgIg8A1wJ7E8kqlrsbQuGHqiqn4Ss7xKRciAXqCHKbAZgY4w5WCSbtkYBO0Pel3hlPSIis4AE\nYEtI8Q+9Jq9fiEhi38LsmQx7uJUxxhwkpjvbRWQE8HvgVlXtqLV8GzgBOBUYCnzrMMfOE5FlIrKs\noqKi32LqmErebko0xhgnkomkFA7qRsj3ysIiIunAX4HvqOqHHeWqWqZOC/AorgntEKr6iKoWqmph\nbm5ur75AV2wqeWOMOVgkE8lSYJKIjBORBGAu8FI4B3r7vwg80blT3aulICICXAWs7deou5GaEIdP\noK7Jhv8aYwxEMJGoajtwO7AY2AA8q6rrRGSBiFwBICKnikgJcA3wsIis8w6/FjgbuKWLYb5Picga\nYA2QA/wgUt+hKz6f2MSNxhgTIpKjtlDVV4BXOpV9L2R9Ka7Jq/NxTwJPHuac5/dzmD1mU8kbY8wB\nYdVIRGRCx+goETlXRO4QkczIhha70pOsRmKMMR3Cbdp6AQiIyETgEVwn+tMRiyrG2VTyxhhzQLiJ\nJOj1eXwWeEBVvwGMiFxYsS09Oc5uSDTGGE+4iaRNRK4HbgZe9sriIxNS7HM1Ehu1ZYwxEH4iuRU4\nHfihqm4TkXG4GwUHpXTrbDfGmP3CGrXlTbR4B4CIZAFpqnpfJAOLZelJ8bS2B2luC5AU7492OMYY\nE1Xhjtp6W0TSRWQosAL4jYj8PLKhxS67u90YYw4It2krQ1XrgM/h7jY/DbggcmHFNnsmiTHGHBBu\nIonzpia5lgOd7YOW1UiMMeaAcBPJAtxUJ1tUdamIjAc2Ry6s2GZTyRtjzAHhdrY/BzwX8n4r8E+R\nCirWpSfZVPLGGNMh3M72fBF5UUTKveUFETlkjqzBYn/TVqMlEmOMCbdp61HcFPAjveUvXtmgtL+z\nvdluSjTGmHATSa6qPqqq7d7yGO4Z6oNSvN9HSoLfmraMMYbwE0mViHxBRPze8gWgKpKBxbqM5Hgb\n/muMMYSfSL6IG/q7GygDrgZuiVBMRwWbSt4YY5ywEomqblfVK1Q1V1WHqepVDOJRW2BTyRtjTIe+\nPGr3zn6L4iiUnhxnne3GGEPfEon0WxRHoXTrIzHGGKBviUT7LYqjkHW2G2OMc8REIiL1IlLXxVKP\nu5/kiERkjohsEpEiEZnfxfazRWSFiLSLyNWdtt0sIpu95eaQ8pkissY7569EJCo1o/SkeOpb2gkE\nB3U+NcaYIycSVU1T1fQuljRVPeL0KiLiBx4CLgamANeLyJROu+3Ajf56utOxQ4G7gdOAWcDd3nNQ\nAH4NfBmY5C1zwvie/S7DZgA2xhigb01b3ZkFFKnqVlVtBZ4BrgzdQVWLVXU1EOx07EXAa6parap7\ngdeAOd4MxOmq+qGqKvAEcFUEv8NhpdvEjcYYA0Q2kYwCdoa8L/HK+nLsKG+923OKyDwRWSYiyyoq\nKsIOOlw2lbwxxjiRTCRRpaqPqGqhqhbm5vb/bC4HmrZsCLAxZnCLZCIpBUaHvM/3yvpybKm33ptz\n9qv0ZJtK3hhjILKJZCkwSUTGiUgCMBc3g3A4FgOzRSTL62SfDSxW1TKgTkQ+5Y3Wugn4cySC7441\nbRljjBOxRKKq7cDtuKSwAXhWVdeJyAIRuQJARE4VkRLgGuBhEVnnHVsNfB+XjJYCC7wygK8CvwWK\ngC3Aokh9hyNJT7LOdmOMgTCfkNhbqvoK8Eqnsu+FrC/l4Kaq0P0WAgu7KF8GnNi/kfZcSoKfOJ9Y\njcQYM+gds53tkSYiZKUmsKW8IdqhGGNMVFki6YNrZubz6vo9rNxZE+1QjDEmaiyR9MG/nDuBnCEJ\n/PCv63H3RxpjzOBjiaQP0pLi+dqFx7G0eC+L1+2OdjjGGBMVlkj66LrC0UwaNoR7F22ktb3zTC/G\nGHPss0TSR3F+H/956WSKqxr5/Yfbox2OMcYMOEsk/eDc43L59KQcfvXGZmoaW6MdjjHGDChLJP1A\nRPjPSyZT19zGA28WRTscY4wZUJZI+snkEelcO3M0T3xQTHHlvmiHY4wxA8YSST/6+uzjiPf7uO9v\nG6MdijHGDBhLJP1oWHoS/3z2BBat3c3S4uruDzDGmGOAJZJ+9uWzx5GXnsQP/rqBoD3P3RgzCFgi\n6WcpCXHcddHxrNpZw19W74p2OMYYE3GWSCLgc6eMYurIdH7yt000twWiHY4xxkSUJZII8PmE71w6\nmdKaJn799pZoh2OMMRFliSRCzpiQw1XTR/LQW0VsKKuLdjjGGBMxlkgi6O7Lp5KZEs83n19Ne8Dm\n4TLGHJsskURQVmoCC648kTWltTzy7tZoh2OMMRFhiSTCLpk2gotPzOOXr2+mqLw+2uEYY0y/i2gi\nEZE5IrJJRIpEZH4X2xNF5I/e9o9EpMArv0FEVoYsQRGZ7m172ztnx7ZhkfwO/WHBlSeSkuDnm8+v\nJmD3lhhjjjERSyQi4gceAi4GpgDXi8iUTrvdBuxV1YnAL4D7AFT1KVWdrqrTgRuBbaq6MuS4Gzq2\nq2p5pL4Dr/4X/Pn2Pp8mNy2Rey6fyoodNTz6/rZ+CMwYY2JHJGsks4AiVd2qqq3AM8CVnfa5Enjc\nW38e+IyISKd9rveOHXjBAKx6Bhoq+nyqK6eP5DMnDON/Xt1kkzoaY44pkUwko4CdIe9LvLIu91HV\ndqAWyO60z3XAHzqVPeo1a323i8QDgIjME5FlIrKsoqKXiWDmLRBsg5VP9u74g+Phh5+dRrzfxzdf\nWG3Tpxhjjhkx3dkuIqcBjaq6NqT4BlWdBnzaW27s6lhVfURVC1W1MDc3t3cB5B4PY8+C5Y9BsO/D\nd/MykvjupVNYsq2apz6ypykaY44NkUwkpcDokPf5XlmX+4hIHJABVIVsn0un2oiqlnqv9cDTuCa0\nyCm8FfYWw9a3+uV01xTm8+lJOfx40UZ2Vjf2yzmNMSaaIplIlgKTRGSciCTgksJLnfZ5CbjZW78a\neFNVFUBEfMC1hPSPiEiciOR46/HAZcBaImny5ZCSA8sW9svpRIQff24aAvzni2usicsYc9SLWCLx\n+jxuBxYDG4BnVXWdiCwQkSu83X4HZItIEXAnEDpE+Gxgp6qG3smXCCwWkdXASlyN5jeR+g4AxCXC\nKTfApkVQV9Yvp8zPSmH+JZN5d3Ml1//mQ3ZUWc3EGHP0Eq8CcEwrLCzUZcuW9f4E1VvhV6fAed+B\nc77ZLzGpKs8tK+H7L68noMq3L5nMDbPG4PN1OXbAGGMGnIgsV9XC7vaL6c72mDF0PEw433W6B9r7\n5ZQiwrWnjuZvXzubmWOz+O7/reXGhR9RstdqJ8aYo4slknDNvBXqSqHotX497ajMZJ744ix+9Nlp\nrNxRw5xfvsszS3YwGGqKxphjgyWScB1/MQzJ67dO91AiwudPG8Pf/uNspo3KYP6f1nDzo0spq23q\n988yxpj+ZokkXP54mHETbH4NanZE5CNGD03hqS+dxoIrp7J0WzXn/PRtvvT4Mv60ooTapraIfKYx\nxvRVXLQDOKrMuAne/R9Y/jh85rsR+QifT7jp9ALOOS6XR98vZvG63by+YQ/xfuHMiTlcfGIeF07J\nY2hqQkQ+3xhjespGbfXU09fBro/ha+tcLSXCgkFlVUkNi9buZtHaMnZWN+H3CZ8aP5TLTxrJZSeP\nZEii/T1gjOl/4Y7askTSU58shqevhWufgCmd56CMLFVl3a46Fq0tY9Ga3Wyt3Edqgp8rTxnF52eN\n4cRRGQMajzHm2GaJJES/JpJgAO4/GbInwE1/7p9z9oKqsmJHDX9YsoOXV++iuS3ISfkZXD9rDJdb\nLcUY0w8skYTo10QC8Pefwls/gH9b4RJKlNU2tfF/H5fy9Ec72LSnfn8t5ebTCzg+Ly3a4RljjlKW\nSEL0eyKp3w0/nwKn/yvM/n7/nbePOmopT3/kaikt7UEumjqc28+bxLR8a/YyxvSMJZIQ/Z5IAP54\nIxS/B1/f6ObjijE1ja0sfL+YR9/fRn1zO+cen8u/nT+RmWOHRjs0Y8xRwqZIibTCW6GpGtZ3ntA4\nNmSmJHDnhcfx/vzz+cZFx7O6pJZ/+vUHfP43H/KPLZV257wxpt9YjaS3gkF4YAZk5MMtL/fvuSOg\nsbWdpz/awcPvbKWivoWZY7OYe+poLpwynMwUuyfFGHMoa9oKEZFEAvDO/8Cb34c7PnYTOx4FmtsC\nPLdsJ4+8u5Wd1U3E+YTTJ2Qz58Q8Zk/JIzct9prpjDHRYYkkRMQSSd0u+MVUOOvOiN3pHimqyuqS\nWhat3c3f1pZRXNWICJxaMJSLT8xjzol5jMhIjnaYxpgoskQSImKJBOCpa2D3WvjaWvD5I/MZEaaq\nbNxdz9/W7uZva3ezaU89AFNGpHP+CcM474RhTB+did+elWLMoGKJJEREE8n6l+DZG+Hzz8FxsyPz\nGQNsa0UDi9ft4a2N5SzfsZdAUMlKieec43I574RhnHNcrvWrGDMIWCIJEdFE0t4KP58MY8+A634f\nmc+IotrGNt7ZXMFbG8t5+5MKqve14hOYMSaLc4/P5dzjhzFlRLo92dGYY5AlkhARTSQAi78DHz3s\n7ilJzYnc50RZIKisLqnhrY3lvLWpgjWltQDkpiVyznG5nHt8Lp+emEtGSuQnszTGRF5MJBIRmQPc\nD/iB36rqvZ22JwJPADOBKuA6VS0WkQJgA7DJ2/VDVf2Kd8xM4DEgGXgF+Hft5ktEPJGUb4D/9ymY\n/UM44/bIfU6Mqahv4e+fVPD2pnLe3VxJbVMbfp8wY0wm5x4/jIumDmdC7hBErLZizNEo6olERPzA\nJ8CFQAmwFLheVdeH7PNV4CRV/YqIzAU+q6rXeYnkZVU9sYvzLgHuAD7CJZJfqeqiI8US8UQC8JvP\nQGsDfPVDGIQ/nO2BIKtKanh7UwVvbSpnbWkdAONzUrlwynBmTx3O9NFZ1mFvzFEk3EQSySliZwFF\nqrrVC+gZ4Epgfcg+VwL3eOvPAw/KEf58FZERQLqqfui9fwK4CjhiIhkQM26Ev/w7lC6H/G6v+zEn\nzu9j5tihzBw7lK/PPp6y2iZeX7+HV9fv4XfvbePhd7aSMySBCya7pDIuZwiBYJBA0DWZBVUJBJWA\nKsGg0toepCUQpK09SGsgSGu7twSC+H3CZSeNJCPZmtCMiQWRTCSjgJ0h70uA0w63j6q2i0gtkO1t\nGyciHwN1wH+p6rve/iWdzjnXTDuNAAAYfUlEQVSqqw8XkXnAPIAxY8b07ZuEY+rn4G/fhhVPDMpE\n0tmIjGRuPL2AG08voLapjbc3lfPa+j28vLqMZ5bu7P4E3fjZq59w1+zjue7U0VbLMSbKYvWhFWXA\nGFWt8vpE/k9EpvbkBKr6CPAIuKatCMR4sKR0mHIVrP0TzPkxJKRG/COPFhnJ8Vw5fRRXTh9FS3uA\nJduqqWxowSeC3yfE+WT/us8n+EVIiPMR7/eRGOcjIc5Hgt97jfNRsreJH/51Pf/54hqe+mg7d18+\nlVnjbDJKY6IlkomkFBgd8j7fK+tqnxIRiQMygCqv87wFQFWXi8gW4Dhv//xuzhk9M26EVU/D+j/D\n9M9HO5qYlBjn59OTcvt0jpwhiTz7z6fzl9Vl/PiVDVz78AdcfvJIvn3xCYzMtLvxjRlokZz9dykw\nSUTGiUgCMBfoPFXuS8DN3vrVwJuqqiKS63XWIyLjgUnAVlUtA+pE5FNeX8pNQPQeU9jZmNNh6ARY\ncezdTxJrRIQrTh7JG18/hzs+M4lX1+3m/J+9zf2vb6a5LbB/P1WlpT1AfXMbVQ0t7KpporSmiYr6\nFuqa22huC9hMyMb0UcRqJF6fx+3AYtzw34Wquk5EFgDLVPUl4HfA70WkCKjGJRuAs4EFItIGBIGv\nqGq1t+2rHBj+u4hY6GjvIAKnfAHe+G+oLIKcidGO6JiXkhDHnRcexzUz8/nxog384vVPePidLfhF\naPE66cMR2nTmEzcAwA0CYP9AgKAqqjA+N5VTRmcxY2wmM8ZkMSF3SLc3ZLYHgpTVNtMWCDI+d0h/\nfHVjYobdkNjfOp6eeOYdcME9A/OZZr8PtlSxaG0Zfp/rZ0n0+0iM9+9PFIlxPkRwo8K8pWM0WEtb\nkNZAAFUO9NmI4Pe59z6foAqbdtfx8c4aahrbAEhLimP66ExOGZPFlBHp1Da1Urq3iZK9TZTUNFG6\nt4nddc0Egu7f2vTRmdx6ZgEXnziChDh7JJCJXVG/jySWDGgiAXh6Luz6GL62DvyxOp7B9IWqsq1y\nHyt21LBix15WbN/LJ3vq8XIFPoG89CTys1IYlZVMvrc0tAR46sPtbK3cR25aIjecNobPnzaGYWlJ\nXX5OeX0z7xdV8u7mSt4vqkQQTh6dwUn5mUwfncm0/AzSk2wYtIkMSyQhBjyRbHgZ/ngDXP9HOH7O\nwH2uiaqGlnaKyhvITk0gLyOJeH/XtY1gUHlncwWP/6OYtzZVEO8XLp02glvOHMfxw9NYUlzNe5sr\neHdzJRt3u5mYh6YmcMaEbPw+YdXOGoqrGvefb3xuKifnZ3JyfgaFBUNt7jPTbyyRhBjwRBJoc81b\no2fB3KcG7nPNUWdrRQNPfLCd55eX0NDSTpxPaA8qCX4fp47L4qyJuXx6Us4hyaGmsZXVJbWsLqlh\nVUktq3bWUF7fArjh1qeNG8rpE7I5Y0IOxw3vepoaVaWyoZXtVfvYVrmPmsY2CnJSOW74EPKzUuz+\nHGOJJNSAJxKAV78LH/4/uPkvkJYHSZmQmG5NXaZL9c1tvPhxKaU1TZwxIYdZBUNJTujZ82121TTx\n0bYqPthSxQdbq9hZ3QRAdmoCnxqfzSljMtnb2EpxZSPFVfvYXtVIQ0t7l+dKjPMxIXcIxw0fwqTh\naUwcNoQxQ1MYkhhHWlIcqYlxh61x9bfyumZ2VDdywoh0hiTav5+BZIkkRFQSScUn8NAsoNP1TRgC\nSRluSctzEz0OnzKwsZlBYWd1Ix9sreJDL7GU1Tbj9wmjs5IpyEmlIDuVguwUxuakMi47lcyUeLZV\n7mPzngY2l9fzyZ4GisobKK1p6vL8CXE+0hJdUulIMBnJ8WSmxJOR7C0pCa4sOZ6cIYnkZSSRlRJ/\n2Ik8VZUtFftYVlzNkuJqlhXvZUe1a8bzCZyQl05hQRYzx7plVGbyIefa19LOlooGNu9poMh7TYr3\nMWNMFjPGugER4QxyqG1sY31ZHdur9nFSfiaTR6QNuglILZGEiEoiAdi9Bmp2QHMdNNceWFq81x0f\nQVsTXL3wmHkololNHc1YmSnxPa5JdPT97KppoqGlnYbmdva1tLv1jqW5nfrmdmqb2qhpaqW2qY3m\ntq6HXif4fQxLTyQvPYnhGUkMT0siIzmedbtqWbZ9L9X7WgFXkyosyOLUgqGMzU5lbWkty7fv5eMd\ne9nX6u4VyktPYubYLIanJ7Gl4tDEF+8XCrJTaWwN7C9PjPNxcn4mp4zNZOaYLKaPyaShuZ0NZfVs\nKKvbv+yqbT4o7vysZGZPyWP21OEUjs0irpvr2B4IsnNvE9X7WkiM85OS4Cc5wU9yvJ+keL83gvDw\nCbVj6HmcT6KWwCyRhIhaIulObSn8YS7sWQsX/QhO+8qgnDnYHJua2wLUNbVR29TG3sY2Khta2F3b\nzJ76ZvbUNrO7rpnyuhZ21zXT2BqgIDuFwoKhnFqQRWHBUMbnpHb5A9oeCLJpTz3Lt+9lWfFelm/f\nS9W+FibkDmHisCFMGjaEicNcc9zY7JT9ibOstokV290ou+Xb97JuVy1tgYN///w+YUJuKpNHpO9f\n8rOSWbqtmtfW7+Hdokpa24NkpcRz/gluAtJZBUPZVdtEUXkDW8ob2FKxj6LyBrZV7qM1cPj7mEQg\nOd6P3ych9y0duH+pQ3K8n+HpiQxPT2J4ehJ5GUkMS3O1u7z0JI7PSyMtQiP3LJGEiNlEAtC6D/40\nDza+DIVfhIt/Av5u/qcIBqDoDWith+Pm2Lxe5qjmZh8IkhTfsz6hzufo6V/tzW0B1pbWsqqklvSk\nOCaPSGfisCFHjGNfSzvvfFLBq+v38MaGPdQ1H9zH5BMYMzRlf1KbkDuEYemJtLQHaW4L0NQaoKkt\nQGNrgGbvNaiKv9Ncc/tfBWqb2g5Kurvrmg+60VYEJuQOcSP3Rmdwcn4mJ4xIIzGu99fzwLktkewX\n04kEIBiENxfAe7+AcefAtY9Dctah+zVWu9mFl/3ONZmB63OZchVMvx7GnAE+u8HNmIHQFgiyZFs1\na0prGZ2VwoRhrt+pLwkxHKq6P7nsqmlibWkdq3bWsKqkhsoG1yyY4PcxeUQaJ4/O5CvnTOj1HHSW\nSELEfCLp8PFT7pkmWQXw+T9C9gRXXroClv4W1r4A7c0w9iyY9WX3WN9Vf4B1f3a1k8wxcPL1cPJc\nGDo+ql/FGDOwVJVdtc37k8qqnTWsKanlja+fS15G1ze8dscSSYijJpEAFL8Pf/wCoHDW12D9S1C6\nDOJTXYI49UuHjvJqbXRNYyufhq1vu2PHnA6n/yuccJn1uxgzSAWC2qf7gSyRhDiqEglA9VZ4+jqo\n/ASyJ7nax8lz3ZDh7tSWwuo/wsdPQvUWGH+u63fJPb7/4gsGoK0REtN6fmxjNXzwENRsB1+86w/y\nJ3iv8a4sLsnNCJA3rf9iNsb0mCWSEEddIgFoqYfyje5pi72pUQTaYdlCeOsHrkP/tK/AOd9yD+Dq\njbZm2PZ32PAX2LQImva65Pbprx9ogjuS9lbXPPf3+9zQ56wCCLa7WQACre412AbtLey/92bSRXD2\nXW6GAGPMgLNEEuKoTCT9paHCTWv/8ZMwZBhc+H046drwklNzLWx+zTWbbX4NWhsgIc3d85KUCSuf\nckngxKvdD35XtR5Vl3xev9vVtMafB7N/AHknHv5zm/bCkt+6mQGaqqHg0y5hjT+37810e4uhsQpG\nzrAmP2O6YYkkxKBOJB1KlsMrd8GuFTD6U3DJTyFnEjSUw74KaNjj1hvKYV85VG2B4vdcLSE1F46/\nBCZfDuPOhrhEd876PfDBA7D0d+7GyqmfhbO/caAPp2Q5vPod2PEB5J7gEsjEC8L/AW/dB8sfg388\nAPVlMGqmSyjHXdzz0WlNe+HvP4UlD7uaUN5Jrg9p6ucgLqFn5zJmkLBEEsISiScYhJVPwuv3uL/K\nDyc5C9JGwoTzXPLIPxV8RxjSuK8SPngQlvzG1VomXw7+RFj7vEtC5/0nnHJT7+cZa29xAwne+4Xr\nW8mdDDNvdjWhId08tjfQDssfhbd+5JLJjBthxHT46GGo3ARD8lwfVOEXIcWe+25MKEskISyRdNK0\nF5Y9Chp0zV1Dhrsf/I7X3v6F3lgNH/7a/UgHWtxf/Gf+R+/7ZToLtMO6P7mkVbYKxA8TPwMnXQcn\nXArxncbKF70Oi78DFRtd89hFP4IRJ7ltqu6mzg8fgi1vQlyy6/P51FddTW1fJdSVQG2JG8DQsV6/\nB0acDCddE37zWHsLbPyrawrcvdY10U25Aiacf2jMx5LmOtj2Dmx5w9Vu00fBpAth4oXuGlvTYsyz\nRBLCEskAa2lwzUfJmZH7jPKNsPoZWP0s1JW6mZWnXAEnzXXJ8LXvwuZXIWuca1I74dLD/3DtWe/6\nY1Y/6xKgP9G9hopLcj+EqTnuoWWBVsieCNOucUvnAQeqULbS3Ru05jlornHH5xfC1r+79/Gp7od1\nyhUwaXbvRsF1J9AG2993z8gpfs/NgpCW5/5oGDIc0oa7WlnacFcLHTKs9z/wwSDsXuUSdNEbULLE\n/X+QMMQNR6/Z4WqB4O55mjTbJZVxnz50doZAu+sf21fhknp7s7veWQVHrh2bfmWJJIQlkmNYMAjF\n77ohz+v/7JrWwCWWc74Js+Yd6NPpTkMFfPwENNVARr5b0ke515TsAz+wTXvd/T1rnnM/ziiMKnSD\nGMafB0WvuQRSvs4lpcmXwfQbXE3E53c/7sXvunNsfNn9WPoTXQ1lwnmQMRoyRkF6vmtu6+kPe1uT\nq2VteBk+8UbYxSVDwZnuh71+DzTsduWdJaRBzkTIOc4NPe9YHzrBXcfmWtdfVbfLey2D+l3ufcky\naKx058k7ydUWJ14A+bMO1HJrdriBG0Wvu4Tats999/xTXQ25sdJdj6YaDpk5G1xCzz0ehk2BYZNd\nM+ewye6/T32Z+6OittS91pW6uOpKXXPtuHPcf5+R0y0ZhckSSQhLJINEayNsegWqt0Hhra72EGm1\npa4vaPVzsGfNgfJRM13yOPFzXU930yEYgB0fupFtG/7imtBCxSVD+ki3ZOS7c+2/9ybh4HVVl6CK\nXnf3+SRluIEJky+DCZ+BhJSDz93e4g2w2AP1u90PbuVmqNrsXutKQ3YW9yPe3sWU8slDXXzDprjk\nMeF8V7PpTnuLG4ix+TX3Gp/iEkJqDqTkeK/ee3+iu6+qYiOUr4fyDS5xHEnyUPeHQPoIt+9u779P\nUoZr6hx/rkss2RMOTtbtLQdm6m6qgZY6l0Tjk12MHUtCivvv4/O5Pw5a97nr3troEmTHa6ANfHEu\nefniQhbvfXyq+++alNH/zyvaV+XO3cupk2IikYjIHOB+wA/8VlXv7bQ9EXgCmAlUAdeparGIXAjc\nCyQArcA3VPVN75i3gRFAx//Rs1W1/EhxWCIxA6J8g6uhFJzl/kruKVX3ox76F3VtyYG/rGtL3f1F\ngVbX9KZdzCw7ZLibzWDyZe7HsrsJQI+kdR9UFbmkUrnZfXZa3oHEljbCLfG9m36jz5r2uibO8vVu\nPX3UgYSbNuLQxLmv0t0LtfVt2PI21Hrz1aWPcs2KTTUueXSVLI/EF+9GN/aHxAxIyXI//h1L6jB3\n3dNGHPyamOYSYKDdDUKp3OySbeUnB9abquGOlTB0XK/CiXoiERE/8AlwIVACLAWuV9X1Ift8FThJ\nVb8iInOBz6rqdSJyCrBHVXeJyInAYlUd5R3zNnCXqoadGSyRmGNSMOAlFe+GzkCbSyQ2cWf3VGHv\nNpdUit9z1y4588BD55IyvSXD/WAH27waRsfS5NVAmlxSD62lxKe6Pp+OdX+8S/rB9oOXQLs7b1uT\nS4SN1e71oKXa1Ro7mmxDxae6GlvDbvf/QIfUYa45MmeSez3p2l7XzsNNJJF8buUsoEhVt3oBPQNc\nCawP2edK4B5v/XngQRERVf04ZJ91QLKIJKpqpx5QYwYxnx98ycf2yK9IEXETmw4d74Z+x7qWetf8\nWF928Ou+SlcLyznOWyYeuSk1QiKZSEYBO0PelwCnHW4fVW0XkVogG6gM2eefgBWdksijIhIAXgB+\noF1Uq0RkHjAPYMyYMX38KsYYE0WJaW7JmRTtSLoU03VgEZkK3Af8c0jxDao6Dfi0t9zY1bGq+oiq\nFqpqYW5uNzetGWOM6bVIJpJSYHTI+3yvrMt9RCQOyMB1uiMi+cCLwE2quqXjAFUt9V7rgadxTWjG\nGGOiJJKJZCkwSUTGiUgCMBd4qdM+LwE3e+tXA2+qqopIJvBXYL6qvt+xs4jEiUiOtx4PXAasjeB3\nMMYY042IJRJVbQduBxYDG4BnVXWdiCwQkSu83X4HZItIEXAnMN8rvx2YCHxPRFZ6yzAgEVgsIquB\nlbgazW8i9R2MMcZ0z25INMYY06Vwh//GdGe7McaY2GeJxBhjTJ9YIjHGGNMng6KPREQqgO29PDyH\ng2+QjCUWW+9YbL1jsfXO0RzbWFXt9ka8QZFI+kJEloXT2RQNFlvvWGy9Y7H1zmCIzZq2jDHG9Ikl\nEmOMMX1iiaR7j0Q7gCOw2HrHYusdi613jvnYrI/EGGNMn1iNxBhjTJ9YIjHGGNMnlkiOQETmiMgm\nESkSkfndHzFwRKRYRNZ4E1pGdSIxEVkoIuUisjakbKiIvCYim73XgX9s2+Fju0dESkMmBL0kSrGN\nFpG3RGS9iKwTkX/3yqN+7Y4QW9SvnYgkicgSEVnlxfbfXvk4EfnI+/f6R2/W8ViJ7TER2RZy3aYP\ndGxeHH4R+VhEXvbe9881U1VbulgAP7AFGA8kAKuAKdGOKyS+YiAn2nF4sZwNzADWhpT9BPcYAHCz\nOt8XQ7HdA9wVA9dtBDDDW08DPgGmxMK1O0JsUb92gABDvPV44CPgU8CzwFyv/H+Bf4mh2B4Dro6B\n/+fuxD3H6WXvfb9cM6uRHN7+Z86raivQ8cx504mqvgNUdyq+EnjcW38cuGpAg/IcJraYoKplqrrC\nW6/HPW5hFDFw7Y4QW9Sp0+C9jfcWBc4HnvfKo3XdDhdb1HkPC7wU+K33Xuina2aJ5PC6euZ8TPxD\n8ijwqogs955PH2uGq2qZt74bGB7NYLpwu4is9pq+otLsFkpECoBTcH/BxtS16xQbxMC185poVgLl\nwGu41oMadc9Bgij+e+0cm6p2XLcfetftFyKSGIXQfgl8Ewh677Ppp2tmieTodZaqzgAuBv5VRM6O\ndkCHo67eHBN/lXl+DUwApgNlwM+iGYyIDAFeAP5DVetCt0X72nURW0xcO1UNqOp03CO8ZwEnRCOO\nrnSOTUROBL6Ni/FUYCjwrYGMSUQuA8pVdXkkzm+J5PDCeeZ81OiBZ9eX455tH2vPrt8jIiMAvNfy\nKMezn6ru8f6xB3FP2IzatfMeGf0C8JSq/skrjolr11VssXTtvHhqgLeA04FMEYnzNkX932tIbHO8\npkJV1RbgUQb+up0JXCEixbhm+vOB++mna2aJ5PDCeeZ8VIhIqoikdawDs4m9Z9e/BNzsrd8M/DmK\nsRyk40fa81midO28NurfARtU9echm6J+7Q4XWyxcOxHJFZFMbz0ZuBDXh/MWcLW3W7SuW1exbQz5\nw0Bw/RADet1U9duqmq+qBbjfsjdV9Qb665pFexRBLC/AJbjRKluA70Q7npC4xuNGka0C1kU7NuAP\nuGaONlw762249tc3gM3A68DQGIrt98AaYDXuR3tElGI7C9dstRpY6S2XxMK1O0JsUb92wEnAx14M\na4HveeXjgSVAEfAckBhDsb3pXbe1wJN4I7ui9P/duRwYtdUv18ymSDHGGNMn1rRljDGmTyyRGGOM\n6RNLJMYYY/rEEokxxpg+sURijDGmTyyRGNMPRCQQMrPrSunH2aJFpCB09mJjYk1c97sYY8LQpG5a\nDGMGHauRGBNB4p4b8xNxz45ZIiITvfICEXnTm8TvDREZ45UPF5EXvedZrBKRM7xT+UXkN94zLl71\n7po2JiZYIjGmfyR3atq6LmRbrapOAx7EzcAK8ADwuKqeBDwF/Mor/xXwd1U9GfcclXVe+STgIVWd\nCtQA/xTh72NM2OzOdmP6gYg0qOqQLsqLgfNVdas3CeJuVc0WkUrc9CJtXnmZquaISAWQr25yv45z\nFOCmI5/kvf8WEK+qP4j8NzOme1YjMSby9DDrPdESsh7A+jdNDLFEYkzkXRfy+oG3/g/cLKwANwDv\neutvAP8C+x+QlDFQQRrTW/ZXjTH9I9l7Kl6Hv6lqxxDgLBFZjatVXO+V/RvwqIh8A6gAbvXK/x14\nRERuw9U8/gU3e7ExMcv6SIyJIK+PpFBVK6MdizGRYk1bxhhj+sRqJMYYY/rEaiTGGGP6xBKJMcaY\nPrFEYowxpk8skRhjjOkTSyTGGGP65P8DhMvWYdGc2tEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UyH8P1SaNYYZ"
      },
      "source": [
        "Evaluating model and storing score in a variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_eDU0sXWNXmE",
        "colab": {}
      },
      "source": [
        "#score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "score = model.evaluate_generator(validation_generator, steps=len(validation_generator), verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_weXQQMkNWk1"
      },
      "source": [
        "Printing loss and accuracy of model test done in last step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkX8JMv79q9r",
        "colab_type": "code",
        "outputId": "756d69ef-a85d-4f19-f27e-1a4fa5299811",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.026909500037133695, 0.9919]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ed35zlSB37Mm",
        "colab_type": "text"
      },
      "source": [
        "Predicting out put for test inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCWoJkwE9suh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8INoWoRT4BBu",
        "colab_type": "text"
      },
      "source": [
        "Printing prediction and test out puts "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym7iCFBm9uBs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(y_pred[:9])\n",
        "print(y_test[:9])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT--y98_dr2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
        "layer_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2GY4Upv4dsUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from keras import backend as K\n",
        "%matplotlib inline\n",
        "# util function to convert a tensor into a valid image\n",
        "def deprocess_image(x):\n",
        "    # normalize tensor: center on 0., ensure std is 0.1\n",
        "    x -= x.mean()\n",
        "    x /= (x.std() + 1e-5)\n",
        "    x *= 0.1\n",
        "\n",
        "    # clip to [0, 1]\n",
        "    x += 0.5\n",
        "    x = np.clip(x, 0, 1)\n",
        "\n",
        "    # convert to RGB array\n",
        "    x *= 255\n",
        "    #x = x.transpose((1, 2, 0))\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x\n",
        "\n",
        "def vis_img_in_filter(img = np.array(X_train[2]).reshape((1, 28, 28, 1)).astype(np.float64), \n",
        "                      layer_name = 'conv2d_2'):  \n",
        "    layer_output = layer_dict[layer_name].output\n",
        "    img_ascs = list()\n",
        "    for filter_index in range(layer_output.shape[3]):\n",
        "        # build a loss function that maximizes the activation\n",
        "        # of the nth filter of the layer considered\n",
        "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
        "\n",
        "        # compute the gradient of the input picture wrt this loss\n",
        "        grads = K.gradients(loss, model.input)[0]\n",
        "\n",
        "        # normalization trick: we normalize the gradient\n",
        "        grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
        "\n",
        "        # this function returns the loss and grads given the input picture\n",
        "        iterate = K.function([model.input], [loss, grads])\n",
        "\n",
        "        # step size for gradient ascent\n",
        "        step = 5.\n",
        "\n",
        "        img_asc = np.array(img)\n",
        "        # run gradient ascent for 20 steps\n",
        "        for i in range(20):\n",
        "            loss_value, grads_value = iterate([img_asc])\n",
        "            img_asc += grads_value * step\n",
        "\n",
        "        img_asc = img_asc[0]\n",
        "        img_ascs.append(deprocess_image(img_asc).reshape((28, 28)))\n",
        "        \n",
        "    if layer_output.shape[3] >= 35:\n",
        "        plot_x, plot_y = 6, 6\n",
        "    elif layer_output.shape[3] >= 23:\n",
        "        plot_x, plot_y = 4, 6\n",
        "    elif layer_output.shape[3] >= 11:\n",
        "        plot_x, plot_y = 2, 6\n",
        "    else:\n",
        "        plot_x, plot_y = 1, 2\n",
        "    fig, ax = plt.subplots(plot_x, plot_y, figsize = (12, 12))\n",
        "    ax[0, 0].imshow(img.reshape((28, 28)), cmap = 'gray')\n",
        "    ax[0, 0].set_title('Input image')\n",
        "    fig.suptitle('Input image and %s filters' % (layer_name,))\n",
        "    fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n",
        "    for (x, y) in [(i, j) for i in range(plot_x) for j in range(plot_y)]:\n",
        "        if x == 0 and y == 0:\n",
        "            continue\n",
        "        ax[x, y].imshow(img_ascs[x * plot_y + y - 1], cmap = 'gray')\n",
        "        ax[x, y].set_title('filter %d' % (x * plot_y + y - 1))\n",
        "\n",
        "vis_img_in_filter()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}